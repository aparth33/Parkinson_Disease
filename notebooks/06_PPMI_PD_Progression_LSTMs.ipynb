{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To do:  \n",
    "* PREPARING DATA: See what has to be done for engineered features (normalisation versus standardization?)\n",
    "* CHOOSE A BASELINE: for example, prediction=last disease stage\n",
    "\n",
    "### results so far: \n",
    "* Best model: n_epochs=50, optimiser='adam', batch_size=8, input_units=50\n",
    "* L2 Regularization doesn't change validation accuracy, and is worse for the loss\n",
    "\n",
    "### To improve model\n",
    "* Try Irwan's optimizer\n",
    "* Try with the reduced list of features (relevant features from the RF classifier): but first code all the data processing as a function\n",
    "* Try with GRU layer instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>INFODT</th>\n",
       "      <th>INFODT_date</th>\n",
       "      <th>NP1COG</th>\n",
       "      <th>NP1HALL</th>\n",
       "      <th>NP1DPRS</th>\n",
       "      <th>NP1ANXS</th>\n",
       "      <th>NP1APAT</th>\n",
       "      <th>NP1DDS</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>SC</td>\n",
       "      <td>02/2011</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2707</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001</td>\n",
       "      <td>V04</td>\n",
       "      <td>03/2012</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2313</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATNO EVENT_ID   INFODT INFODT_date  NP1COG  NP1HALL  NP1DPRS  NP1ANXS  \\\n",
       "0   3001       SC  02/2011  2011-02-01     0.0      0.0      0.0      1.0   \n",
       "1   3001      V04  03/2012  2012-03-01     1.0      0.0      1.0      1.0   \n",
       "\n",
       "   NP1APAT  NP1DDS         ...          DXPOSINS  DXOTHSX  DOMSIDE  \\\n",
       "0      0.0     0.0         ...                 0        0        2   \n",
       "1      1.0     0.0         ...                 0        0        2   \n",
       "\n",
       "   num_visits  VISIT_ID  visitsdiff_days  lastDate_diff_days  \\\n",
       "0           7         1                0                2707   \n",
       "1           7         2              394                2313   \n",
       "\n",
       "   PDDXDT_diff_days  PDMEDT_diff_days  PDSURGDT_diff_days  \n",
       "0               306                 0                   0  \n",
       "1               700                 0                   0  \n",
       "\n",
       "[2 rows x 378 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### reading processed dataframe\n",
    "file_path='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/output/pre-processing/dfFinal.csv'\n",
    "df=pd.read_csv(file_path)\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalizing continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a .txt in data_pre-processing and reload it. \n",
    "continuous_features=list()\n",
    "path_features='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/output/pre-processing/list_continuousFeatures.txt'\n",
    "with open(path_features, 'r') as f:  \n",
    "    for line in f:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        currentPlace = line[:-1]\n",
    "        # add item to the list\n",
    "        continuous_features.append(currentPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSFSPNRT</th>\n",
       "      <th>SMPDSCRD</th>\n",
       "      <th>RBCRSLT</th>\n",
       "      <th>WBCRSLT</th>\n",
       "      <th>TOPRRSLT</th>\n",
       "      <th>TGLCRSLT</th>\n",
       "      <th>SYSSUP</th>\n",
       "      <th>DIASUP</th>\n",
       "      <th>HRSUP</th>\n",
       "      <th>SYSSTND</th>\n",
       "      <th>...</th>\n",
       "      <th>AGE_ASSESS_LNS</th>\n",
       "      <th>DVS_LNS</th>\n",
       "      <th>DVSD_SDM</th>\n",
       "      <th>DVT_SDM</th>\n",
       "      <th>SDMTOTAL</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998.8</td>\n",
       "      <td>0</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>45.4</td>\n",
       "      <td>59.2</td>\n",
       "      <td>152.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2707</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>42.0</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2313</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>48.330002</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1887</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998.8</td>\n",
       "      <td>0</td>\n",
       "      <td>129.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>45.4</td>\n",
       "      <td>59.2</td>\n",
       "      <td>111.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1552</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.400</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1187</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CSFSPNRT  SMPDSCRD  RBCRSLT  WBCRSLT  TOPRRSLT  TGLCRSLT  SYSSUP  DIASUP  \\\n",
       "0    1998.8         0    129.1      2.3      45.4      59.2   152.0    90.0   \n",
       "1    2000.0         0     10.0      1.0      38.0      58.0   139.0    83.0   \n",
       "2    2000.0         0      1.0      1.0      39.0      56.0   119.0    72.0   \n",
       "3    1998.8         0    129.1      2.3      45.4      59.2   111.0    68.0   \n",
       "4    2000.0         0      0.0      0.0      36.0      57.0   128.0    81.0   \n",
       "\n",
       "   HRSUP  SYSSTND       ...         AGE_ASSESS_LNS  DVS_LNS  DVSD_SDM  \\\n",
       "0   64.0    136.0       ...                   64.0     12.0     0.000   \n",
       "1   66.0    124.0       ...                   64.0     12.0     0.000   \n",
       "2   67.0    104.0       ...                   67.0     18.0    -0.167   \n",
       "3   76.0    107.0       ...                   68.0     15.0     0.400   \n",
       "4   79.0    114.0       ...                   69.0     18.0     0.400   \n",
       "\n",
       "     DVT_SDM  SDMTOTAL  PDDXDT_diff_days  PDMEDT_diff_days  \\\n",
       "0  47.000000      42.0               306                 0   \n",
       "1  47.000000      42.0               700                 0   \n",
       "2  48.330002      42.0              1126                 0   \n",
       "3  54.000000      48.0              1461                 0   \n",
       "4  54.000000      48.0              1826                 0   \n",
       "\n",
       "   PDSURGDT_diff_days  lastDate_diff_days  visitsdiff_days  \n",
       "0                   0                2707                0  \n",
       "1                   0                2313              394  \n",
       "2                   0                1887              426  \n",
       "3                   0                1552              335  \n",
       "4                   0                1187              365  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[continuous_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CSFSPNRT</th>\n",
       "      <th>SMPDSCRD</th>\n",
       "      <th>RBCRSLT</th>\n",
       "      <th>WBCRSLT</th>\n",
       "      <th>TOPRRSLT</th>\n",
       "      <th>TGLCRSLT</th>\n",
       "      <th>SYSSUP</th>\n",
       "      <th>DIASUP</th>\n",
       "      <th>HRSUP</th>\n",
       "      <th>SYSSTND</th>\n",
       "      <th>...</th>\n",
       "      <th>AGE_ASSESS_LNS</th>\n",
       "      <th>DVS_LNS</th>\n",
       "      <th>DVSD_SDM</th>\n",
       "      <th>DVT_SDM</th>\n",
       "      <th>SDMTOTAL</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1952.620056</td>\n",
       "      <td>-0.18115</td>\n",
       "      <td>128.747995</td>\n",
       "      <td>2.147378</td>\n",
       "      <td>43.264597</td>\n",
       "      <td>54.002456</td>\n",
       "      <td>144.601095</td>\n",
       "      <td>82.638178</td>\n",
       "      <td>57.726907</td>\n",
       "      <td>128.879238</td>\n",
       "      <td>...</td>\n",
       "      <td>54.965183</td>\n",
       "      <td>6.813539</td>\n",
       "      <td>0.282465</td>\n",
       "      <td>40.982679</td>\n",
       "      <td>37.090282</td>\n",
       "      <td>305.161156</td>\n",
       "      <td>-0.027076</td>\n",
       "      <td>-0.047676</td>\n",
       "      <td>2705.439754</td>\n",
       "      <td>-1.23556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953.820056</td>\n",
       "      <td>-0.18115</td>\n",
       "      <td>9.647995</td>\n",
       "      <td>0.847378</td>\n",
       "      <td>35.864597</td>\n",
       "      <td>52.802456</td>\n",
       "      <td>131.601095</td>\n",
       "      <td>75.638178</td>\n",
       "      <td>59.726907</td>\n",
       "      <td>116.879238</td>\n",
       "      <td>...</td>\n",
       "      <td>54.965183</td>\n",
       "      <td>6.813539</td>\n",
       "      <td>0.282465</td>\n",
       "      <td>40.982679</td>\n",
       "      <td>37.090282</td>\n",
       "      <td>699.161156</td>\n",
       "      <td>-0.027076</td>\n",
       "      <td>-0.047676</td>\n",
       "      <td>2311.439754</td>\n",
       "      <td>392.76444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953.820056</td>\n",
       "      <td>-0.18115</td>\n",
       "      <td>0.647995</td>\n",
       "      <td>0.847378</td>\n",
       "      <td>36.864597</td>\n",
       "      <td>50.802456</td>\n",
       "      <td>111.601095</td>\n",
       "      <td>64.638178</td>\n",
       "      <td>60.726907</td>\n",
       "      <td>96.879238</td>\n",
       "      <td>...</td>\n",
       "      <td>57.965183</td>\n",
       "      <td>12.813539</td>\n",
       "      <td>0.115465</td>\n",
       "      <td>42.312681</td>\n",
       "      <td>37.090282</td>\n",
       "      <td>1125.161156</td>\n",
       "      <td>-0.027076</td>\n",
       "      <td>-0.047676</td>\n",
       "      <td>1885.439754</td>\n",
       "      <td>424.76444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1952.620056</td>\n",
       "      <td>-0.18115</td>\n",
       "      <td>128.747995</td>\n",
       "      <td>2.147378</td>\n",
       "      <td>43.264597</td>\n",
       "      <td>54.002456</td>\n",
       "      <td>103.601095</td>\n",
       "      <td>60.638178</td>\n",
       "      <td>69.726907</td>\n",
       "      <td>99.879238</td>\n",
       "      <td>...</td>\n",
       "      <td>58.965183</td>\n",
       "      <td>9.813539</td>\n",
       "      <td>0.682465</td>\n",
       "      <td>47.982679</td>\n",
       "      <td>43.090282</td>\n",
       "      <td>1460.161156</td>\n",
       "      <td>-0.027076</td>\n",
       "      <td>-0.047676</td>\n",
       "      <td>1550.439754</td>\n",
       "      <td>333.76444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953.820056</td>\n",
       "      <td>-0.18115</td>\n",
       "      <td>-0.352005</td>\n",
       "      <td>-0.152622</td>\n",
       "      <td>33.864597</td>\n",
       "      <td>51.802456</td>\n",
       "      <td>120.601095</td>\n",
       "      <td>73.638178</td>\n",
       "      <td>72.726907</td>\n",
       "      <td>106.879238</td>\n",
       "      <td>...</td>\n",
       "      <td>59.965183</td>\n",
       "      <td>12.813539</td>\n",
       "      <td>0.682465</td>\n",
       "      <td>47.982679</td>\n",
       "      <td>43.090282</td>\n",
       "      <td>1825.161156</td>\n",
       "      <td>-0.027076</td>\n",
       "      <td>-0.047676</td>\n",
       "      <td>1185.439754</td>\n",
       "      <td>363.76444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CSFSPNRT  SMPDSCRD     RBCRSLT   WBCRSLT   TOPRRSLT   TGLCRSLT  \\\n",
       "0  1952.620056  -0.18115  128.747995  2.147378  43.264597  54.002456   \n",
       "1  1953.820056  -0.18115    9.647995  0.847378  35.864597  52.802456   \n",
       "2  1953.820056  -0.18115    0.647995  0.847378  36.864597  50.802456   \n",
       "3  1952.620056  -0.18115  128.747995  2.147378  43.264597  54.002456   \n",
       "4  1953.820056  -0.18115   -0.352005 -0.152622  33.864597  51.802456   \n",
       "\n",
       "       SYSSUP     DIASUP      HRSUP     SYSSTND       ...         \\\n",
       "0  144.601095  82.638178  57.726907  128.879238       ...          \n",
       "1  131.601095  75.638178  59.726907  116.879238       ...          \n",
       "2  111.601095  64.638178  60.726907   96.879238       ...          \n",
       "3  103.601095  60.638178  69.726907   99.879238       ...          \n",
       "4  120.601095  73.638178  72.726907  106.879238       ...          \n",
       "\n",
       "   AGE_ASSESS_LNS    DVS_LNS  DVSD_SDM    DVT_SDM   SDMTOTAL  \\\n",
       "0       54.965183   6.813539  0.282465  40.982679  37.090282   \n",
       "1       54.965183   6.813539  0.282465  40.982679  37.090282   \n",
       "2       57.965183  12.813539  0.115465  42.312681  37.090282   \n",
       "3       58.965183   9.813539  0.682465  47.982679  43.090282   \n",
       "4       59.965183  12.813539  0.682465  47.982679  43.090282   \n",
       "\n",
       "   PDDXDT_diff_days  PDMEDT_diff_days  PDSURGDT_diff_days  lastDate_diff_days  \\\n",
       "0        305.161156         -0.027076           -0.047676         2705.439754   \n",
       "1        699.161156         -0.027076           -0.047676         2311.439754   \n",
       "2       1125.161156         -0.027076           -0.047676         1885.439754   \n",
       "3       1460.161156         -0.027076           -0.047676         1550.439754   \n",
       "4       1825.161156         -0.027076           -0.047676         1185.439754   \n",
       "\n",
       "   visitsdiff_days  \n",
       "0         -1.23556  \n",
       "1        392.76444  \n",
       "2        424.76444  \n",
       "3        333.76444  \n",
       "4        363.76444  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if relevant to do normalization for engineered features - standardization better? \n",
    "\n",
    "df[continuous_features]=df[continuous_features].apply(lambda x: x-np.mean(x)/np.std(x))\n",
    "df[continuous_features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection only patients with more than one visit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8597408026755853\n",
      "samples lost: 671\n"
     ]
    }
   ],
   "source": [
    "df_2visits=df[df.num_visits>=2]\n",
    "print(len(df_2visits)/len(df))\n",
    "print('samples lost: {}'.format((df.shape[0]-df_2visits.shape[0])))\n",
    "assert len(df_2visits[df_2visits['num_visits']==1])==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding visit sequences for a sequence_length=4 - custom function TO CORRECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows_to_pad(df, num_visits, visit_ID):\n",
    "    subdf=df[df['num_visits']==num_visits]\n",
    "    rowstoAdd=subdf.groupby('PATNO').median() \n",
    "\n",
    "    # Changing the value of the engineered features\n",
    "    Engineered_features_max=['PDDXDT_diff_days','PDMEDT_diff_days','PDSURGDT_diff_days']\n",
    "    Engineered_features_min='lastDate_diff_days'\n",
    "    rowstoAdd[Engineered_features_max]=subdf.groupby('PATNO').max()[Engineered_features_max]\n",
    "    rowstoAdd[Engineered_features_min]=subdf.groupby('PATNO').min()[Engineered_features_min]\n",
    "    rowstoAdd['VISIT_ID']=visit_ID\n",
    "    rowstoAdd['visitsdiff_days']=3*61 # we assume that the visit we add is three months later\n",
    "\n",
    "    # updating the engineered values features\n",
    "    rowstoAdd['lastDate_diff_days']=rowstoAdd['lastDate_diff_days']-rowstoAdd['visitsdiff_days']\n",
    "    rowstoAdd['PDDXDT_diff_days']=rowstoAdd['PDDXDT_diff_days'].where(rowstoAdd['PDDXDT_diff_days']==0,\n",
    "                                                                     rowstoAdd['PDDXDT_diff_days']+rowstoAdd['visitsdiff_days'])\n",
    "    maskMED=rowstoAdd['PDMEDT_diff_days']!=0\n",
    "    rowstoAdd.loc[maskMED,'PDMEDT_diff_days']=rowstoAdd.loc[maskMED,'PDMEDT_diff_days']+rowstoAdd.loc[maskMED,'visitsdiff_days']\n",
    "    maskSURG=rowstoAdd['PDSURGDT_diff_days']!=0\n",
    "    rowstoAdd.loc[maskSURG,'PDSURGDT_diff_days']=rowstoAdd.loc[maskSURG,'PDSURGDT_diff_days']+rowstoAdd.loc[maskSURG,'visitsdiff_days']\n",
    "    \n",
    "    return rowstoAdd\n",
    "\n",
    "def padding_visits_PPMI(df, seq_length=4):\n",
    "\n",
    "    #number of visits==2\n",
    "    ## Visit_ID=3\n",
    "    rowstoAdd=rows_to_pad(df,num_visits=2,visit_ID=3)\n",
    "    \n",
    "    #Number of visits==2\n",
    "    ##Visit_ID==4\n",
    "    rowstoAdd2=rows_to_pad(df,num_visits=2,visit_ID=4)\n",
    "    \n",
    "    #Number of visits==3, visit_ID=4\n",
    "    rowstoAdd3=rows_to_pad(df,num_visits=3,visit_ID=4)\n",
    "\n",
    "    # concatenating all the rows to add\n",
    "    rowspadding=pd.concat([rowstoAdd,rowstoAdd2,rowstoAdd3])\n",
    "    rowspadding['num_visits']=4\n",
    "    rowspadding.reset_index(inplace=True)\n",
    "    #print(rowspadding.shape)\n",
    "\n",
    "    # reformatting final df\n",
    "    dfpad_th4=df.drop(columns=['INFODT_date','INFODT','EVENT_ID'])\n",
    "    dfpad_th4=pd.concat([dfpad_th4,rowspadding])\n",
    "    # updating the new number of visits for the padded sequences\n",
    "    dfpad_th4['num_visits'].replace(2,4,inplace=True)\n",
    "    dfpad_th4['num_visits'].replace(3,4,inplace=True)\n",
    "    dfpad_th4.reset_index(drop=True,inplace=True)\n",
    "    dfpad_th4['NHY']=dfpad_th4['NHY'].apply(lambda x: round(x,0)) \n",
    "    # APPLY ROUND TO ALL VARIABLE INSTEAD?\n",
    "    dfpad_th4.sort_values(['PATNO','VISIT_ID'],inplace=True)\n",
    "    print('df final shape: {}'.format(dfpad_th4.shape))\n",
    "    print('number final of patients:{}'.format(len(set(dfpad_th4['PATNO']))))\n",
    "    \n",
    "    return dfpad_th4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df final shape: (4887, 375)\n",
      "number final of patients:1003\n"
     ]
    }
   ],
   "source": [
    "df_4visits=padding_visits_PPMI(df_2visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>NP1COG</th>\n",
       "      <th>NP1HALL</th>\n",
       "      <th>NP1DPRS</th>\n",
       "      <th>NP1ANXS</th>\n",
       "      <th>NP1APAT</th>\n",
       "      <th>NP1DDS</th>\n",
       "      <th>NP2SPCH</th>\n",
       "      <th>NP2SALV</th>\n",
       "      <th>NP2SWAL</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2707</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2313</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>426</td>\n",
       "      <td>1887</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>335</td>\n",
       "      <td>1552</td>\n",
       "      <td>1461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "      <td>1187</td>\n",
       "      <td>1826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 375 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATNO  NP1COG  NP1HALL  NP1DPRS  NP1ANXS  NP1APAT  NP1DDS  NP2SPCH  \\\n",
       "0   3001     0.0      0.0      0.0      1.0      0.0     0.0      0.0   \n",
       "1   3001     1.0      0.0      1.0      1.0      1.0     0.0      0.0   \n",
       "2   3001     0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
       "3   3001     0.0      0.0      0.0      1.0      0.0     0.0      0.0   \n",
       "4   3001     0.0      0.0      0.0      1.0      0.0     0.0      0.0   \n",
       "\n",
       "   NP2SALV  NP2SWAL         ...          DXPOSINS  DXOTHSX  DOMSIDE  \\\n",
       "0      0.0      0.0         ...               0.0      0.0      2.0   \n",
       "1      0.0      0.0         ...               0.0      0.0      2.0   \n",
       "2      0.0      0.0         ...               0.0      0.0      2.0   \n",
       "3      0.0      0.0         ...               0.0      0.0      2.0   \n",
       "4      0.0      1.0         ...               0.0      0.0      2.0   \n",
       "\n",
       "   num_visits  VISIT_ID  visitsdiff_days  lastDate_diff_days  \\\n",
       "0           7         1                0                2707   \n",
       "1           7         2              394                2313   \n",
       "2           7         3              426                1887   \n",
       "3           7         4              335                1552   \n",
       "4           7         5              365                1187   \n",
       "\n",
       "   PDDXDT_diff_days  PDMEDT_diff_days  PDSURGDT_diff_days  \n",
       "0               306                 0                   0  \n",
       "1               700                 0                   0  \n",
       "2              1126                 0                   0  \n",
       "3              1461                 0                   0  \n",
       "4              1826                 0                   0  \n",
       "\n",
       "[5 rows x 375 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NP1COG</th>\n",
       "      <th>NP1HALL</th>\n",
       "      <th>NP1DPRS</th>\n",
       "      <th>NP1ANXS</th>\n",
       "      <th>NP1APAT</th>\n",
       "      <th>NP1DDS</th>\n",
       "      <th>NP2SPCH</th>\n",
       "      <th>NP2SALV</th>\n",
       "      <th>NP2SWAL</th>\n",
       "      <th>NP2EAT</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[0, 394, 426, 335, 365, 427, 638]</td>\n",
       "      <td>[2707, 2313, 1887, 1552, 1187, 760, 122]</td>\n",
       "      <td>[306, 700, 1126, 1461, 1826, 2253, 2891]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3002</th>\n",
       "      <td>[1.0, 1.0, 2.0, 1.0, 2.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 3.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 2.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 2.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 2.0, 1.0, 2.0, 0.0, 2.0]</td>\n",
       "      <td>[0.0, 2.0, 1.0, 3.0, 3.0, 3.0]</td>\n",
       "      <td>[0.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 2.0, 1.0, 1.0, 2.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[0, 397, 365, 699, 397, 730]</td>\n",
       "      <td>[2679, 2282, 1917, 1218, 821, 91]</td>\n",
       "      <td>[393, 790, 1155, 1854, 2251, 2981]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3003</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]</td>\n",
       "      <td>[7, 7, 7, 7, 7, 7, 7]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7]</td>\n",
       "      <td>[0, 397, 365, 365, 365, 366, 365]</td>\n",
       "      <td>[2679, 2282, 1917, 1552, 1187, 821, 456]</td>\n",
       "      <td>[730, 1127, 1492, 1857, 2222, 2588, 2953]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.5, 0.5]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.0, 3.0, 2.5, 2.5]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0]</td>\n",
       "      <td>[4, 4, 4, 4]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>[0, 427, 183, 183]</td>\n",
       "      <td>[2679, 2252, 2069, 2069]</td>\n",
       "      <td>[120, 547, 730, 730]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>[1.0, 0.0, 0.0, 1.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 1.0, 0.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 3.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 2.0, 2.0, 1.0, 2.0]</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 2.0, 3.0, 2.0, 2.0, 3.0]</td>\n",
       "      <td>[1.0, 2.0, 3.0, 2.0, 2.0, 3.0]</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>[0.0, 1.0, 2.0, 2.0, 1.0, 1.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6]</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[30, 397, 395, 427, 273, 519]</td>\n",
       "      <td>[2618, 2221, 1826, 1399, 1126, 607]</td>\n",
       "      <td>[89, 486, 881, 1308, 1581, 2100]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 374 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    NP1COG  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]   \n",
       "3002        [1.0, 1.0, 2.0, 1.0, 2.0, 1.0]   \n",
       "3003   [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [1.0, 0.0, 0.0, 1.0, 0.0, 1.0]   \n",
       "\n",
       "                                   NP1HALL  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "3003   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [0.0, 1.0, 0.0, 0.0, 1.0, 0.0]   \n",
       "\n",
       "                                   NP1DPRS  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]   \n",
       "3002        [1.0, 1.0, 3.0, 0.0, 1.0, 1.0]   \n",
       "3003   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3006                  [0.0, 1.0, 0.5, 0.5]   \n",
       "3010        [0.0, 1.0, 0.0, 3.0, 0.0, 0.0]   \n",
       "\n",
       "                                   NP1ANXS  \\\n",
       "PATNO                                        \n",
       "3001   [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3002        [1.0, 1.0, 1.0, 2.0, 1.0, 1.0]   \n",
       "3003   [0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0]   \n",
       "3006                  [1.0, 1.0, 1.0, 1.0]   \n",
       "3010        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                   NP1APAT  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [0.0, 0.0, 2.0, 0.0, 0.0, 1.0]   \n",
       "3003   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [1.0, 1.0, 2.0, 2.0, 1.0, 2.0]   \n",
       "\n",
       "                                    NP1DDS  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [0.0, 0.0, 0.0, 1.0, 0.0, 0.0]   \n",
       "3003   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                   NP2SPCH  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [1.0, 2.0, 1.0, 2.0, 0.0, 2.0]   \n",
       "3003   [0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0]   \n",
       "3006                  [2.0, 3.0, 2.5, 2.5]   \n",
       "3010        [1.0, 2.0, 3.0, 2.0, 2.0, 3.0]   \n",
       "\n",
       "                                   NP2SALV  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [0.0, 2.0, 1.0, 3.0, 3.0, 3.0]   \n",
       "3003   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [1.0, 2.0, 3.0, 2.0, 2.0, 3.0]   \n",
       "\n",
       "                                   NP2SWAL  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]   \n",
       "3002        [0.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3003   [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3006                  [1.0, 1.0, 1.0, 1.0]   \n",
       "3010        [0.0, 0.0, 1.0, 0.0, 0.0, 1.0]   \n",
       "\n",
       "                                    NP2EAT          ...            \\\n",
       "PATNO                                               ...             \n",
       "3001   [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]          ...             \n",
       "3002        [1.0, 2.0, 1.0, 1.0, 2.0, 1.0]          ...             \n",
       "3003   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]          ...             \n",
       "3006                  [1.0, 1.0, 1.0, 1.0]          ...             \n",
       "3010        [0.0, 1.0, 2.0, 2.0, 1.0, 1.0]          ...             \n",
       "\n",
       "                                  DXPOSINS  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3003   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                   DXOTHSX  \\\n",
       "PATNO                                        \n",
       "3001   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3002        [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3003   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]   \n",
       "3006                  [0.0, 0.0, 0.0, 0.0]   \n",
       "3010        [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                   DOMSIDE             num_visits  \\\n",
       "PATNO                                                               \n",
       "3001   [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]  [7, 7, 7, 7, 7, 7, 7]   \n",
       "3002        [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]     [6, 6, 6, 6, 6, 6]   \n",
       "3003   [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]  [7, 7, 7, 7, 7, 7, 7]   \n",
       "3006                  [2.0, 2.0, 2.0, 2.0]           [4, 4, 4, 4]   \n",
       "3010        [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]     [6, 6, 6, 6, 6, 6]   \n",
       "\n",
       "                    VISIT_ID                    visitsdiff_days  \\\n",
       "PATNO                                                             \n",
       "3001   [1, 2, 3, 4, 5, 6, 7]  [0, 394, 426, 335, 365, 427, 638]   \n",
       "3002      [1, 2, 3, 4, 5, 6]       [0, 397, 365, 699, 397, 730]   \n",
       "3003   [1, 2, 3, 4, 5, 6, 7]  [0, 397, 365, 365, 365, 366, 365]   \n",
       "3006            [1, 2, 3, 4]                 [0, 427, 183, 183]   \n",
       "3010      [1, 2, 3, 4, 5, 6]      [30, 397, 395, 427, 273, 519]   \n",
       "\n",
       "                             lastDate_diff_days  \\\n",
       "PATNO                                             \n",
       "3001   [2707, 2313, 1887, 1552, 1187, 760, 122]   \n",
       "3002          [2679, 2282, 1917, 1218, 821, 91]   \n",
       "3003   [2679, 2282, 1917, 1552, 1187, 821, 456]   \n",
       "3006                   [2679, 2252, 2069, 2069]   \n",
       "3010        [2618, 2221, 1826, 1399, 1126, 607]   \n",
       "\n",
       "                                PDDXDT_diff_days       PDMEDT_diff_days  \\\n",
       "PATNO                                                                     \n",
       "3001    [306, 700, 1126, 1461, 1826, 2253, 2891]  [0, 0, 0, 0, 0, 0, 0]   \n",
       "3002          [393, 790, 1155, 1854, 2251, 2981]     [0, 0, 0, 0, 0, 0]   \n",
       "3003   [730, 1127, 1492, 1857, 2222, 2588, 2953]  [0, 0, 0, 0, 0, 0, 0]   \n",
       "3006                        [120, 547, 730, 730]           [0, 0, 0, 0]   \n",
       "3010            [89, 486, 881, 1308, 1581, 2100]     [0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "          PDSURGDT_diff_days  \n",
       "PATNO                         \n",
       "3001   [0, 0, 0, 0, 0, 0, 0]  \n",
       "3002      [0, 0, 0, 0, 0, 0]  \n",
       "3003   [0, 0, 0, 0, 0, 0, 0]  \n",
       "3006            [0, 0, 0, 0]  \n",
       "3010      [0, 0, 0, 0, 0, 0]  \n",
       "\n",
       "[5 rows x 374 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# caution: to pad/trucate sequences, you need to reshape your data first\n",
    "cols=list(df_4visits.columns)\n",
    "cols.remove('PATNO')\n",
    "df_reshaped=pd.DataFrame()\n",
    "for col in cols:\n",
    "    ser_col=df_4visits.groupby('PATNO')[col].apply(list)\n",
    "    keys=list(df.columns).append(col)\n",
    "    df_reshaped=pd.concat([df_reshaped,ser_col],axis=1,keys=keys)\n",
    "\n",
    "df_reshaped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1003,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=df_reshaped['NHY']\n",
    "data=df_reshaped.values\n",
    "\n",
    "target_truncated=pad_sequences(target,maxlen=4)\n",
    "target_final=target_truncated[:,3]\n",
    "#target_final.reshape((target_final.shape[0],1))\n",
    "target_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    1],\n",
       "       [   0,    0,    0],\n",
       "       [   0,    0,    1],\n",
       "       ...,\n",
       "       [1461, 1826, 2253],\n",
       "       [   0,    0,    0],\n",
       "       [   0,    0,    0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_truncated=np.zeros(shape=(data.shape[0],data.shape[1],3),dtype=int)\n",
    "for i in range(data.shape[1]):\n",
    "    # take the last 4 sequences\n",
    "    seq_truncated_col=pad_sequences(data[:,i],maxlen=4)\n",
    "    # remove the last sequence (visit to predict)\n",
    "    seq_truncated_col=pad_sequences(seq_truncated_col,maxlen=3,truncating='post')\n",
    "    data_truncated[:,i]=seq_truncated_col\n",
    "data_truncated[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1003, 374, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1003, 3, 374)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_truncated.shape)\n",
    "data_final=np.transpose(data_truncated,axes=(0,2,1))\n",
    "data_final.shape # final data shape: (num_of_samples, number_of_timesteps, number of features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(target_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the dataset train/test/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.cross_validation as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1003, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "target_final=to_categorical(target_final,num_classes=6,dtype='int32')\n",
    "print(target_final.shape)\n",
    "target_final[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(802, 3, 374)\n",
      "(201, 3, 374)\n",
      "(802, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test=train_test_split(data_final, test_size=0.2, random_state=0)\n",
    "y_train, y_test=train_test_split(target_final, test_size=0.2, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM model (simple vanilla LSTM model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 50)                85000     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 85,306\n",
      "Trainable params: 85,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "n_class=6\n",
    "seq_length=3\n",
    "n_features=374\n",
    "\n",
    "### hyperparameters to optimize\n",
    "optimizer='adam'\n",
    "input_units=50\n",
    "n_epochs=50\n",
    "batch_size=8\n",
    "\n",
    "model=Sequential()\n",
    "model.add(LSTM(input_units, input_shape=(seq_length,n_features)))\n",
    "model.add(Dense(n_class, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 641 samples, validate on 161 samples\n",
      "Epoch 1/100\n",
      "641/641 [==============================] - 3s 5ms/step - loss: 1.1487 - acc: 0.6583 - val_loss: 0.8752 - val_acc: 0.8012\n",
      "Epoch 2/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.8416 - acc: 0.7707 - val_loss: 0.7743 - val_acc: 0.8012\n",
      "Epoch 3/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7841 - acc: 0.7785 - val_loss: 0.7290 - val_acc: 0.7888\n",
      "Epoch 4/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7611 - acc: 0.7800 - val_loss: 0.7217 - val_acc: 0.7888\n",
      "Epoch 5/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7477 - acc: 0.7832 - val_loss: 0.7320 - val_acc: 0.7888\n",
      "Epoch 6/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7485 - acc: 0.7800 - val_loss: 0.7467 - val_acc: 0.7764\n",
      "Epoch 7/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7477 - acc: 0.7800 - val_loss: 0.7675 - val_acc: 0.7826\n",
      "Epoch 8/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7469 - acc: 0.7769 - val_loss: 0.7198 - val_acc: 0.7888\n",
      "Epoch 9/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7317 - acc: 0.7816 - val_loss: 0.7391 - val_acc: 0.7826\n",
      "Epoch 10/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7336 - acc: 0.7816 - val_loss: 0.7254 - val_acc: 0.7888\n",
      "Epoch 11/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7347 - acc: 0.7816 - val_loss: 0.7246 - val_acc: 0.7888\n",
      "Epoch 12/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7305 - acc: 0.7800 - val_loss: 0.7352 - val_acc: 0.7888\n",
      "Epoch 13/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7283 - acc: 0.7832 - val_loss: 0.7286 - val_acc: 0.7888\n",
      "Epoch 14/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7389 - acc: 0.7832 - val_loss: 0.7297 - val_acc: 0.7888\n",
      "Epoch 15/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7293 - acc: 0.7847 - val_loss: 0.7398 - val_acc: 0.7950\n",
      "Epoch 16/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7345 - acc: 0.7847 - val_loss: 0.7484 - val_acc: 0.7888\n",
      "Epoch 17/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7330 - acc: 0.7847 - val_loss: 0.7382 - val_acc: 0.7888\n",
      "Epoch 18/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7354 - acc: 0.7847 - val_loss: 0.7426 - val_acc: 0.7888\n",
      "Epoch 19/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7288 - acc: 0.7847 - val_loss: 0.7383 - val_acc: 0.7888\n",
      "Epoch 20/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7317 - acc: 0.7847 - val_loss: 0.7403 - val_acc: 0.7888\n",
      "Epoch 21/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7328 - acc: 0.7847 - val_loss: 0.7414 - val_acc: 0.7888\n",
      "Epoch 22/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7359 - acc: 0.7847 - val_loss: 0.7421 - val_acc: 0.7888\n",
      "Epoch 23/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7368 - acc: 0.7847 - val_loss: 0.7203 - val_acc: 0.7888\n",
      "Epoch 24/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7274 - acc: 0.7863 - val_loss: 0.7220 - val_acc: 0.7888\n",
      "Epoch 25/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7296 - acc: 0.7863 - val_loss: 0.7209 - val_acc: 0.7888\n",
      "Epoch 26/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7252 - acc: 0.7847 - val_loss: 0.7306 - val_acc: 0.7888\n",
      "Epoch 27/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7260 - acc: 0.7847 - val_loss: 0.7248 - val_acc: 0.7888\n",
      "Epoch 28/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7237 - acc: 0.7863 - val_loss: 0.7231 - val_acc: 0.7888\n",
      "Epoch 29/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7290 - acc: 0.7863 - val_loss: 0.7305 - val_acc: 0.7888\n",
      "Epoch 30/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7324 - acc: 0.7847 - val_loss: 0.7387 - val_acc: 0.7888\n",
      "Epoch 31/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7270 - acc: 0.7863 - val_loss: 0.7286 - val_acc: 0.7888\n",
      "Epoch 32/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7272 - acc: 0.7863 - val_loss: 0.7192 - val_acc: 0.7888\n",
      "Epoch 33/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7319 - acc: 0.7847 - val_loss: 0.7446 - val_acc: 0.7888\n",
      "Epoch 34/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7358 - acc: 0.7847 - val_loss: 0.7280 - val_acc: 0.7888\n",
      "Epoch 35/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7233 - acc: 0.7863 - val_loss: 0.7249 - val_acc: 0.7888\n",
      "Epoch 36/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7269 - acc: 0.7863 - val_loss: 0.7315 - val_acc: 0.7888\n",
      "Epoch 37/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7173 - acc: 0.7878 - val_loss: 0.7308 - val_acc: 0.7888\n",
      "Epoch 38/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7224 - acc: 0.7878 - val_loss: 0.7149 - val_acc: 0.7888\n",
      "Epoch 39/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7216 - acc: 0.7878 - val_loss: 0.7374 - val_acc: 0.7888\n",
      "Epoch 40/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7309 - acc: 0.7878 - val_loss: 0.7400 - val_acc: 0.7888\n",
      "Epoch 41/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7272 - acc: 0.7863 - val_loss: 0.7325 - val_acc: 0.7888\n",
      "Epoch 42/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7269 - acc: 0.7878 - val_loss: 0.7360 - val_acc: 0.7888\n",
      "Epoch 43/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7238 - acc: 0.7863 - val_loss: 0.7239 - val_acc: 0.7888\n",
      "Epoch 44/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7223 - acc: 0.7878 - val_loss: 0.7372 - val_acc: 0.7888\n",
      "Epoch 45/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7435 - acc: 0.7878 - val_loss: 0.7463 - val_acc: 0.7888\n",
      "Epoch 46/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7290 - acc: 0.7863 - val_loss: 0.7448 - val_acc: 0.7888\n",
      "Epoch 47/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7314 - acc: 0.7863 - val_loss: 0.7291 - val_acc: 0.7888\n",
      "Epoch 48/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7294 - acc: 0.7878 - val_loss: 0.7314 - val_acc: 0.7888\n",
      "Epoch 49/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7245 - acc: 0.7878 - val_loss: 0.7245 - val_acc: 0.7888\n",
      "Epoch 50/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7282 - acc: 0.7878 - val_loss: 0.7332 - val_acc: 0.7888\n",
      "Epoch 51/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7350 - acc: 0.7878 - val_loss: 0.7254 - val_acc: 0.7888\n",
      "Epoch 52/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7261 - acc: 0.7878 - val_loss: 0.7310 - val_acc: 0.7888\n",
      "Epoch 53/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7204 - acc: 0.7894 - val_loss: 0.7291 - val_acc: 0.7888\n",
      "Epoch 54/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7201 - acc: 0.7878 - val_loss: 0.7127 - val_acc: 0.7888\n",
      "Epoch 55/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7234 - acc: 0.7863 - val_loss: 0.7209 - val_acc: 0.7888\n",
      "Epoch 56/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7350 - acc: 0.7863 - val_loss: 0.7261 - val_acc: 0.7888\n",
      "Epoch 57/100\n",
      "641/641 [==============================] - 1s 986us/step - loss: 0.7262 - acc: 0.7863 - val_loss: 0.7341 - val_acc: 0.7888\n",
      "Epoch 58/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7264 - acc: 0.7863 - val_loss: 0.7204 - val_acc: 0.7888\n",
      "Epoch 59/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7268 - acc: 0.7863 - val_loss: 0.7192 - val_acc: 0.7888\n",
      "Epoch 60/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7285 - acc: 0.7863 - val_loss: 0.7168 - val_acc: 0.7888\n",
      "Epoch 61/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7206 - acc: 0.7863 - val_loss: 0.7180 - val_acc: 0.7888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.7263 - acc: 0.7863 - val_loss: 0.7167 - val_acc: 0.7888\n",
      "Epoch 63/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7228 - acc: 0.7878 - val_loss: 0.7151 - val_acc: 0.7888\n",
      "Epoch 64/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7267 - acc: 0.7863 - val_loss: 0.7305 - val_acc: 0.7888\n",
      "Epoch 65/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7265 - acc: 0.7863 - val_loss: 0.7254 - val_acc: 0.7888\n",
      "Epoch 66/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7289 - acc: 0.7878 - val_loss: 0.7401 - val_acc: 0.7888\n",
      "Epoch 67/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7234 - acc: 0.7878 - val_loss: 0.7149 - val_acc: 0.7888\n",
      "Epoch 68/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7136 - acc: 0.7894 - val_loss: 0.7275 - val_acc: 0.7888\n",
      "Epoch 69/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7247 - acc: 0.7863 - val_loss: 0.7179 - val_acc: 0.7888\n",
      "Epoch 70/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7213 - acc: 0.7878 - val_loss: 0.7184 - val_acc: 0.7888\n",
      "Epoch 71/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7154 - acc: 0.7863 - val_loss: 0.7140 - val_acc: 0.7888\n",
      "Epoch 72/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7198 - acc: 0.7863 - val_loss: 0.7078 - val_acc: 0.7888\n",
      "Epoch 73/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7191 - acc: 0.7863 - val_loss: 0.7062 - val_acc: 0.7888\n",
      "Epoch 74/100\n",
      "641/641 [==============================] - 1s 961us/step - loss: 0.7220 - acc: 0.7863 - val_loss: 0.7167 - val_acc: 0.7888\n",
      "Epoch 75/100\n",
      "641/641 [==============================] - 1s 960us/step - loss: 0.7238 - acc: 0.7878 - val_loss: 0.7360 - val_acc: 0.7888\n",
      "Epoch 76/100\n",
      "641/641 [==============================] - 1s 977us/step - loss: 0.7314 - acc: 0.7863 - val_loss: 0.7442 - val_acc: 0.7888\n",
      "Epoch 77/100\n",
      "641/641 [==============================] - 1s 954us/step - loss: 0.7262 - acc: 0.7863 - val_loss: 0.7286 - val_acc: 0.7888\n",
      "Epoch 78/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7208 - acc: 0.7863 - val_loss: 0.7169 - val_acc: 0.7888\n",
      "Epoch 79/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7288 - acc: 0.7878 - val_loss: 0.7294 - val_acc: 0.7888\n",
      "Epoch 80/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7331 - acc: 0.7878 - val_loss: 0.7403 - val_acc: 0.7888\n",
      "Epoch 81/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7334 - acc: 0.7878 - val_loss: 0.7357 - val_acc: 0.7888\n",
      "Epoch 82/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7327 - acc: 0.7878 - val_loss: 0.7346 - val_acc: 0.7888\n",
      "Epoch 83/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7313 - acc: 0.7878 - val_loss: 0.7122 - val_acc: 0.7888\n",
      "Epoch 84/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7294 - acc: 0.7863 - val_loss: 0.7363 - val_acc: 0.7888\n",
      "Epoch 85/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7309 - acc: 0.7878 - val_loss: 0.7393 - val_acc: 0.7888\n",
      "Epoch 86/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7358 - acc: 0.7863 - val_loss: 0.7360 - val_acc: 0.7888\n",
      "Epoch 87/100\n",
      "641/641 [==============================] - 1s 995us/step - loss: 0.7305 - acc: 0.7878 - val_loss: 0.7320 - val_acc: 0.7888\n",
      "Epoch 88/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7317 - acc: 0.7863 - val_loss: 0.7317 - val_acc: 0.7888\n",
      "Epoch 89/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7334 - acc: 0.7863 - val_loss: 0.7387 - val_acc: 0.7888\n",
      "Epoch 90/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7351 - acc: 0.7863 - val_loss: 0.7327 - val_acc: 0.7888\n",
      "Epoch 91/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7259 - acc: 0.7863 - val_loss: 0.7090 - val_acc: 0.7888\n",
      "Epoch 92/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7192 - acc: 0.7863 - val_loss: 0.7039 - val_acc: 0.7888\n",
      "Epoch 93/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7183 - acc: 0.7847 - val_loss: 0.7138 - val_acc: 0.7888\n",
      "Epoch 94/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7227 - acc: 0.7863 - val_loss: 0.7180 - val_acc: 0.7888\n",
      "Epoch 95/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7282 - acc: 0.7863 - val_loss: 0.7199 - val_acc: 0.7888\n",
      "Epoch 96/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7244 - acc: 0.7863 - val_loss: 0.7218 - val_acc: 0.7888\n",
      "Epoch 97/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7215 - acc: 0.7863 - val_loss: 0.7249 - val_acc: 0.7888\n",
      "Epoch 98/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7184 - acc: 0.7863 - val_loss: 0.7219 - val_acc: 0.7888\n",
      "Epoch 99/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7181 - acc: 0.7863 - val_loss: 0.7219 - val_acc: 0.7888\n",
      "Epoch 100/100\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7160 - acc: 0.7863 - val_loss: 0.7193 - val_acc: 0.7888\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, y_train, batch_size=batch_size,epochs=n_epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding a regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 50)                85000     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 85,306\n",
      "Trainable params: 85,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "model_reg=Sequential()\n",
    "model_reg.add(LSTM(input_units, input_shape=(seq_length,n_features)))\n",
    "model_reg.add(Dense(n_class, activation='softmax',kernel_regularizer=regularizers.l2(0.001)))\n",
    "model_reg.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "print(model_reg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 641 samples, validate on 161 samples\n",
      "Epoch 1/50\n",
      "641/641 [==============================] - 3s 5ms/step - loss: 1.4224 - acc: 0.4680 - val_loss: 1.0124 - val_acc: 0.7205\n",
      "Epoch 2/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.9858 - acc: 0.7566 - val_loss: 0.8536 - val_acc: 0.7826\n",
      "Epoch 3/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.8620 - acc: 0.7800 - val_loss: 0.7976 - val_acc: 0.7888\n",
      "Epoch 4/50\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.8170 - acc: 0.7832 - val_loss: 0.7652 - val_acc: 0.7888\n",
      "Epoch 5/50\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.7943 - acc: 0.7816 - val_loss: 0.7639 - val_acc: 0.7888\n",
      "Epoch 6/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7842 - acc: 0.7832 - val_loss: 0.7431 - val_acc: 0.7888\n",
      "Epoch 7/50\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.7687 - acc: 0.7832 - val_loss: 0.7406 - val_acc: 0.7888\n",
      "Epoch 8/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7521 - acc: 0.7816 - val_loss: 0.7253 - val_acc: 0.7888\n",
      "Epoch 9/50\n",
      "641/641 [==============================] - 1s 2ms/step - loss: 0.7490 - acc: 0.7816 - val_loss: 0.7339 - val_acc: 0.7888\n",
      "Epoch 10/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7345 - acc: 0.7832 - val_loss: 0.7157 - val_acc: 0.7888\n",
      "Epoch 11/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7646 - acc: 0.7816 - val_loss: 0.7357 - val_acc: 0.7888\n",
      "Epoch 12/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7549 - acc: 0.7816 - val_loss: 0.7322 - val_acc: 0.7888\n",
      "Epoch 13/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7495 - acc: 0.7832 - val_loss: 0.7290 - val_acc: 0.7888\n",
      "Epoch 14/50\n",
      "641/641 [==============================] - 1s 999us/step - loss: 0.7509 - acc: 0.7816 - val_loss: 0.7328 - val_acc: 0.7888\n",
      "Epoch 15/50\n",
      "641/641 [==============================] - 1s 974us/step - loss: 0.7462 - acc: 0.7847 - val_loss: 0.7310 - val_acc: 0.7888\n",
      "Epoch 16/50\n",
      "641/641 [==============================] - 1s 976us/step - loss: 0.7380 - acc: 0.7816 - val_loss: 0.7263 - val_acc: 0.7888\n",
      "Epoch 17/50\n",
      "641/641 [==============================] - 1s 962us/step - loss: 0.7400 - acc: 0.7832 - val_loss: 0.7304 - val_acc: 0.7888\n",
      "Epoch 18/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7448 - acc: 0.7847 - val_loss: 0.7316 - val_acc: 0.7888\n",
      "Epoch 19/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7380 - acc: 0.7847 - val_loss: 0.7328 - val_acc: 0.7888\n",
      "Epoch 20/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7391 - acc: 0.7816 - val_loss: 0.7176 - val_acc: 0.7888\n",
      "Epoch 21/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7363 - acc: 0.7832 - val_loss: 0.7229 - val_acc: 0.7888\n",
      "Epoch 22/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7320 - acc: 0.7816 - val_loss: 0.7236 - val_acc: 0.7888\n",
      "Epoch 23/50\n",
      "641/641 [==============================] - 1s 947us/step - loss: 0.7337 - acc: 0.7816 - val_loss: 0.7263 - val_acc: 0.7888\n",
      "Epoch 24/50\n",
      "641/641 [==============================] - 1s 973us/step - loss: 0.7378 - acc: 0.7816 - val_loss: 0.7265 - val_acc: 0.7888\n",
      "Epoch 25/50\n",
      "641/641 [==============================] - 1s 973us/step - loss: 0.7367 - acc: 0.7816 - val_loss: 0.7260 - val_acc: 0.7888\n",
      "Epoch 26/50\n",
      "641/641 [==============================] - 1s 987us/step - loss: 0.7333 - acc: 0.7816 - val_loss: 0.7177 - val_acc: 0.7888\n",
      "Epoch 27/50\n",
      "641/641 [==============================] - 1s 988us/step - loss: 0.7414 - acc: 0.7832 - val_loss: 0.7282 - val_acc: 0.7888\n",
      "Epoch 28/50\n",
      "641/641 [==============================] - 1s 994us/step - loss: 0.7418 - acc: 0.7832 - val_loss: 0.7254 - val_acc: 0.7888\n",
      "Epoch 29/50\n",
      "641/641 [==============================] - 1s 976us/step - loss: 0.7425 - acc: 0.7847 - val_loss: 0.7333 - val_acc: 0.7888\n",
      "Epoch 30/50\n",
      "641/641 [==============================] - 1s 968us/step - loss: 0.7422 - acc: 0.7847 - val_loss: 0.7330 - val_acc: 0.7888\n",
      "Epoch 31/50\n",
      "641/641 [==============================] - 1s 966us/step - loss: 0.7549 - acc: 0.7847 - val_loss: 0.7357 - val_acc: 0.7888\n",
      "Epoch 32/50\n",
      "641/641 [==============================] - 1s 991us/step - loss: 0.7448 - acc: 0.7847 - val_loss: 0.7331 - val_acc: 0.7888\n",
      "Epoch 33/50\n",
      "641/641 [==============================] - 1s 979us/step - loss: 0.7422 - acc: 0.7847 - val_loss: 0.7290 - val_acc: 0.7888\n",
      "Epoch 34/50\n",
      "641/641 [==============================] - 1s 983us/step - loss: 0.7422 - acc: 0.7847 - val_loss: 0.7294 - val_acc: 0.7888\n",
      "Epoch 35/50\n",
      "641/641 [==============================] - 1s 970us/step - loss: 0.7412 - acc: 0.7847 - val_loss: 0.7282 - val_acc: 0.7888\n",
      "Epoch 36/50\n",
      "641/641 [==============================] - 1s 984us/step - loss: 0.7356 - acc: 0.7832 - val_loss: 0.7290 - val_acc: 0.7888\n",
      "Epoch 37/50\n",
      "641/641 [==============================] - 1s 961us/step - loss: 0.7436 - acc: 0.7847 - val_loss: 0.7287 - val_acc: 0.7888\n",
      "Epoch 38/50\n",
      "641/641 [==============================] - 1s 949us/step - loss: 0.7407 - acc: 0.7847 - val_loss: 0.7271 - val_acc: 0.7888\n",
      "Epoch 39/50\n",
      "641/641 [==============================] - 1s 953us/step - loss: 0.7387 - acc: 0.7847 - val_loss: 0.7284 - val_acc: 0.7888\n",
      "Epoch 40/50\n",
      "641/641 [==============================] - 1s 965us/step - loss: 0.7415 - acc: 0.7847 - val_loss: 0.7269 - val_acc: 0.7888\n",
      "Epoch 41/50\n",
      "641/641 [==============================] - 1s 952us/step - loss: 0.7390 - acc: 0.7863 - val_loss: 0.7229 - val_acc: 0.7888\n",
      "Epoch 42/50\n",
      "641/641 [==============================] - 1s 975us/step - loss: 0.7368 - acc: 0.7863 - val_loss: 0.7253 - val_acc: 0.7888\n",
      "Epoch 43/50\n",
      "641/641 [==============================] - 1s 968us/step - loss: 0.7367 - acc: 0.7863 - val_loss: 0.7265 - val_acc: 0.7888\n",
      "Epoch 44/50\n",
      "641/641 [==============================] - 1s 958us/step - loss: 0.7384 - acc: 0.7863 - val_loss: 0.7233 - val_acc: 0.7888\n",
      "Epoch 45/50\n",
      "641/641 [==============================] - 1s 965us/step - loss: 0.7358 - acc: 0.7863 - val_loss: 0.7252 - val_acc: 0.7888\n",
      "Epoch 46/50\n",
      "641/641 [==============================] - 1s 968us/step - loss: 0.7366 - acc: 0.7863 - val_loss: 0.7227 - val_acc: 0.7888\n",
      "Epoch 47/50\n",
      "641/641 [==============================] - 1s 943us/step - loss: 0.7347 - acc: 0.7863 - val_loss: 0.7244 - val_acc: 0.7888\n",
      "Epoch 48/50\n",
      "641/641 [==============================] - 1s 965us/step - loss: 0.7356 - acc: 0.7863 - val_loss: 0.7242 - val_acc: 0.7888\n",
      "Epoch 49/50\n",
      "641/641 [==============================] - 1s 960us/step - loss: 0.7365 - acc: 0.7863 - val_loss: 0.7260 - val_acc: 0.7888\n",
      "Epoch 50/50\n",
      "641/641 [==============================] - 1s 1ms/step - loss: 0.7345 - acc: 0.7863 - val_loss: 0.7239 - val_acc: 0.7888\n"
     ]
    }
   ],
   "source": [
    "history_reg=model_reg.fit(X_train, y_train, batch_size=batch_size,epochs=n_epochs,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features=list()\n",
    "path_features='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/output/ML_predictions/list_relevantFeatures.txt'\n",
    "with open(path_features, 'r') as f:  \n",
    "    for line in f:\n",
    "        # remove linebreak which is the last character of the string\n",
    "        currentPlace = line[:-1]\n",
    "        # add item to the list\n",
    "        relevant_features.append(currentPlace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NHY',\n",
       " 'PDDXDT_diff_days',\n",
       " 'DOMSIDE',\n",
       " 'DFBRADYP',\n",
       " 'DFRIGIDP',\n",
       " 'PRIMDIAG',\n",
       " 'APPRDX',\n",
       " 'NP3FACXP',\n",
       " 'NP3BRADY',\n",
       " 'DFBRADYA',\n",
       " 'DXTREMOR',\n",
       " 'NP3TTAPL',\n",
       " 'DFRIGIDA',\n",
       " 'NP3FTAPL',\n",
       " 'lastDate_diff_days',\n",
       " 'BIRTHDT',\n",
       " 'ON_OFF_DOSE',\n",
       " 'CURRENT_APPRDX',\n",
       " 'NP3PRSPL',\n",
       " 'DIASTND',\n",
       " 'NP3FTAPR',\n",
       " 'SYSSTND',\n",
       " 'PD_MED_USE',\n",
       " 'SYSSUP',\n",
       " 'NP3HMOVL',\n",
       " 'DIASUP',\n",
       " 'NP3RTCON',\n",
       " 'NP3PSTBL',\n",
       " 'HRSTND',\n",
       " 'NP3RIGN',\n",
       " 'HRSUP',\n",
       " 'NP3RIGLU',\n",
       " 'PDMEDYN',\n",
       " 'NP3RIGRU',\n",
       " 'NP2WALK',\n",
       " 'NP3TTAPR',\n",
       " 'NP2TRMR',\n",
       " 'NP3SPCH',\n",
       " 'num_visits',\n",
       " 'NP2HWRT',\n",
       " 'DXBRADY',\n",
       " 'NP3LGAGL',\n",
       " 'NP2DRES',\n",
       " 'NP2SPCH',\n",
       " 'MHROW_2',\n",
       " 'NP3RISNG',\n",
       " 'DFRTREMA',\n",
       " 'NP3GAIT',\n",
       " 'NP3POSTR',\n",
       " 'visitsdiff_days',\n",
       " 'NP3HMOVR',\n",
       " 'PN3RIGRL',\n",
       " 'TOPRRSLT',\n",
       " 'DXRIGID',\n",
       " 'DFPGDIST',\n",
       " 'NP3RTALU',\n",
       " 'NP2RISE',\n",
       " 'NP3PRSPR',\n",
       " 'DVS_JLO_MSSAE',\n",
       " 'AGE_ASSESS_LNS',\n",
       " 'NP2TURN',\n",
       " 'NP3LGAGR',\n",
       " 'AGE_ASSESS_JLO',\n",
       " 'VISIT_ID',\n",
       " 'DVT_SDM',\n",
       " 'NP3RIGLL',\n",
       " 'DVT_RETENTION',\n",
       " 'MHROW_3',\n",
       " 'NP2HOBB',\n",
       " 'TGLCRSLT',\n",
       " 'SDMTOTAL',\n",
       " 'RBCRSLT',\n",
       " 'NP1COG',\n",
       " 'NP2HYGN',\n",
       " 'DVT_DELAYED_RECALL',\n",
       " 'RFLLLRSP',\n",
       " 'DVSD_SDM',\n",
       " 'NP3RTARU',\n",
       " 'DVT_TOTAL_RECALL',\n",
       " 'NP1ANXS',\n",
       " 'NP2EAT',\n",
       " 'DVT_RECOG_DISC_INDEX',\n",
       " 'WBCRSLT',\n",
       " 'NP2SALV',\n",
       " 'MCAVFNUM',\n",
       " 'NP1DPRS',\n",
       " 'RFLRLRSP',\n",
       " 'DFRTREMP',\n",
       " 'DVS_LNS',\n",
       " 'LNS_TOTRAW',\n",
       " 'RFLRARSP',\n",
       " 'HVLTRDLY',\n",
       " 'NP3FRZGT',\n",
       " 'HVLTRT1',\n",
       " 'NP1APAT',\n",
       " 'NP2FREZ',\n",
       " 'HVLTVRSN',\n",
       " 'NP3PTRML',\n",
       " 'HVLTRT2',\n",
       " 'HVLTRT3',\n",
       " 'CN1RSP',\n",
       " 'PARKISM',\n",
       " 'JLO_TOTCALC',\n",
       " 'MCATOT',\n",
       " 'NP3KTRML',\n",
       " 'GENDER',\n",
       " 'NP3PTRMR',\n",
       " 'PLRLRSP',\n",
       " 'DVS_JLO_MSSA',\n",
       " 'RFLLARSP',\n",
       " 'NP3KTRMR',\n",
       " 'ONLDOPA',\n",
       " 'JLO_TOTRAW',\n",
       " 'NP2SWAL',\n",
       " 'FULNUPDR',\n",
       " 'PLRRRSP',\n",
       " 'ESS2',\n",
       " 'NP4FLCTI',\n",
       " 'HVLTREC',\n",
       " 'DFFALLS',\n",
       " 'NP4OFF',\n",
       " 'ONOTHER',\n",
       " 'HVLTFPRL',\n",
       " 'STAIAD2',\n",
       " 'ONDOPAG',\n",
       " 'SCAU13',\n",
       " 'NP3RTALL',\n",
       " 'SCAU12',\n",
       " 'MHROW_4',\n",
       " 'STAIAD26',\n",
       " 'STAIAD23',\n",
       " 'ESS4',\n",
       " 'STAIAD27',\n",
       " 'SCAU6',\n",
       " 'P3GRP',\n",
       " 'NP3RTARL',\n",
       " 'SENLLRSP',\n",
       " 'ESS5',\n",
       " 'STAIAD39',\n",
       " 'STAIAD34',\n",
       " 'DXOTHSX',\n",
       " 'NP1DDS',\n",
       " 'SCAU11',\n",
       " 'SCAU10',\n",
       " 'NP1HALL',\n",
       " 'STAIAD1',\n",
       " 'CSFSPNRT',\n",
       " 'STAIAD36',\n",
       " 'SENRLRSP',\n",
       " 'STAIAD3',\n",
       " 'STAIAD24',\n",
       " 'DFPSYCH',\n",
       " 'STAIAD30',\n",
       " 'NP4FLCTX',\n",
       " 'STAIAD15',\n",
       " 'SCAU5',\n",
       " 'STAIAD32',\n",
       " 'STAIAD33',\n",
       " 'STAIAD5',\n",
       " 'SCAU8',\n",
       " 'ESS7',\n",
       " 'SCAU20',\n",
       " 'DXPOSINS',\n",
       " 'STAIAD20',\n",
       " 'SCAU19',\n",
       " 'STAIAD22',\n",
       " 'DFBWLDYS',\n",
       " 'DFCOGNIT',\n",
       " 'STAIAD19',\n",
       " 'CN2RSP',\n",
       " 'SCAU21',\n",
       " 'ESS1',\n",
       " 'MHROW_1',\n",
       " 'DFURDYS',\n",
       " 'STAIAD16',\n",
       " 'STAIAD37',\n",
       " 'STAIAD21',\n",
       " 'STAIAD12',\n",
       " 'STAIAD29',\n",
       " 'SCAU3',\n",
       " 'STAIAD17',\n",
       " 'STAIAD13',\n",
       " 'STAIAD38',\n",
       " 'ESS3',\n",
       " 'STAIAD11',\n",
       " 'STAIAD8',\n",
       " 'STAIAD10',\n",
       " 'STAIAD6',\n",
       " 'GDSMEMRY',\n",
       " 'DFRPROG',\n",
       " 'COHSRRSP',\n",
       " 'NP4DYSKI',\n",
       " 'SCAU2',\n",
       " 'NP4WDYSK',\n",
       " 'STAIAD14',\n",
       " 'DFSTROKE',\n",
       " 'STAIAD35',\n",
       " 'DRMREMEM',\n",
       " 'STAIAD28',\n",
       " 'MSRLRSP',\n",
       " 'STAIAD40',\n",
       " 'DRMAGRAC',\n",
       " 'SCAU17',\n",
       " 'STAIAD31',\n",
       " 'MCAREC1',\n",
       " 'MSRARSP',\n",
       " 'SCAU26D',\n",
       " 'STAIAD7',\n",
       " 'STAIAD18',\n",
       " 'NP4DYSTN',\n",
       " 'SCAU15',\n",
       " 'SCAU14',\n",
       " 'ABNORM',\n",
       " 'DFUNIRIG',\n",
       " 'MSLLRSP',\n",
       " 'SCAU1',\n",
       " 'SCAU9',\n",
       " 'SLPLMBMV',\n",
       " 'COHSLRSP',\n",
       " 'CN8RSP',\n",
       " 'DRMVIVID',\n",
       " 'STAIAD9',\n",
       " 'SCAU18',\n",
       " 'SCAU4',\n",
       " 'STAIAD4',\n",
       " 'DYSKPRES',\n",
       " 'MCAREC2',\n",
       " 'SCAU26C',\n",
       " 'NP3RTALJ',\n",
       " 'MCASNTNC',\n",
       " 'SDMTVRSN',\n",
       " 'MCAREC3',\n",
       " 'RVWNPSY',\n",
       " 'DFPSHYPO',\n",
       " 'COGDXCL',\n",
       " 'GDSENRGY',\n",
       " 'DFOTHCRS',\n",
       " 'COFNRRSP',\n",
       " 'ESS8',\n",
       " 'MCAREC4',\n",
       " 'DRMVERBL',\n",
       " 'SMPDSCRD',\n",
       " 'SLPDSTRB',\n",
       " 'MCABDS',\n",
       " 'MSLARSP',\n",
       " 'DRMNOCTB',\n",
       " 'GDSBETER',\n",
       " 'MHROW_5',\n",
       " 'GDSDROPD',\n",
       " 'GDSHOME',\n",
       " 'DFSTATIC',\n",
       " 'HVLTFPUN',\n",
       " 'HETRA',\n",
       " 'CN346RSP',\n",
       " 'MCAALTTM',\n",
       " 'MCAREC5',\n",
       " 'STAIAD25',\n",
       " 'MCACUBE',\n",
       " 'MCACLCKN',\n",
       " 'DEPRS',\n",
       " 'DRMFIGHT',\n",
       " 'COGSTATE',\n",
       " 'DFDYSTON',\n",
       " 'MCASER7',\n",
       " 'DFSEXDYS',\n",
       " 'GDSAFRAD',\n",
       " 'TMEAT',\n",
       " 'PTINBOTH',\n",
       " 'COFNLRSP',\n",
       " 'TMBUY',\n",
       " 'MVAWAKEN',\n",
       " 'GDSHAPPY',\n",
       " 'MCACLCKH',\n",
       " 'MCAVF',\n",
       " 'GDSEMPTY',\n",
       " 'TMTORACT',\n",
       " 'SCAU16',\n",
       " 'SCAU7',\n",
       " 'DRMOBJFL',\n",
       " 'SENRARSP',\n",
       " 'SENLARSP',\n",
       " 'DRMUMV',\n",
       " 'GDSGSPIR',\n",
       " 'SLPINJUR',\n",
       " 'DFOTHTRM',\n",
       " 'GDSHOPLS',\n",
       " 'COGDECLN',\n",
       " 'DFAXRIG',\n",
       " 'CN7RSP',\n",
       " 'GDSWRTLS',\n",
       " 'TESTNAME',\n",
       " 'SCAU26B',\n",
       " 'GDSALIVE',\n",
       " 'MCARHINO',\n",
       " 'MHROW_6',\n",
       " 'DFOTHPG',\n",
       " 'MCAABSTR',\n",
       " 'DFATYP',\n",
       " 'GDSHLPLS',\n",
       " 'DFOTHHYP',\n",
       " 'DIAGNOSIS',\n",
       " 'RLS',\n",
       " 'ESS6',\n",
       " 'DFFREEZ',\n",
       " 'CN11RSP',\n",
       " 'CNTRLSEX',\n",
       " 'CNTRLEAT',\n",
       " 'TESTVALUE',\n",
       " 'FNCDTCOG',\n",
       " 'DFPATREM',\n",
       " 'DFTONE',\n",
       " 'MCAFDS',\n",
       " 'GDSSATIS',\n",
       " 'DFPRESNT',\n",
       " 'DFNEURAB',\n",
       " 'DFBRPLUS',\n",
       " 'DFOTHABR',\n",
       " 'MCACLCKC',\n",
       " 'DFBULBAR',\n",
       " 'EPILEPSY',\n",
       " 'TMSEX',\n",
       " 'DFRSKFCT',\n",
       " 'GDSBORED',\n",
       " 'MHROW_7',\n",
       " 'TMTMTACT',\n",
       " 'DFOCULO',\n",
       " 'MCAVIGIL',\n",
       " 'DFAKINES',\n",
       " 'DFEYELID',\n",
       " 'CNTRLBUY',\n",
       " 'CN12RSP',\n",
       " 'CN5RSP',\n",
       " 'DFOTHRIG',\n",
       " 'MCALION',\n",
       " 'STROKE',\n",
       " 'CN910RSP',\n",
       " 'DFGAIT',\n",
       " 'TMGAMBLE',\n",
       " 'PDSURG',\n",
       " 'PDSURGDT_diff_days',\n",
       " 'PDSURGTP',\n",
       " 'DFRAPSPE',\n",
       " 'CNTRLGMB',\n",
       " 'PESEQ_11',\n",
       " 'TMTRWD',\n",
       " 'DFHEMTRO',\n",
       " 'DFCHOREA',\n",
       " 'DFHEMPRK',\n",
       " 'PDMEDT_diff_days',\n",
       " 'DFMYOCLO',\n",
       " 'MCACAMEL',\n",
       " 'NARCLPSY',\n",
       " 'MHROW_9',\n",
       " 'MHROW_11',\n",
       " 'DFAGESX',\n",
       " 'MHROW_10']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,acc=model.evaluate(x=X_test,y=y_test) # to evaluate on validation_set "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project]",
   "language": "python",
   "name": "conda-env-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: \n",
    "#### Understand what is the source of the perfect training accuracy: \n",
    "* Logistic Regression: play on the C parameter\n",
    "* RF: play on the parameters that can reduce overfitting\n",
    "#### Features highly correlated with NHY feature:\n",
    "* NP3FACXP, NP3FTAPR, NP3HMOVR, NP3PRSPR, NP3TTAPR,NP3POSTR, NP3BRADY,NP2TMPR,NP3SPCH,MSEADLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTEBOOKS - classic ML\n",
    "* [DSR- Gerrit- intro to ML] (http://localhost:8888/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/Machine%20Learning%20-%20DSR%20Intro.ipynb)\n",
    "* [DSR-Gerrit- Boosting & XGBoost]\n",
    "http://localhost:8888/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/Boosting%20and%20XGBoost.ipynb\n",
    "* [DSR-Gerrit- RF]\n",
    "(http://localhost:8888/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/%20RF%20notebooks/DecisionTrees_Intro.ipynb)\n",
    "* [DSR-Gerrit-Evaluation models] (http://localhost:8888/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/exercises/Evaluation%20Solutions.ipynb)\n",
    "* [DSR-Gerrit- Bayesian Learning]\n",
    "(http://localhost:8888/notebooks/00_TRAINING/02_DSR/05_ML_Geritt_Week2/exercises/Bayesian%20Learning%20Solutions.ipynb)\n",
    "* [DSR-Rachel-ML Pipelines]\n",
    "(http://localhost:8888/notebooks/00_TRAINING/02_DSR/10_DSR_Model_Pipelines_Rachel/1.3%20Pipelines%20.ipynb)\n",
    "#### GITHUB repos: \n",
    "* **Hands-On Machine Learning w/scikit-learn and TensorFlow book: https://github.com/AMDonati/handson-ml**\n",
    "* https://github.com/AMDonati/data-science-ipython-notebooks\n",
    "* Data Science w/ Python handbook: https://github.com/AMDonati/PythonDataScienceHandbook\n",
    "* https://github.com/AMDonati/machine-learning-cheat-sheet\n",
    "#### Specific to time-series: \n",
    "* https://github.com/ChadFulton/tsa-notebooks\n",
    "* https://github.com/maxim5/time-series-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#imports \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "% matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>INFODT_date</th>\n",
       "      <th>NP1COG</th>\n",
       "      <th>NP1HALL</th>\n",
       "      <th>NP1DPRS</th>\n",
       "      <th>NP1ANXS</th>\n",
       "      <th>NP1APAT</th>\n",
       "      <th>NP1DDS</th>\n",
       "      <th>NP2SPCH</th>\n",
       "      <th>NP2SALV</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2707</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3001</td>\n",
       "      <td>2012-03-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2313</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3001</td>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>426</td>\n",
       "      <td>1887</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3001</td>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>335</td>\n",
       "      <td>1552</td>\n",
       "      <td>1461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3001</td>\n",
       "      <td>2015-04-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "      <td>1187</td>\n",
       "      <td>1826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 376 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATNO INFODT_date  NP1COG  NP1HALL  NP1DPRS  NP1ANXS  NP1APAT  NP1DDS  \\\n",
       "0   3001  2011-02-01     0.0      0.0      0.0      1.0      0.0     0.0   \n",
       "1   3001  2012-03-01     1.0      0.0      1.0      1.0      1.0     0.0   \n",
       "2   3001  2013-05-01     0.0      0.0      0.0      0.0      0.0     0.0   \n",
       "3   3001  2014-04-01     0.0      0.0      0.0      1.0      0.0     0.0   \n",
       "4   3001  2015-04-01     0.0      0.0      0.0      1.0      0.0     0.0   \n",
       "\n",
       "   NP2SPCH  NP2SALV         ...          DXPOSINS  DXOTHSX  DOMSIDE  \\\n",
       "0      0.0      0.0         ...                 0        0        2   \n",
       "1      0.0      0.0         ...                 0        0        2   \n",
       "2      0.0      0.0         ...                 0        0        2   \n",
       "3      0.0      0.0         ...                 0        0        2   \n",
       "4      0.0      0.0         ...                 0        0        2   \n",
       "\n",
       "   num_visits  VISIT_ID  visitsdiff_days  lastDate_diff_days  \\\n",
       "0           7         1                0                2707   \n",
       "1           7         2              394                2313   \n",
       "2           7         3              426                1887   \n",
       "3           7         4              335                1552   \n",
       "4           7         5              365                1187   \n",
       "\n",
       "   PDDXDT_diff_days  PDMEDT_diff_days  PDSURGDT_diff_days  \n",
       "0               306                 0                   0  \n",
       "1               700                 0                   0  \n",
       "2              1126                 0                   0  \n",
       "3              1461                 0                   0  \n",
       "4              1826                 0                   0  \n",
       "\n",
       "[5 rows x 376 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/output/pre-processing/dfFinal.csv'\n",
    "df=pd.read_csv(file_path)\n",
    "df.drop(columns='Unnamed: 0',inplace=True)\n",
    "df.drop(columns=['EVENT_ID','INFODT'],inplace=True)\n",
    "#df.set_index(keys=['PATNO'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing motor and non motor assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>NP1COG</th>\n",
       "      <th>NP1HALL</th>\n",
       "      <th>NP1DPRS</th>\n",
       "      <th>NP1ANXS</th>\n",
       "      <th>NP1APAT</th>\n",
       "      <th>NP1DDS</th>\n",
       "      <th>NP2SPCH</th>\n",
       "      <th>NP2SALV</th>\n",
       "      <th>NP2SWAL</th>\n",
       "      <th>...</th>\n",
       "      <th>NP3RTCON</th>\n",
       "      <th>DYSKPRES</th>\n",
       "      <th>ON_OFF_DOSE</th>\n",
       "      <th>PD_MED_USE</th>\n",
       "      <th>NP4WDYSK</th>\n",
       "      <th>NP4DYSKI</th>\n",
       "      <th>NP4OFF</th>\n",
       "      <th>NP4FLCTI</th>\n",
       "      <th>NP4FLCTX</th>\n",
       "      <th>NP4DYSTN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATNO  NP1COG  NP1HALL  NP1DPRS  NP1ANXS  NP1APAT  NP1DDS  NP2SPCH  \\\n",
       "0   3402     0.0      0.0      1.0      0.0      2.0     0.0      0.0   \n",
       "1   3400     0.0      0.0      2.0      3.0      2.0     0.0      0.0   \n",
       "2   3403     0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
       "3   3404     0.0      0.0      0.0      0.0      0.0     0.0      0.0   \n",
       "4   3406     0.0      0.0      0.0      1.0      1.0     0.0      0.0   \n",
       "\n",
       "   NP2SALV  NP2SWAL    ...     NP3RTCON  DYSKPRES  ON_OFF_DOSE  PD_MED_USE  \\\n",
       "0      0.0      0.0    ...          1.0       0.0          0.0           0   \n",
       "1      2.0      0.0    ...          1.0       0.0          0.0           0   \n",
       "2      0.0      0.0    ...          0.0       0.0          0.0           0   \n",
       "3      0.0      0.0    ...          0.0       0.0          0.0           0   \n",
       "4      2.0      0.0    ...          2.0       0.0          0.0           0   \n",
       "\n",
       "   NP4WDYSK  NP4DYSKI  NP4OFF  NP4FLCTI  NP4FLCTX  NP4DYSTN  \n",
       "0       0.0       0.0     0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0     0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0     0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0     0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0     0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path2='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/output/pre-processing/PD_Progression_Motor-assessments.csv'\n",
    "motor_ass=pd.read_csv(file_path2)\n",
    "motor_ass.drop(columns='Unnamed: 0',inplace=True)\n",
    "motor_ass.drop(columns=['EVENT_ID','INFODT'],inplace=True)\n",
    "#df.set_index(keys=['PATNO'],inplace=True)\n",
    "Motor_ass_features=list(motor_ass.columns)\n",
    "motor_ass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'PATNO' in Motor_ass_features: \n",
    "    Motor_ass_features.remove('PATNO')\n",
    "#Motor_ass_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>ESS1</th>\n",
       "      <th>ESS2</th>\n",
       "      <th>ESS3</th>\n",
       "      <th>ESS4</th>\n",
       "      <th>ESS5</th>\n",
       "      <th>ESS6</th>\n",
       "      <th>ESS7</th>\n",
       "      <th>ESS8</th>\n",
       "      <th>LNS_TOTRAW</th>\n",
       "      <th>...</th>\n",
       "      <th>CNTRLGMB</th>\n",
       "      <th>TMSEX</th>\n",
       "      <th>CNTRLSEX</th>\n",
       "      <th>TMBUY</th>\n",
       "      <th>CNTRLBUY</th>\n",
       "      <th>TMEAT</th>\n",
       "      <th>CNTRLEAT</th>\n",
       "      <th>TMTORACT</th>\n",
       "      <th>TMTMTACT</th>\n",
       "      <th>TMTRWD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3102</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3630</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3428</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATNO  ESS1  ESS2  ESS3  ESS4  ESS5  ESS6  ESS7  ESS8  LNS_TOTRAW   ...    \\\n",
       "0   3102   3.0   2.0   1.0   2.0   3.0   1.0   1.0   1.0         8.0   ...     \n",
       "1   3630   1.0   0.0   0.0   1.0   3.0   0.0   0.0   0.0         8.0   ...     \n",
       "2   3404   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0        16.0   ...     \n",
       "3   3429   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0         6.0   ...     \n",
       "4   3428   1.0   1.0   1.0   1.0   3.0   1.0   0.0   0.0         5.0   ...     \n",
       "\n",
       "   CNTRLGMB  TMSEX  CNTRLSEX  TMBUY  CNTRLBUY  TMEAT  CNTRLEAT  TMTORACT  \\\n",
       "0       0.0    0.0       0.0    0.0       0.0    0.0       0.0       0.0   \n",
       "1       0.0    0.0       0.0    1.0       0.0    0.0       0.0       0.0   \n",
       "2       0.0    0.0       0.0    0.0       0.0    0.0       0.0       0.0   \n",
       "3       0.0    0.0       0.0    0.0       0.0    0.0       0.0       0.0   \n",
       "4       0.0    0.0       0.0    0.0       0.0    0.0       0.0       0.0   \n",
       "\n",
       "   TMTMTACT  TMTRWD  \n",
       "0       0.0     0.0  \n",
       "1       0.0     0.0  \n",
       "2       0.0     0.0  \n",
       "3       0.0     0.0  \n",
       "4       0.0     0.0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path3='/Users/alicemartin/02_DSR_Project/parkinson-disease-project/output/pre-processing/Non-Motor_Assessments.csv'\n",
    "NonMotor_ass=pd.read_csv(file_path3)\n",
    "NonMotor_ass.drop(columns='Unnamed: 0',inplace=True)\n",
    "NonMotor_ass.drop(columns=['EVENT_ID','INFODT'],inplace=True)\n",
    "#df.set_index(keys=['PATNO'],inplace=True)\n",
    "NonMotor_ass_features=list(NonMotor_ass.columns)\n",
    "NonMotor_ass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESS1',\n",
       " 'ESS2',\n",
       " 'ESS3',\n",
       " 'ESS4',\n",
       " 'ESS5',\n",
       " 'ESS6',\n",
       " 'ESS7',\n",
       " 'ESS8',\n",
       " 'LNS_TOTRAW',\n",
       " 'AGE_ASSESS_LNS',\n",
       " 'DVS_LNS',\n",
       " 'DRMVIVID',\n",
       " 'DRMAGRAC',\n",
       " 'DRMNOCTB',\n",
       " 'SLPLMBMV',\n",
       " 'SLPINJUR',\n",
       " 'DRMVERBL',\n",
       " 'DRMFIGHT',\n",
       " 'DRMUMV',\n",
       " 'DRMOBJFL',\n",
       " 'MVAWAKEN',\n",
       " 'DRMREMEM',\n",
       " 'SLPDSTRB',\n",
       " 'STROKE',\n",
       " 'HETRA',\n",
       " 'PARKISM',\n",
       " 'RLS',\n",
       " 'NARCLPSY',\n",
       " 'DEPRS',\n",
       " 'EPILEPSY',\n",
       " 'BRNINFM',\n",
       " 'SCAU1',\n",
       " 'SCAU2',\n",
       " 'SCAU3',\n",
       " 'SCAU4',\n",
       " 'SCAU5',\n",
       " 'SCAU6',\n",
       " 'SCAU7',\n",
       " 'SCAU8',\n",
       " 'SCAU9',\n",
       " 'SCAU10',\n",
       " 'SCAU11',\n",
       " 'SCAU12',\n",
       " 'SCAU13',\n",
       " 'SCAU14',\n",
       " 'SCAU15',\n",
       " 'SCAU16',\n",
       " 'SCAU17',\n",
       " 'SCAU18',\n",
       " 'SCAU19',\n",
       " 'SCAU20',\n",
       " 'SCAU21',\n",
       " 'SCAU26B',\n",
       " 'SCAU26C',\n",
       " 'SCAU26D',\n",
       " 'COGDECLN',\n",
       " 'FNCDTCOG',\n",
       " 'COGSTATE',\n",
       " 'COGDXCL',\n",
       " 'RVWNPSY',\n",
       " 'HVLTRT1',\n",
       " 'HVLTRT2',\n",
       " 'HVLTRT3',\n",
       " 'HVLTRDLY',\n",
       " 'HVLTREC',\n",
       " 'HVLTFPRL',\n",
       " 'HVLTFPUN',\n",
       " 'HVLTVRSN',\n",
       " 'DVT_TOTAL_RECALL',\n",
       " 'DVT_DELAYED_RECALL',\n",
       " 'DVT_RETENTION',\n",
       " 'DVT_RECOG_DISC_INDEX',\n",
       " 'MCAALTTM',\n",
       " 'MCACUBE',\n",
       " 'MCACLCKC',\n",
       " 'MCACLCKN',\n",
       " 'MCACLCKH',\n",
       " 'MCALION',\n",
       " 'MCARHINO',\n",
       " 'MCACAMEL',\n",
       " 'MCAFDS',\n",
       " 'MCABDS',\n",
       " 'MCAVIGIL',\n",
       " 'MCASER7',\n",
       " 'MCASNTNC',\n",
       " 'MCAVFNUM',\n",
       " 'MCAVF',\n",
       " 'MCAABSTR',\n",
       " 'MCAREC1',\n",
       " 'MCAREC2',\n",
       " 'MCAREC3',\n",
       " 'MCAREC4',\n",
       " 'MCAREC5',\n",
       " 'MCATOT',\n",
       " 'GDSSATIS',\n",
       " 'GDSDROPD',\n",
       " 'GDSEMPTY',\n",
       " 'GDSBORED',\n",
       " 'GDSGSPIR',\n",
       " 'GDSAFRAD',\n",
       " 'GDSHAPPY',\n",
       " 'GDSHLPLS',\n",
       " 'GDSHOME',\n",
       " 'GDSMEMRY',\n",
       " 'GDSALIVE',\n",
       " 'GDSWRTLS',\n",
       " 'GDSENRGY',\n",
       " 'GDSHOPLS',\n",
       " 'GDSBETER',\n",
       " 'SDMTOTAL',\n",
       " 'SDMTVRSN',\n",
       " 'DVSD_SDM',\n",
       " 'DVT_SDM',\n",
       " 'STAIAD1',\n",
       " 'STAIAD2',\n",
       " 'STAIAD3',\n",
       " 'STAIAD4',\n",
       " 'STAIAD5',\n",
       " 'STAIAD6',\n",
       " 'STAIAD7',\n",
       " 'STAIAD8',\n",
       " 'STAIAD9',\n",
       " 'STAIAD10',\n",
       " 'STAIAD11',\n",
       " 'STAIAD12',\n",
       " 'STAIAD13',\n",
       " 'STAIAD14',\n",
       " 'STAIAD15',\n",
       " 'STAIAD16',\n",
       " 'STAIAD17',\n",
       " 'STAIAD18',\n",
       " 'STAIAD19',\n",
       " 'STAIAD20',\n",
       " 'STAIAD21',\n",
       " 'STAIAD22',\n",
       " 'STAIAD23',\n",
       " 'STAIAD24',\n",
       " 'STAIAD25',\n",
       " 'STAIAD26',\n",
       " 'STAIAD27',\n",
       " 'STAIAD28',\n",
       " 'STAIAD29',\n",
       " 'STAIAD30',\n",
       " 'STAIAD31',\n",
       " 'STAIAD32',\n",
       " 'STAIAD33',\n",
       " 'STAIAD34',\n",
       " 'STAIAD35',\n",
       " 'STAIAD36',\n",
       " 'STAIAD37',\n",
       " 'STAIAD38',\n",
       " 'STAIAD39',\n",
       " 'STAIAD40',\n",
       " 'JLO_TOTRAW',\n",
       " 'JLO_TOTCALC',\n",
       " 'AGE_ASSESS_JLO',\n",
       " 'DVS_JLO_MSSA',\n",
       " 'DVS_JLO_MSSAE',\n",
       " 'PTINBOTH',\n",
       " 'TMGAMBLE',\n",
       " 'CNTRLGMB',\n",
       " 'TMSEX',\n",
       " 'CNTRLSEX',\n",
       " 'TMBUY',\n",
       " 'CNTRLBUY',\n",
       " 'TMEAT',\n",
       " 'CNTRLEAT',\n",
       " 'TMTORACT',\n",
       " 'TMTMTACT',\n",
       " 'TMTRWD']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'PATNO' in NonMotor_ass_features: \n",
    "    NonMotor_ass_features.remove('PATNO')\n",
    "NonMotor_ass_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features:142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NHY</th>\n",
       "      <th>PDMEDYN</th>\n",
       "      <th>ONLDOPA</th>\n",
       "      <th>ONDOPAG</th>\n",
       "      <th>ONOTHER</th>\n",
       "      <th>FULNUPDR</th>\n",
       "      <th>PDSURG</th>\n",
       "      <th>PDSURGTP</th>\n",
       "      <th>MSRARSP</th>\n",
       "      <th>MSLARSP</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th>INFODT_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3001</th>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2707</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2313</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>426</td>\n",
       "      <td>1887</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>335</td>\n",
       "      <td>1552</td>\n",
       "      <td>1461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "      <td>1187</td>\n",
       "      <td>1826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   NHY  PDMEDYN  ONLDOPA  ONDOPAG  ONOTHER  FULNUPDR  PDSURG  \\\n",
       "PATNO INFODT_date                                                              \n",
       "3001  2011-02-01   2.0      0.0      0.0      0.0      0.0       0.0     0.0   \n",
       "      2012-03-01   2.0      0.0      0.0      0.0      0.0       1.0     0.0   \n",
       "      2013-05-01   2.0      1.0      0.0      0.0      1.0       0.0     0.0   \n",
       "      2014-04-01   2.0      1.0      0.0      1.0      1.0       0.0     0.0   \n",
       "      2015-04-01   2.0      1.0      1.0      0.0      1.0       1.0     0.0   \n",
       "\n",
       "                   PDSURGTP  MSRARSP  MSLARSP         ...          DXPOSINS  \\\n",
       "PATNO INFODT_date                                     ...                     \n",
       "3001  2011-02-01        4.0      0.0      0.0         ...                 0   \n",
       "      2012-03-01        4.0      0.0      0.0         ...                 0   \n",
       "      2013-05-01        4.0      0.0      0.0         ...                 0   \n",
       "      2014-04-01        4.0      0.0      0.0         ...                 0   \n",
       "      2015-04-01        4.0      0.0      0.0         ...                 0   \n",
       "\n",
       "                   DXOTHSX  DOMSIDE  num_visits  VISIT_ID  visitsdiff_days  \\\n",
       "PATNO INFODT_date                                                            \n",
       "3001  2011-02-01         0        2           7         1                0   \n",
       "      2012-03-01         0        2           7         2              394   \n",
       "      2013-05-01         0        2           7         3              426   \n",
       "      2014-04-01         0        2           7         4              335   \n",
       "      2015-04-01         0        2           7         5              365   \n",
       "\n",
       "                   lastDate_diff_days  PDDXDT_diff_days  PDMEDT_diff_days  \\\n",
       "PATNO INFODT_date                                                           \n",
       "3001  2011-02-01                 2707               306                 0   \n",
       "      2012-03-01                 2313               700                 0   \n",
       "      2013-05-01                 1887              1126                 0   \n",
       "      2014-04-01                 1552              1461                 0   \n",
       "      2015-04-01                 1187              1826                 0   \n",
       "\n",
       "                   PDSURGDT_diff_days  \n",
       "PATNO INFODT_date                      \n",
       "3001  2011-02-01                    0  \n",
       "      2012-03-01                    0  \n",
       "      2013-05-01                    0  \n",
       "      2014-04-01                    0  \n",
       "      2015-04-01                    0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truncated=df.drop(columns=Motor_ass_features)\n",
    "df_truncated.drop(columns=NonMotor_ass_features,inplace=True)\n",
    "df_truncated.drop(columns=['MSEADLG'],inplace=True)\n",
    "df_truncated.set_index(keys=['PATNO','INFODT_date'],inplace=True)\n",
    "print('number of features:{}'.format(len(df_truncated.columns)))\n",
    "df_truncated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    2386\n",
       "0.0    1227\n",
       "1.0     865\n",
       "3.0     246\n",
       "4.0      47\n",
       "5.0      13\n",
       "Name: NHY, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truncated['NHY'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train counts: 2.0    1671\n",
      "0.0     842\n",
      "1.0     617\n",
      "3.0     173\n",
      "4.0      37\n",
      "5.0       8\n",
      "Name: NHY, dtype: int64\n",
      "(3348, 141)\n",
      "test counts: 2.0    715\n",
      "0.0    385\n",
      "1.0    248\n",
      "3.0     73\n",
      "4.0     10\n",
      "5.0      5\n",
      "Name: NHY, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NHY</th>\n",
       "      <th>PDMEDYN</th>\n",
       "      <th>ONLDOPA</th>\n",
       "      <th>ONDOPAG</th>\n",
       "      <th>ONOTHER</th>\n",
       "      <th>FULNUPDR</th>\n",
       "      <th>PDSURG</th>\n",
       "      <th>PDSURGTP</th>\n",
       "      <th>MSRARSP</th>\n",
       "      <th>MSLARSP</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th>INFODT_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40574</th>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>759</td>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>396</td>\n",
       "      <td>91</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3373</th>\n",
       "      <th>2015-06-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>335</td>\n",
       "      <td>1126</td>\n",
       "      <td>1247</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42454</th>\n",
       "      <th>2016-12-01</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>2253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>366</td>\n",
       "      <td>852</td>\n",
       "      <td>1886</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   NHY  PDMEDYN  ONLDOPA  ONDOPAG  ONOTHER  FULNUPDR  PDSURG  \\\n",
       "PATNO INFODT_date                                                              \n",
       "40574 2016-03-01   0.0      0.0      0.0      0.0      0.0       0.0     0.0   \n",
       "4034  2018-04-01   2.0      1.0      1.0      0.0      0.0       0.0     0.0   \n",
       "3373  2015-06-01   2.0      1.0      1.0      0.0      0.0       0.0     0.0   \n",
       "42454 2016-12-01   3.0      0.0      0.0      0.0      0.0       0.0     0.0   \n",
       "3415  2016-03-01   2.0      1.0      1.0      0.0      1.0       1.0     0.0   \n",
       "\n",
       "                   PDSURGTP  MSRARSP  MSLARSP         ...          DXPOSINS  \\\n",
       "PATNO INFODT_date                                     ...                     \n",
       "40574 2016-03-01        4.0      0.0      0.0         ...                 0   \n",
       "4034  2018-04-01        4.0      0.0      0.0         ...                 0   \n",
       "3373  2015-06-01        4.0      0.0      0.0         ...                 0   \n",
       "42454 2016-12-01        4.0      0.0      0.0         ...                 0   \n",
       "3415  2016-03-01        4.0      0.0      0.0         ...                 0   \n",
       "\n",
       "                   DXOTHSX  DOMSIDE  num_visits  VISIT_ID  visitsdiff_days  \\\n",
       "PATNO INFODT_date                                                            \n",
       "40574 2016-03-01         0        0           3         2              759   \n",
       "4034  2018-04-01         1        2           6         6              396   \n",
       "3373  2015-06-01         1        2           6         4              335   \n",
       "42454 2016-12-01         1        1           2         1                0   \n",
       "3415  2016-03-01         0        2           8         6              366   \n",
       "\n",
       "                   lastDate_diff_days  PDDXDT_diff_days  PDMEDT_diff_days  \\\n",
       "PATNO INFODT_date                                                           \n",
       "40574 2016-03-01                  852                 0                 0   \n",
       "4034  2018-04-01                   91              2800                 0   \n",
       "3373  2015-06-01                 1126              1247                 0   \n",
       "42454 2016-12-01                  577              2253                 0   \n",
       "3415  2016-03-01                  852              1886                 0   \n",
       "\n",
       "                   PDSURGDT_diff_days  \n",
       "PATNO INFODT_date                      \n",
       "40574 2016-03-01                    0  \n",
       "4034  2018-04-01                    0  \n",
       "3373  2015-06-01                    0  \n",
       "42454 2016-12-01                    0  \n",
       "3415  2016-03-01                    0  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data=df_truncated.drop(columns='NHY')\n",
    "target=df_truncated['NHY']\n",
    "train, test = train_test_split(df_truncated, test_size=0.3, random_state=0)\n",
    "\n",
    "train.to_pickle(\"./train_nonTS.pickle\")\n",
    "test.to_pickle(\"./test_nonTS.pickle\")\n",
    "print('train counts: {}'.format(train.NHY.value_counts()))\n",
    "\n",
    "X_train = train.loc[:,train.columns!='NHY']\n",
    "y_train = train['NHY']\n",
    "X_test = test.loc[:,train.columns!='NHY']\n",
    "y_test = test[('NHY')]\n",
    "print(X_train.shape)\n",
    "print('test counts: {}'.format(y_test.value_counts()))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take care of the classes unbalance with a sample upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    1671\n",
      "4.0    1671\n",
      "3.0    1671\n",
      "0.0    1671\n",
      "1.0    1671\n",
      "2.0    1671\n",
      "Name: NHY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def upsampling_NHY(train):\n",
    "    train_majority = train[train.NHY==2.0]\n",
    "    train_minority_1 = train[train.NHY==1.0]\n",
    "    train_minority_0= train[train.NHY==0.0]\n",
    "    train_minority_3= train[train.NHY==3.0]\n",
    "    train_minority_4=train[train.NHY==4.0]\n",
    "    train_minority_5=train[train.NHY==5.0]\n",
    "\n",
    "    # Upsample minority class\n",
    "    train_minority_upsampled_1 = resample(train_minority_1, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=train_majority.shape[0],  # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    train_minority_upsampled_0 = resample(train_minority_0, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=train_majority.shape[0],  # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    train_minority_upsampled_3 = resample(train_minority_3, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=train_majority.shape[0],  # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    train_minority_upsampled_4= resample(train_minority_4, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=train_majority.shape[0],  # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "    train_minority_upsampled_5= resample(train_minority_5, \n",
    "                                     replace=True,     # sample with replacement\n",
    "                                     n_samples=train_majority.shape[0],  # to match majority class\n",
    "                                     random_state=123) # reproducible results\n",
    "\n",
    "    # Combine majority class with upsampled minority class\n",
    "    train_upsampled = pd.concat([train_majority, train_minority_upsampled_1,train_minority_upsampled_0,\n",
    "                                 train_minority_upsampled_3,train_minority_upsampled_4,\n",
    "                                 train_minority_upsampled_5])\n",
    "\n",
    "    # Show new class counts\n",
    "    print(train_upsampled.NHY.value_counts())\n",
    "    \n",
    "    return train_upsampled\n",
    "\n",
    "train_upsampled=upsampling_NHY(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    2386\n",
      "4.0    2386\n",
      "3.0    2386\n",
      "0.0    2386\n",
      "1.0    2386\n",
      "2.0    2386\n",
      "Name: NHY, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train_up = train_upsampled.loc[:,train.columns!='NHY']\n",
    "y_train_up= train_upsampled['NHY']\n",
    "data_up=upsampling_NHY(df_truncated)\n",
    "target_up=data_up['NHY']\n",
    "data_up.drop(columns='NHY',inplace=True)\n",
    "\n",
    "assert len(data_up)==len(target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PDMEDYN</th>\n",
       "      <th>ONLDOPA</th>\n",
       "      <th>ONDOPAG</th>\n",
       "      <th>ONOTHER</th>\n",
       "      <th>FULNUPDR</th>\n",
       "      <th>PDSURG</th>\n",
       "      <th>PDSURGTP</th>\n",
       "      <th>MSRARSP</th>\n",
       "      <th>MSLARSP</th>\n",
       "      <th>MSRLRSP</th>\n",
       "      <th>...</th>\n",
       "      <th>DXPOSINS</th>\n",
       "      <th>DXOTHSX</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>num_visits</th>\n",
       "      <th>VISIT_ID</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>PDSURGDT_diff_days</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th>INFODT_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3001</th>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2707</td>\n",
       "      <td>306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>394</td>\n",
       "      <td>2313</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>426</td>\n",
       "      <td>1887</td>\n",
       "      <td>1126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>335</td>\n",
       "      <td>1552</td>\n",
       "      <td>1461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>365</td>\n",
       "      <td>1187</td>\n",
       "      <td>1826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PDMEDYN  ONLDOPA  ONDOPAG  ONOTHER  FULNUPDR  PDSURG  \\\n",
       "PATNO INFODT_date                                                         \n",
       "3001  2011-02-01       0.0      0.0      0.0      0.0       0.0     0.0   \n",
       "      2012-03-01       0.0      0.0      0.0      0.0       1.0     0.0   \n",
       "      2013-05-01       1.0      0.0      0.0      1.0       0.0     0.0   \n",
       "      2014-04-01       1.0      0.0      1.0      1.0       0.0     0.0   \n",
       "      2015-04-01       1.0      1.0      0.0      1.0       1.0     0.0   \n",
       "\n",
       "                   PDSURGTP  MSRARSP  MSLARSP  MSRLRSP         ...          \\\n",
       "PATNO INFODT_date                                              ...           \n",
       "3001  2011-02-01        4.0      0.0      0.0      0.0         ...           \n",
       "      2012-03-01        4.0      0.0      0.0      0.0         ...           \n",
       "      2013-05-01        4.0      0.0      0.0      0.0         ...           \n",
       "      2014-04-01        4.0      0.0      0.0      0.0         ...           \n",
       "      2015-04-01        4.0      0.0      0.0      0.0         ...           \n",
       "\n",
       "                   DXPOSINS  DXOTHSX  DOMSIDE  num_visits  VISIT_ID  \\\n",
       "PATNO INFODT_date                                                     \n",
       "3001  2011-02-01          0        0        2           7         1   \n",
       "      2012-03-01          0        0        2           7         2   \n",
       "      2013-05-01          0        0        2           7         3   \n",
       "      2014-04-01          0        0        2           7         4   \n",
       "      2015-04-01          0        0        2           7         5   \n",
       "\n",
       "                   visitsdiff_days  lastDate_diff_days  PDDXDT_diff_days  \\\n",
       "PATNO INFODT_date                                                          \n",
       "3001  2011-02-01                 0                2707               306   \n",
       "      2012-03-01               394                2313               700   \n",
       "      2013-05-01               426                1887              1126   \n",
       "      2014-04-01               335                1552              1461   \n",
       "      2015-04-01               365                1187              1826   \n",
       "\n",
       "                   PDMEDT_diff_days  PDSURGDT_diff_days  \n",
       "PATNO INFODT_date                                        \n",
       "3001  2011-02-01                  0                   0  \n",
       "      2012-03-01                  0                   0  \n",
       "      2013-05-01                  0                   0  \n",
       "      2014-04-01                  0                   0  \n",
       "      2015-04-01                  0                   0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_up.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PATNO  INFODT_date\n",
       "3001   2011-02-01     2.0\n",
       "       2012-03-01     2.0\n",
       "       2013-05-01     2.0\n",
       "       2014-04-01     2.0\n",
       "       2015-04-01     2.0\n",
       "Name: NHY, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_up.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n",
    "X_resampled.shape\n",
    "logreg_smote = LogisticRegression(random_state=0).fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_resampled, y_resampled = ADASYN().fit_sample(X, y)\n",
    "#clf_adasyn = LinearSVC().fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=None, strategy='stratified')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy=DummyClassifier()\n",
    "dummy.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Score: 0.3417, Test-Accuracy: 0.3586\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-Score: %.4f, Test-Accuracy: %.4f\" % (dummy.score(X_train, y_train), dummy.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=0, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(multi_class='multinomial',solver='newton-cg',random_state=0)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_up=LogisticRegression(multi_class='multinomial',solver='newton-cg',random_state=1)\n",
    "logreg_up.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=1,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_up = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "rfc_up.fit(X_train_up, y_train_up)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "dict_weight={'0.0':0.4, '2.0':0.4, '1.0':0.4/3, '3.0':0.4/9, '4.0':0.4/27, '5.0':0.4/(27*8)}\n",
    "rfc_weighted = RandomForestClassifier(n_estimators=100, random_state=1,class_weight='balanced')\n",
    "rfc_weighted.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.16"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for estimator in rfc.estimators_:\n",
    "    #print(estimator.tree_.max_depth)\n",
    "np.mean([estimator.tree_.max_depth for estimator in rfc.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944444444444445"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4*2+0.4/3+0.4/9+0.4/27+0.4/(8*27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(n_jobs=-1,seed=0)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_up=XGBClassifier(n_jobs=-1,seed=0)\n",
    "xgb_up.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation: Calculating, plotting metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Score-logreg: 0.7873, Test-Accuracy-logreg: 0.7514\n",
      "Train-Score-logreg-up: 0.8231, Test-Accuracy-logreg-up: 0.6379\n",
      "Train-Score-rfc: 1.0000, Test-Accuracy-rfc: 0.7765\n",
      "Train-Score-rfc-up: 1.0000, Test-Accuracy-rfc: 0.7744\n",
      "Train-Score-rfc-weighted: 1.0000, Test-Accuracy-weighted: 0.7660\n",
      "Train-Score-xgb: 0.8253, Test-Accuracy-xgb: 0.7639\n",
      "Train-Score-xgb-up: 0.8864, Test-Accuracy-xgb-up: 0.6657\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-Score-logreg: %.4f, Test-Accuracy-logreg: %.4f\" % (logreg.score(X_train, y_train), \n",
    "                                                                logreg.score(X_test, y_test)))\n",
    "print(\"Train-Score-logreg-up: %.4f, Test-Accuracy-logreg-up: %.4f\" % (logreg_up.score(X_train_up, y_train_up), \n",
    "                                                                      logreg_up.score(X_test, y_test)))\n",
    "print(\"Train-Score-rfc: %.4f, Test-Accuracy-rfc: %.4f\" % (rfc.score(X_train, y_train), rfc.score(X_test, y_test)))\n",
    "print(\"Train-Score-rfc-up: %.4f, Test-Accuracy-rfc: %.4f\" % (rfc_up.score(X_train_up, y_train_up), \n",
    "                                                             rfc_up.score(X_test, y_test)))\n",
    "print(\"Train-Score-rfc-weighted: %.4f, Test-Accuracy-weighted: %.4f\" % (rfc_weighted.score(X_train, y_train), \n",
    "                                                             rfc_weighted.score(X_test, y_test)))\n",
    "\n",
    "print(\"Train-Score-xgb: %.4f, Test-Accuracy-xgb: %.4f\" % (xgb.score(X_train, y_train), \n",
    "                                                         xgb.score(X_test, y_test)))\n",
    "print(\"Train-Score-xgb-up: %.4f, Test-Accuracy-xgb-up: %.4f\" % (xgb_up.score(X_train_up, y_train_up), \n",
    "                                                         xgb_up.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b62db38>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_logreg=logreg.predict(X_test)\n",
    "cm_logreg=confusion_matrix(y_test,y_pred_logreg)\n",
    "cm_logreg_df=pd.DataFrame(cm_logreg,index=[0,1,2,3,4,5],columns=[0,1,2,3,4,5])\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm_logreg_df,annot=True,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b70f7b8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_rfc=rfc.predict(X_test)\n",
    "cm_rfc=confusion_matrix(y_test,y_pred_rfc)\n",
    "cm_rfc_df=pd.DataFrame(cm_rfc,index=[0,1,2,3,4,5],columns=[0,1,2,3,4,5])\n",
    "sns.heatmap(cm_rfc_df,annot=True,cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.95      0.94       385\n",
      "        1.0       0.52      0.29      0.38       248\n",
      "        2.0       0.72      0.88      0.79       715\n",
      "        3.0       0.41      0.15      0.22        73\n",
      "        4.0       0.12      0.10      0.11        10\n",
      "        5.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.72      0.75      0.73      1436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_logreg = classification_report(y_test, \n",
    "                      y_pred_logreg)\n",
    "print(report_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.95      0.95       385\n",
      "        1.0       0.63      0.30      0.41       248\n",
      "        2.0       0.72      0.93      0.82       715\n",
      "        3.0       0.67      0.08      0.15        73\n",
      "        4.0       1.00      0.10      0.18        10\n",
      "        5.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.76      0.78      0.74      1436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "report_rfc = classification_report(y_test, \n",
    "                      y_pred_rfc)\n",
    "print(report_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      0.95      0.95       385\n",
      "        1.0       0.58      0.38      0.45       248\n",
      "        2.0       0.74      0.90      0.81       715\n",
      "        3.0       0.50      0.10      0.16        73\n",
      "        4.0       1.00      0.10      0.18        10\n",
      "        5.0       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.75      0.77      0.75      1436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred_rfc_up=rfc_up.predict(X_test)\n",
    "report_rfc_up = classification_report(y_test, \n",
    "                      y_pred_rfc_up)\n",
    "print(report_rfc_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import LeaveOneOut, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "# C = 1/lambda, the parameter of the sigmoid function\n",
    "# lambda = 0.001, 0.005, 0.01, 0.05, ..., 1, 5, 10, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cross_validate_rfc=cross_validate(rfc,data,target,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_xgb=cross_validate(xgb,data,target,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_lr=cross_validate(logreg,data,target,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_rfc_up=cross_validate(rfc_up,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_xgb_up=cross_validate(xgb_up,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_lr_up=cross_validate(logreg_up,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy LR: 0.80 (+/- 0.02)\n",
      "Training Accuracy RF: 1.00 (+/- 0.00)\n",
      "Training Accuracy XGB: 0.84 (+/- 0.01)\n",
      "Test Accuracy LR: 0.61 (+/- 0.27)\n",
      "Test Accuracy RF: 0.64 (+/- 0.29)\n",
      "Test Accuracy XGB: 0.63 (+/- 0.28)\n"
     ]
    }
   ],
   "source": [
    "#print(cross_validate_lr)\n",
    "print(\"Training Accuracy LR: %0.2f (+/- %0.2f)\" % (cross_validate_lr['train_score'].mean(), cross_validate_lr['train_score'].std() * 2))\n",
    "print(\"Training Accuracy RF: %0.2f (+/- %0.2f)\" % (cross_validate_rfc['train_score'].mean(), cross_validate_rfc['train_score'].std() * 2))\n",
    "print(\"Training Accuracy XGB: %0.2f (+/- %0.2f)\" % (cross_validate_xgb['train_score'].mean(), cross_validate_xgb['train_score'].std() * 2))\n",
    "\n",
    "print(\"Test Accuracy LR: %0.2f (+/- %0.2f)\" % (cross_validate_lr['test_score'].mean(), cross_validate_lr['test_score'].std() * 2))\n",
    "print(\"Test Accuracy RF: %0.2f (+/- %0.2f)\" % (cross_validate_rfc['test_score'].mean(), cross_validate_rfc['test_score'].std() * 2))\n",
    "print(\"Test Accuracy XGB: %0.2f (+/- %0.2f)\" % (cross_validate_xgb['test_score'].mean(), cross_validate_xgb['test_score'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy LR upsampled: 0.80 (+/- 0.03)\n",
      "Training Accuracy RF upsampled: 1.00 (+/- 0.00)\n",
      "Training Accuracy XGB upsampled: 0.88 (+/- 0.02)\n",
      "Test Accuracy LR upsampled: 0.74 (+/- 0.04)\n",
      "Test Accuracy RF upsampled: 0.90 (+/- 0.07)\n",
      "Test Accuracy XGB upsampled: 0.80 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "#print(cross_validate_lr)\n",
    "print(\"Training Accuracy LR upsampled: %0.2f (+/- %0.2f)\" % (cross_validate_lr_up['train_score'].mean(), cross_validate_lr_up['train_score'].std() * 2))\n",
    "print(\"Training Accuracy RF upsampled: %0.2f (+/- %0.2f)\" % (cross_validate_rfc_up['train_score'].mean(), cross_validate_rfc_up['train_score'].std() * 2))\n",
    "print(\"Training Accuracy XGB upsampled: %0.2f (+/- %0.2f)\" % (cross_validate_xgb_up['train_score'].mean(), cross_validate_xgb_up['train_score'].std() * 2))\n",
    "\n",
    "print(\"Test Accuracy LR upsampled: %0.2f (+/- %0.2f)\" % (cross_validate_lr_up['test_score'].mean(), cross_validate_lr_up['test_score'].std() * 2))\n",
    "print(\"Test Accuracy RF upsampled: %0.2f (+/- %0.2f)\" % (cross_validate_rfc_up['test_score'].mean(), cross_validate_rfc_up['test_score'].std() * 2))\n",
    "print(\"Test Accuracy XGB upsampled: %0.2f (+/- %0.2f)\" % (cross_validate_xgb_up['test_score'].mean(), cross_validate_xgb_up['test_score'].std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76434728]\n",
      "0.9078014184397163\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <td>0.083899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIRTHDT</th>\n",
       "      <td>0.038845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <td>0.037973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRIMDIAG</th>\n",
       "      <td>0.031572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYSSTND</th>\n",
       "      <td>0.030584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOMSIDE</th>\n",
       "      <td>0.029472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIASTND</th>\n",
       "      <td>0.028454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRSTND</th>\n",
       "      <td>0.028355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <td>0.028215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIASUP</th>\n",
       "      <td>0.027865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HRSUP</th>\n",
       "      <td>0.026745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYSSUP</th>\n",
       "      <td>0.025147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_visits</th>\n",
       "      <td>0.021194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APPRDX</th>\n",
       "      <td>0.020152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CURRENT_APPRDX</th>\n",
       "      <td>0.019694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLRLRSP</th>\n",
       "      <td>0.018751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFBRADYP</th>\n",
       "      <td>0.018594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXTREMOR</th>\n",
       "      <td>0.017849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MHROW_2</th>\n",
       "      <td>0.015687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXBRADY</th>\n",
       "      <td>0.015603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFRIGIDP</th>\n",
       "      <td>0.015047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SENLLRSP</th>\n",
       "      <td>0.014238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFPGDIST</th>\n",
       "      <td>0.013773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VISIT_ID</th>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MHROW_3</th>\n",
       "      <td>0.013314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLRRRSP</th>\n",
       "      <td>0.011866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PDMEDYN</th>\n",
       "      <td>0.011321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SENRLRSP</th>\n",
       "      <td>0.011207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DXRIGID</th>\n",
       "      <td>0.011116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGLCRSLT</th>\n",
       "      <td>0.010828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TOPRRSLT</th>\n",
       "      <td>0.010766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFRIGIDA</th>\n",
       "      <td>0.010722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFBRADYA</th>\n",
       "      <td>0.010620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFFALLS</th>\n",
       "      <td>0.010608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONLDOPA</th>\n",
       "      <td>0.010448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFURDYS</th>\n",
       "      <td>0.010356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DFCOGNIT</th>\n",
       "      <td>0.010138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    importance\n",
       "PDDXDT_diff_days      0.083899\n",
       "BIRTHDT               0.038845\n",
       "lastDate_diff_days    0.037973\n",
       "PRIMDIAG              0.031572\n",
       "SYSSTND               0.030584\n",
       "DOMSIDE               0.029472\n",
       "DIASTND               0.028454\n",
       "HRSTND                0.028355\n",
       "visitsdiff_days       0.028215\n",
       "DIASUP                0.027865\n",
       "HRSUP                 0.026745\n",
       "SYSSUP                0.025147\n",
       "num_visits            0.021194\n",
       "APPRDX                0.020152\n",
       "CURRENT_APPRDX        0.019694\n",
       "PLRLRSP               0.018751\n",
       "DFBRADYP              0.018594\n",
       "DXTREMOR              0.017849\n",
       "MHROW_2               0.015687\n",
       "DXBRADY               0.015603\n",
       "DFRIGIDP              0.015047\n",
       "SENLLRSP              0.014238\n",
       "DFPGDIST              0.013773\n",
       "VISIT_ID              0.013333\n",
       "MHROW_3               0.013314\n",
       "PLRRRSP               0.011866\n",
       "PDMEDYN               0.011321\n",
       "SENRLRSP              0.011207\n",
       "DXRIGID               0.011116\n",
       "TGLCRSLT              0.010828\n",
       "TOPRRSLT              0.010766\n",
       "DFRIGIDA              0.010722\n",
       "DFBRADYA              0.010620\n",
       "DFFALLS               0.010608\n",
       "ONLDOPA               0.010448\n",
       "DFURDYS               0.010356\n",
       "DFCOGNIT              0.010138"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(rfc_up.feature_importances_,\n",
    "                                   index = X_train.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "ImportantFeatures=feature_importances[feature_importances.values>=0.01]\n",
    "RelevantFeatures=feature_importances[feature_importances.values>0]\n",
    "RelevantFeaturesList=list(RelevantFeatures.index)\n",
    "print(sum(ImportantFeatures.values))\n",
    "print(len(RelevantFeatures)/len(feature_importances))\n",
    "ImportantFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn0AAAJcCAYAAACMgxJeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzs3Xm8XVV99/HPlxkKVpAAYdCUMBvgaq5ViyAIVFQQrVVEqqLY1KeVIhYEiz4ixalQ02JQiIwqg0WFUogCjxABjZhzJTNEDWFIZEikWgIRIXyfP/Y6unNz7pDk3tzhfN+v13l17zXttW9KX7+utddask1EREREjG4bDXUHIiIiImLwJeiLiIiIaAMJ+iIiIiLaQIK+iIiIiDaQoC8iIiKiDSToi4iIiGgDCfoiIiIi2kCCvojY4CQ9KGmlpBW1387r2eahkpYMVB/7+cwrJJ27IZ/ZE0lnS/rmUPcjIoavBH0RMVSOsb117feroeyMpE2G8vnrYyT3PSI2nAR9ETGsSHqNpB9L+o2k2ZIOreV9QNJ9kp6S9ICkvyvpfwJ8D9i5PnLYfSSu+2hgGXE8Q9Ic4GlJm5R635G0TNJiSf/Yz36Pk+TSx0ck/Y+kD0t6laQ55X2m1MqfKOlHkqZI+q2k+yUdXsvfWdKNkp6U9EtJf1vLO1vStyV9U9L/Ah8G/hk4rrz77N7+XvW/haR/kvSEpEclfaCWv6Wkf5P0UOnf3ZK27Me/0YnlWU+Vv98J/fn7RcTgy/93GBHDhqRdgJuB9wLfBw4HviNpH9vLgCeAo4EHgEOA70maaftnkt4EfNP2rrX2+vPY44G3AMuBF4D/Bv6rpO8K/D9JC23f0s/XeDWwZ+nfjeU9jgA2Be6VdJ3tH9bKfhvYHvgr4LuS/sz2k8C1wDxgZ2Af4DZJi2zfXuoeC7wTeB+weWljD9t/U+tLj3+vkr8T8KfALsCRwLcl3WD7f4DzgZcDfwE8Vvr6Qm//RsAzwAXAq2wvlDQW2K6ff7eIGGQZ6YuIoXJDGSn6jaQbStrfANNsT7P9gu3bgAbwZgDbN9te5MoPgVuBg9ezHxfYfsT2SuBVwBjb59j+ve0HgK8B716L9v7F9u9s3wo8DVxj+wnbS4G7gFfUyj4B/Lvt52x/C1gIvEXSbsBBwBmlrVnAJVQBXtMM2zeUv9PKVh3px9/rOeCc8vxpwApgb0kbAR8ETrG91PYq2z+2/Sx9/BtRBc4TJG1p+1Hb89fibxcRgyhBX0QMlbfZfnH5va2kvQx4Zy0Y/A3wOmAsgKQ3SfpJmfL8DVWgsf169uOR2vXLqKaI68//Z2DHtWjv8dr1yhb3W9ful9p27f4hqpG9nYEnbT/VLW+XHvrdUj/+Xr+2/Xzt/pnSv+2BLYBFLZrt8d/I9tPAcVTTzY9KurmMAEbEMJCgLyKGk0eAb9SCwRfb/hPbX5C0OfAdqmnHHW2/GJgGNOdw3aK9p4Gtavc7tShTr/cIsLjb87ex/eYW9QbCLlp9DvqlwK/KbztJ23TLW9pDv9e478ffqzfLgd8B41vk9fhvBGD7FttHUgXq91ONlEbEMJCgLyKGk28Cx0h6o6SNJW1RFhzsCmxG9e3aMuD58g3fX9bqPg68RNKf1tJmAW+WtJ2knYCP9vH8nwJPlcUdW5Y+TJD0qgF7w9XtAPyjpE0lvRPYl2rq9BHgx8Dny9/gAOAkqr9PTx4HxpWpWej779Uj2y8AlwFfKgtKNpb02hJI9vhvJGlHSceqWljzLNV08Qtr+TeJiEGSoC8iho0S7BxLNaW6jGpU6XRgozLV+Y/AfwL/A7yHaqFEs+79wDXAA2XacWfgG8Bs4EGq79m+1cfzV1EtfOgAFlONeF1CtdhhMNxDtehjOfBZ4K9t/7rkHQ+Moxr1ux74tO3/10tb15X/+WtJP+vr79UPpwFzgZnAk8AXqf4devw3Kr+PlT4/Cbwe+D9r8cyIGERa/XOSiIjYECSdCHzI9uuGui8R0R4y0hcRERHRBhL0RURERLSBTO9GREREtIGM9EVERES0gRzD1sL222/vcePGDXU3IiIiIvrU1dW13PaYvsol6Gth3LhxNBqNoe5GRERERJ8kPdSfcpnejYiIiGgDCfoiIiIi2kCCvoiIiIg2kKAvIiIiog0k6IuIiIhoAwn6IiIiItpAgr6IiIiINpCgLyIiIqINJOiLiIiIaAMJ+iIiIiLaQIK+iIiIiDaQoC8iIiKiDSToi4iIiGgDCfoiIiIi2kCCvoiIiIg2kKAvIiIiog0k6IuIiIhoAwn6IiIiItpAgr6IiIiINpCgLyIiIqINJOiLiIiIaAMJ+iIiIiLaQIK+iIiIiDawyVB3YDjq6gJpqHsRERERI5U91D1YU0b6IiIiItrAkAR9klZ0uz9R0pRyfbakpZJmSVog6fhauddIuqfk3Sfp7Fqd07q1+aCk7cv1qlJnnqTrJG016C8ZERERMYwM15G+ybY7gGOBiyVtWtKvBCaVvAnAf/azvZW2O2xPAH4PfHjAexwRERExjA3XoA8A278AngG2LUk7AI+WvFW2F6xDs3cBewxMDyMiIiJGhqFayLGlpFm1++2AG7sXkvRK4Be2nyhJk4GFkqYD3weutP27/j5U0ibAm0rd7nmTgEnV3Uv722RERETEiDBUI33N6daOMlX7f7vlnyppPnAP8Nlmou1zgE7gVuA9/DF462mNTDO9GWQ2gIeBS9coaE+13Wm7E8as63tFREREDEvDdcuWybbPl/RW4FJJ45sjerYXAV+V9DVgmaSXAL8GxnZrYxvgN+V6ZQkuIyIiItrScP+m70aq0bn3A0h6i/SHHfT2BFZRBXZ3Am+VtE0p91fAbNurNnyvIyIiIoaf4TrSV3cOcHUZ2XsvMFnSM8DzwAklsJtTtny5W5KBJ4APDVmPIyIiIoYZeThuGT3EpE5XA4wRERERa29DhleSuqo1Cb0bCSN9G9zEidBIzBcRERGjyLD+pi8iIiIiBkZG+lro6oI/LBeJiFEhX7JERLvLSF9EREREG0jQFxEREdEGBizok7RK0ixJ8yRdJ2mrkr6iRdmzJS0t5RdIOr6Wd4WkxSVvtqTDa3nTJS0s6TMlddTyPihprqQ5pQ/HtmjvZ5JeO1DvHBERETFSDORIX/NotQnA74EP91F+cjkl41jgYkmb1vJOL3kfBS7qVu8E2wcCXwHOA5C0K3AW8DrbBwCvAea0aO9M4OJ1e72IiIiIkWuwpnfvAvboT0HbvwCeAbZtkT0D2KWHqvW8HYCngBWlzRW2F7eoc2d/+xURERExmgx40CdpE+BNwNx+ln8l8AvbT7TIPgq4oYeq9bzZwOPAYkmXSzqmhzrH9NQvSZMkNSQ1YFl/uh4RERExYgzkli1bSppVru8CLu2j/KmSPgDsRRWM1Z0n6XPArkD3b/CukrQZsDXQAWB7laSjgFcBh1Md1TbR9tm19j5JFc2d1KoztqcCU6F5IkdERETE6DEY3/R12D7Z9u/7KD/Z9suBdwCXStqilne67b2AM4DLutU7AdgduBL4cjPRlZ/a/jzw7tJuvb0O20fanreO7xcRERExYg35li22b6Q66Pb9LbKnABtJemO3OgY+BbxG0j6Sdi7TxE0dwEOD1eeIiIiIkWZDBH1bSVpS+32sRZlzgI9JWq0/Jbg7F/h49wq2VwL/BpwObAqcL+n+MsV8HHDKQL9IRERExEgl52yiNXR2drrRaAx1NyIiIiL6JKnLdmdf5YZ8ejciIiIiBl+CvoiIiIg2MJBbtowaXV0gDXUvImJd5IuViIjWMtIXERER0QY2SNAnaZWkWZLmS5ot6Z+aK3UlHSrppm7lb5D0k25pe0uaXtq5T1LZSFknSprSrex0SZ3l+kFJcyXNkXSrpJ0G920jIiIihp8NNdLX3Lj55cCRVMe0fbpVQUkvBiYCfypp91rWBVQbOnfY3pfaxsz9cJjtA6j2A/zndXqDiIiIiBFsg0/vljN2JwEfkVp+OfdXwH8D11KdrNE0FlhSa6dfZ/t2cyewxzrUi4iIiBjRhuSbPtsPABsDO7TIPh64pvyOr6VPBm6X9D1Jp5YRwbV1NNAyWJQ0SVJDUqM6ojciIiJi9BhWCzkk7QjsCdxt++fAc5ImANi+HNgXuA44FPiJpM2Bntbq1dPvKCd1vAj4fMvC9lTbndXmhmMG5H0iIiIihoshCfrKt3qrgCe6Zb0L2BZYLOlBYBy10T7bv7J9me1jgeeBCcCvS5267YDltfvDyreA77P9m4F8l4iIiIiRYIMHfZLGABcBU7zmGXDHA0fZHmd7HNWCjneXekdJ2rRc7wS8BFgKzAQOaq7KLat2Nwce2QCvExERETEibKjNmbcs06ubUo3QfQP4Ur2ApHHAy4A/bNVie7Gk30p6NfCXwH9I+l3JPt32Y6XuKcC0sg3MCuB42y8M7itFREREjBxac7AtpE5Xu7tExEiT/5MWEe1GUle1JqF3OYathYkToZGYLyIiIkaRYbV6NyIiIiIGR0b6WujqgpbbRkdEpk8jIkaojPRFREREtIEEfRERERFtYJ2DPkmrJM2SNE/SfzePRZM0TtLKktf8bSbpRElTWrTzoKTtu6X1VnaupDmSfijpZbW8syTNL3mzyjYvSJouaaGk2ZJ+JGnvdX3niIiIiJFqfUb6VpZTLiYATwL/UMtbVPKav9+vXzdXc5jtA4DpwCcBJL2W6lzdV5a8I1h9c+YTbB8IXAmcN4B9iYiIiBgRBmp6dwawywC1tS7PHAsst/0sgO3ltn/Vos6dwB4bqH8RERERw8Z6B32SNgYOB26sJY+vTe1euL7P6MFRwA3l+lZgN0k/l/QVSa/voc4xwNxWGZImSWpIasCyQehuRERExNBZny1bmker7QLcB9xWy1tku2O9etazOyRtR3Xc2qcAbK+QNBE4GDgM+JakM21fUepcJWkl8CBwcqtGbU8FpkLzRI6IiIiI0WO9v+mjOi9XrP5N32A6rDxzFvCZZqLtVban2/408BHgHbU6J5RvC99m+xEiIiIi2sx6T+/afgb4R+CfJG2QzZ5tPw98FHifpO0k7S1pz1qRDuChDdGXiIiIiJFgQBZy2L4XmAMc30fREyUtqf12Lelzamlf6qNs85mPAtdQjTBuDVwpaYGkOcB+wNkD8W4RERERo4GcM5XW0NnZ6UajMdTdiIiIiOiTpC7bnX2Vy4kcEREREW0gQV9EREREG9ggCy9Gmq4ukIa6FxFDJ199RESMPhnpi4iIiGgDA3EihyV9s3a/iaRlkm4q9ztKuknS7LK6dlpJHydpZTm1Y4Gkr0vatOQd2qzf7VnTJS0sbc2U1FHL+6CkuZLmSJon6diSfoWkxeU5Pyvn9EZERES0lYEY6XsamCBpy3J/JLC0ln8OcJvtA23vB5xZy2ue3LE/sCvwrn487wTbBwJfAc4DKNu5nAW8zvYBwGuotpBpOr0850zg4rV9wYiIiIiRbqCmd6cBbynXx1Ptn9c0FljSvLFdD8aaaauAn1Id6dZfM2rldwCeojqaDdsrbC9uUedOYI+1eEZERETEqDBQQd+1wLslbQEcANxTy7sQuFTSHZLOkrRz98ql3quB76/FM48CbijXs4HHgcWSLpd0TA91jgHmtsqQNElSQ1IDlq1FNyIiIiKGvwFZvWt7jqRxVKN807rl3SJpd6og7U3AvZImlOzxkmYBfwbc3GoUsIWrJG1GdQpHR3nGKklHAa8CDgcmS5po++xS5zxJn6SK5k7q4R2mAlMBpM6sXYyIiIhRZSBX794InM/qU7sA2H7S9tW23wvMBA4pWc1v+sYDEyW9tR/POQHYHbgS+HLtGbb9U9ufB94NvKNW53TbHbaPtD1vXV4uIiIiYiQbyKDvMuAztlebPpX0BklblettqAK8h+tlbC+nWmTxif48yNXZcZ8CXiNpH0k7S3plrUgH8NA6v0lERETEKDNgQZ/tJbYvaJE1EWhImkO1+OIS2zNblLsB2ErSweX+cElLar/VtlqxvRL4N+B0YFPgfEn3l+ni44BTBujVIiIiIkY8OVvvr6Gzs9ONRmOouxERERHRJ0ldtjv7KpcTOSIiIiLaQIK+iIiIiDYwIFu2jDZdXSANdS8iBle+7IiIaC8Z6YuIiIhoA2sV9EnaSdK1khZJ6pI0TdJekizp5Fq5KZJOLNcHSpohaa6k/5b0opL+knJKxwpJU7o9Z2Ip/0tJF0jVuJukKyQtljRL0mxJh9fqHC3p3pK+QNLflfSzJS0tdeb1cy/AiIiIiFGl30FfCbyuB6bbHm97ItW+ejsCTwCnlJMyursEONP2/qX+6SX9d1R77Z3Wos5Xgb8F9iy/o2p5p5cNnT8KXFT6tinVaRrH2D4QeAUwvVZncqnzTuAySRnhjIiIiLayNsHPYcBzti9qJtieDTxCdbzZD4D3t6i3F3Bnub6NclKG7adt300V/P2BpLHAi2z/pGzC/HXgbS3anQHsUq63ofo+8del7WdtL+xewfZ9wPPA9v154YiIiIjRYm2CvglAVy/5XwROk7Rxt/T5wLHl+p3Abn08ZxdgSe1+CX8M7uqOotrQGdtPUh0D95CkaySd0Go0T9KrgReogtTueZMkNSQ1WmRHREREjGgDeSLHA8A9wHu6ZX0Q+HtJXVQjcr9fz0edJ+nnwNVUgWbz+R8CDgd+SjVlfFmtzqnlpI7zgePcYkdq21Ntd1abG45Zzy5GREREDC9rE/TNpzpSrTefA84A/rDhie37bf9l+QbwGmBRH20sBXat3e9a0ppOt71XeU49sMP2XNuTgSMp08jFZNsdtg+2fVcfz4+IiIgYddYm6Lsd2FzSpGaCpAOoTdfavh9YABxTK7ND+Z8bAZ+kLL7oie1Hgf+V9JqyeOR9wH+1KDoF2EjSGyVtLenQWl4H8NBavFtERETEqNbvoK9Mib4dOKJs2TIf+DzwWLein2X1kbrjy3Ts/cCvgMubGZIeBL4EnChpiaT9StbfU636/SXVyOD3eujPucDHqUYWPy5pYZnG/QxwYn/fLSIiImK0U4vP29qe1GloDHU3IgZV/tOPiBgdJHVVaxJ6l2PYWpg4ERqJ+SIiImIUySbFEREREW0gI30tdHWB1He5iJEg07gREQEZ6YuIiIhoCwn6IiIiItrAgAV9kizpm7X7TSQtk3RTud9R0k2SZktaIGlaSR8naV6L9q6Q9Nfd0sZJWilpVmnj65I2LXlbSbpK0lxJ8yTdLWnrkreq1Jkn6TpJWw3Ue0dERESMBAM50vc0MEHSluX+SFY/SeMc4DbbB9reDzhzHZ+zyHYHsD/VfoDvKumnAI/b3t/2BOAk4LmSt7KcyDGB6hi4D6/jsyMiIiJGpIGe3p0GvKVcH0917FrTWGBJ88b2nPV5kO1VVOfs7lJrf2ktf6HtZ1tUvQvYY32eHRERETHSDHTQdy3wbklbAAcA99TyLgQulXSHpLMk7bw+DyrPeDXw/ZJ0GXCGpBmSzpW0Z4s6mwBvAua2yJskqSGpAcvWp2sRERERw86ABn1l9G4c1SjftG55twC7A18D9gHulTRmHR4zvhy19jjwaHPE0Pas0v55wHbATEn7ljpbljoN4GHg0hZ9n2q7s9rRel26FRERETF8DcY+fTcC5wOHAi+pZ9h+ErgauLos8DgE6FrL9hfZ7pC0PfAjSW+1fWNpfwXwXeC7kl4A3gzcR/mmbz3eKSIiImJEG4wtWy4DPmN7tSlUSW9orpqVtA0wnmrUbZ3YXk61GOQTpc2DJG1brjcD9gMeWtf2IyIiIkaTAQ/6bC+xfUGLrIlAQ9IcYAZwie2ZJW9vSUtqv3eW9ItraTNatHkDsJWkg6mCyB9KmgvcSzWV+50BfbmIiIiIEUrOGU1r6OzsdKPRGOpuRERERPRJUle1JqF3OZEjIiIiog0k6IuIiIhoA4OxenfE6+oCaah7EbH+8vVGREQ0ZaQvIiIiog30K+iTtJOkayUtktQlaZqkvSS9XNLtkhZK+oWkT0nVGJmkEyUtkzSr/L5e0q+QtFTS5uV+e0kPlutxklaW8gskfV3SpiXvUEm/LXn3Szq/1r8dJd0kaXapN62H9i6SlEA3IiIi2k6fAVAJ4q4Hptseb3si1d54O1JtxPwF23sDBwJ/Afx9rfq3bHeU3/tq6auAD/bwyEVlI+X9gV2Bd9Xy7ip5rwCOlnRQST8HuM32gbb3o9q/r3t7B1Dt3fe2vt45IiIiYrTpz6jXYcBzti9qJtieDewF/Mj2rSXtGeAjrB5w9eTfgVPLWbgt2V4F/BTYpUXeSmBWLW8ssKSWP6dFneeBHwN79KN/EREREaNKf4K+CbQ+Ku3l3dNtLwK2lvSiknRcbXr3A7WiDwN3A+/t6aGStgBeDXy/Rd62wJ7AnSXpQuBSSXdIOkvSzi3qbAUcDsztnlfyJ0lqSGrAsp66FRERETEiDfb3bfXp3cu75X0eOL1FH8ZLmgU8DjzabdTuYEmzgaXALbYfA7B9C7A78DVgH+BeSWO6tfcj4Gbb32vVUdtTbXdWmxuOaVUkIiIiYsTqT9A3n+oIte4WdE+XtDuwwvb/9tWo7V9QTdG+q1tW8xu88cBESW+t5d1l+0CqUcaTJHXU2nvS9tW23wvMBA6pt2f7FbbP7qtfEREREaNRf4K+24HNJU1qJkg6AFgIvE7SESVtS+AC4F/X4vmfBU5rlWF7OdX3gZ9okbcY+AJwRnn2G8r0LZK2oQoYH16LfkRERESMan0Gfa4O5307cETZsmU+1dTsY8CxwCclLaT6Vm4mMKW/D7c9H/hZL0VuALaSdHCLvIuAQySNoxpxbEiaA8wALrE9s7/9iIiIiBjt5GzZvwap09AY6m5ErLf85x0RMfpJ6qrWJPQux7C1MHEiNBLzRURExCiS0ykiIiIi2kBG+lro6oLqMLmIkStTuxERUZeRvoiIiIg2kKAvIiIiog1skKCvHI02X9KcciTb9yR9sZb/MkkPSHqxpKMl3StptqQFkv6ulNlb0vRS/z5JU0v6iZKmdHvedEmd5fpBSXPLs2+VtNOGeOeIiIiI4WTQv+mT9FrgaOCVtp+VtD2wOXC7pCts3wf8B/Ap4GlgKvDntpdI2hwYV5q6AJhs+79Ku/uvRTcOs71c0ueAfwb+cSDeLSIiImKk2BAjfWOB5bafheqkDdtLgVOBCyW9GdjG9lXANlSB6K9L2WdtL6y1s6TZqO2569CXO4E91vlNIiIiIkaoDRH03QrsJunnkr4i6fUAtqcB/wNcCfx9SXsSuBF4SNI1kk6Q1OzjZKrRwe9JOlXSi9ehL0dTnRyyBkmTJDUkNWDZOjQdERERMXwNetBnewXVMWmTqKKpb0k6sWRfCMysjeZh+0PA4cBPqc7lvaykXw7sC1wHHAr8pEz/9rQxRT39DkmzgBdRHSHXqp9TbXdWO1qPWYc3jYiIiBi+Nsg+fbZXAdOB6ZLmAu8HrgBeKL/u5ecCcyV9A1gMnFjSf0UVBF4maR4wgWoqeNtuTWwHLK/dH2Z7ORERERFtatBH+sqq2z1rSR3AQz2U3VrSoa3KSjpK0qbleifgJcBSYCZwUHNVblm1uznwyAC/SkRERMSItSFG+rYGvly+wXse+CXVVG8rAj4u6WJgJdVq3hNL3l8C/yHpd+X+dNuPAUg6BZhWvv9bARxve40RxIiIiIh2JeespjV0dna60WgMdTciIiIi+iSpq1qT0LucyBERERHRBhL0RURERLSBDbJ6d6Tp6gJpqHsRsW7yxUZERLSSkb6IiIiINrBeQZ8kS/pm7X4TScsk3VTud5R0k6TZkhZImlbSx0laKWlWSf96czuWWlv/Lmlp7UQOJJ1Y2p8l6X5Jp9by9pY0veTdJ2lqST9U0m9r6Z9en3eOiIiIGInWd6TvaWCCpC3L/ZFUe+c1nQPcZvtA2/sBZ9byFtnuAPYHdgXe1cwogd7bqfbae323Z36r1DsIOEvSbiX9AmCy7Q7b+wJfrtW5q9TpBP5G0ivX/ZUjIiIiRp6BmN6dBrylXB8PXFPLGwssad7YntO9cjmt46fALrXkQ4H5wFdLm2uw/WuqPf/G9vCsNc7Ytf000AXs0fsrRURERIwuAxH0XQu8W9IWwAHAPbW8C4FLJd0h6SxJO3evXOq9Gvh+LbkZPF4PvKX71G+p91JgC6AZSE4Gbpf0PUmnls2gu9d5CfAaqoCye94kSQ1JjeqI4IiIiIjRY72DvjJ6N44qUJvWLe8WYHfga8A+wL2SxpTs8ZJmAY8DjzZHASVtBrwZuMH2/1IFkW+sNXucpDlUo3xfsf278qzLgX2B66hGCn8iafNS52BJ9wK3Al+wvUbQZ3uq7c5qc8Mx3bMjIiIiRrSBWr17I3A+q0/tAmD7SdtX234v1Tm5h5Ss5jd944GJkt5a0t8IvBiYK+lB4HWsPsX7LdsHAH8BfKF55m551q9sX2b7WKoj3yaUrLtsv8L2RNsXDdA7R0RERIwYAxX0XQZ8pvt3dJLeIGmrcr0NVYD3cL2M7eVUCzw+UZKOBz5ke5ztccCfAUc226nVawDfAE4p7R/VnAYugeBLWH1RSURERETbGpCgz/YS2xe0yJoINMp07AzgEtszW5S7AdhK0uuBo4Cba20/DdwNHNOi3heBD5SA8i+BeZJmA7cAp9t+bH3eKyIiImK0kLN9/xqkTkNjqLsRsU7yn3RERHuR1FWtSehdjmFrYeJEaCTmi4iIiFEkx7BFREREtIGM9LXQ1QXSUPciomeZwo2IiLWVkb6IiIiINpCgLyIiIqINrHfQJ8mSvlm730TSMkk3lfsdJd0kabakBZKmlfRxkub10GazjS90S58uaWFpa6akjlreByXNlTRH0jxJx5b0KyQtljRL0s8kvXZ93zkiIiJipBmIkb6ngQmStiz3R7L6psjnALfZPtD2flQbMfflSODnwDulNb6uO8H2gcBXgPMAJO0KnAW8rpzW8Rr+eCYvVHv2dZRnX7xWbxcRERExCgzU9O404C3l+nhWP45tLLCkedM8Y7cPxwP/QXV6R08jczOAXcr1DsBTwIryjBW2F7eocyewRz+eHxERETGqDFTQdy2tbynzAAAgAElEQVTwbklbAAcA99TyLgQulXSHpLMk7dxbQ6WNI4D/pgoej++h6FFUJ3kAzAYeBxZLulxSq9M7oDrVY26rDEmTJDUkNWBZb12MiIiIGHEG6hi2OcA4qgBtWre8W4Ddga8B+wD3ShrTS3NHA3fYXgl8B3ibpI1r+VdJWkw1nXthecYqqiDwr6mmhSdLOrtW5zxJs4BJwEk9vMNU253Vjta9dS8iIiJi5BnI1bs3Auez+tQuALaftH217fcCM4FDemnneOAISQ8CXcBLgDfU8k+gCiKvBL5ce4Zt/9T254F3A++o1TnddoftI223XDwSERERMZoNZNB3GfAZ26tNn0p6g6StyvU2wHiqb/XWIOlFwMHAS22Psz0O+Ae6TfG6OjD4U8BrJO0jaWdJr6wV6QAeGpjXioiIiBj5Bizos73E9gUtsiYCDUlzqBZfXGJ7ZsnbW9KS5g94O3C77Wdr9f8LOEbS5t2etxL4N+B0YFPgfEn3l2nc44BTBurdIiIiIkY6Oec5raGzs9ONRmOouxERERHRJ0ld1ZqE3uVEjoiIiIg2kKAvIiIiog1sMtQdGI66umCNc0AiNoB8bREREYMlI30RERERbaBfI32SVlGdZLEJcB/wftvP1NI3BZ4Hvg5Mtv1C2abla1QndAj4DdUGytsDN9meUGv/bGCF7fMlXQG8Hvhtqfcx2z8o5TahOsv3nVRn/gJcB1wE/KDc7wSs4o/Havw5sLJV//v3J4qIiIgY+fo70reybG48Afg98OFu6S8HjgTeBHy65J0CPG57/1LvJOC5fj7vdNsdwEepArqmc4Gdgf1L/sHAprZ/XfrRUcpPbt7b/n0v/Y+IiIhoC+syvXsXsEf3RNtPUB1z9hFJAsYCS2v5C7vtv9cfM4BdAMrI4d8CJ9v+XWnzKdtnD0T/IyIiIkaztQr6yvTqm6imStdg+wFgY2AHqhM6zpA0Q9K5kvZch/4dBdxQrvcAHrb91Dq0A/Tef0mTJDUkNf44MxwRERExOvQ36NuynHTRoDpC7dK+KtieRXVG7nnAdsBMSfsCPa1PrKefJ+nnwNXAF1sVlvQBSbMkPSJpt/Xtv+2ptjurzQ3H9NFcRERExMjS3y1bVpbv5XolaXeqRRRPANheAXwX+K6kF4A3AxcD23aruh2wuHZ/uu1vSzqZasRwIvBL4KWStinTupcDl0uaRzW6uN79j4iIiBitBmzLFkljqBZRTLFtSQdJ2rbkbQbsBzxUAsFHJb2h5G1HNY17d4tmpwAbSXpjWW17KTBF0hal7sbAZgP1DhERERGj1fpuztycNm1u2fIN4Eslbzzw1bKoYyPgZuA7Je99wIWSmmU/Y3tR98ZL8Hgu8HHgFuAs4F+AeZKeotqK5UrgV+v5HhERERGjmpwjANbQ2dnpRqMx1N2IiIiI6JOkrmpNQu9yIkdEREREG0jQFxEREdEG1vebvlGpqwukoe5FDDf5EiIiIkayjPRFREREtIEBCfok7STpWkmLJHVJmiZpL0kue+01y02RdGK5fqek+ZJekNRZK/MSSXdIWiFpSrfnPChprqQ5kn4o6WW1vLNKe3PKps2vLunTJS2UNFvSjyTtPRDvHBERETGSrHfQV7ZkuR6Ybnu87YnAJ4AdqTZpPqXs09fdPOCvgDu7pf8O+BRwWg+PPMz2AcB04JOlD68FjgZeWfKOAB6p1TnB9oFU27uct9YvGRERETHCDcRI32HAc7YvaibYnk0VdC0DfgC8v3sl2/fZXtgi/Wnbd1MFf72ZAexSrscCy20/W9pYbrvV3n13Up3hGxEREdFWBiLomwB09ZL/ReC0cnrGQDoKuKFc3wrsJunnkr4i6fU91DkGmNsqQ9IkSQ1JjSpWjYiIiBg9Bn0hh+0HgHuA9wxQk3dIWgq8CbimPGMF1fm8k6gitm81vx0srionhxxED9PGtqfa7qw2NxwzQF2NiIiIGB4GIuibTxVw9eZzwBnAQGyEchjwMmAW8Jlmou1Vtqfb/jTwEeAdtTon2O6w/TbbjxARERHRZgYi6Lsd2FzSpGaCpAOA3Zr3tu8HFlBNr643288DHwXeJ2k7SXtL2rNWpAN4aCCeFRERETEarHfQ5+rw3rcDR5QtW+YDnwce61b0s8CuzRtJb5e0BHgtcLOkW2p5DwJfAk6UtETSfi2e+yjV9O4/AFsDV0paIGkOsB9w9vq+W0RERMRoIeeYgTVInYbGUHcjhpn8pxIREcORpK5qTULvcgxbCxMnQiMxX0RERIwiOYYtIiIiog1kpK+Fri7QQKwzjhEnU7gRETFaZaQvIiIiog0k6IuIiIhoA4Ma9EnaSdK1ZSuXLknTJO0lyZJOrpWb0jxBQ9I7Jc2X9IKkzlqZQyX9VtIsSfdLOr+Wt6OkmyTNLtu2TCvp4yStLHUWSLpIUgLdiIiIaDuDFgBJEnA9MN32eNsTgU8AOwJPAKdI2qxF1XnAXwF3tsi7y3YH8ArgaEkHlfRzgNtsH2h7P+DMWp1Fpc4BVPv3vW0AXi8iIiJiRBnMUa/DgOdsX9RMsD0beITqfNwfAO/vXsn2fbYX9taw7ZVUx7DtUpLGAktq+XNa1Hke+DGwx1q/SURERMQIN5hB3wSgq5f8LwKnSdp4bRuWtC2wJ38cDbwQuFTSHZLOkrRzizpbAYcDc3toc5KkhqRGFZNGREREjB5D9n2b7QeAe4D3rEW1gyXNBpYCt9h+rLR1C7A78DVgH+BeSWNKnfGSZgE/Am62/b0e+jPVdme1o/WYVkUiIiIiRqzBDPrmAxP7KPM54Aygv7vi3WX7QODlwEmSOpoZtp+0fbXt9wIzgUNK1iLbHbZfYfvstXqDiIiIiFFiMIO+24HNJU1qJkg6ANiteW/7fmABcMzaNGx7MfAFqoARSW8o07dI2gYYDzy8vi8QERERMVoMWtBn28DbgSPKli3zgc8Dj3Ur+llg1+aNpLdLWgK8FrhZ0i09POIi4BBJ46hGFBuS5gAzgEtszxzI94mIiIgYyeScO7WGzs5ONxqNoe5GRERERJ8kdVVrEnqXjYojIiIi2kCCvoiIiIg2sMlQd2A46uoC9Xc9cYx4+cIhIiLaQUb6IiIiItrAgAd9klZJmiVpnqTraluprGhR9mxJS0v5BZKOr+VdIemvu5UfJ2llrfzXJW1a8raSdJWkueXZd0vaurc+RURERLSLwRjpW1k2Q54A/B74cB/lJ9vuAI4FLm4Gcb1YVMrvT7XVy7tK+inA47b3L88+CXhuHfsUERERMaoM9vTuXcAe/Slo+xfAM8C2/Sy/CvgpsEtJGkt1PFszf6HtZ9enTxERERGjxaAFfZI2Ad4EzO1n+VcCv7D9RD/LbwG8Gvh+SboMOEPSDEnnStpzbfokaZKkhqQGLOtPFyIiIiJGjMEI+raUNAtoUB2Fdmkf5U8tp3XcQ3U6R1/Gl/YfBx61PQfA9ixgd+A8YDtgpqR9+9sn21Ntd1abG47pRzciIiIiRo7B2LJlZfnmrr8m2z5f0luBSyWNt/27Xsovst0haXvgR5LeavtGANsrgO8C35X0AvBm4L516FNERETEqDJstmwpgVsDeH8/yy8HzgQ+ASDpIEnbluvNgP2AhwantxEREREjy4YM+raStKT2+1iLMucAH5PU7NfFtfIzWpS/obR7MDAe+KGkucC9VAHkdwbjRSIiIiJGGjnHEaxB6nQVM0Y7yH8CERExkknqqtYk9C7HsLUwcSI0EvNFRETEKDJsvumLiIiIiMGTkb4WurpAGupexEDLNG5ERLSzjPRFREREtIEEfRERERFtYFCCPkmrJM2SNE/SdZK26pY+X9JsSf/U3J5F0laSrpI0t9S7W9LWksZJmtet/bMlnVaur5C0uLQ7W9LhtXKbSPqcpF+U/FmSzhqMd46IiIgYzgZrpG+l7Q7bE4DfAx/ulv5y4Eiqc3A/XfJOAR63vX+pdxLwXD+fd3o5ceOjwEW19HOBnYH9S/7BwKbr82IRERERI9GGmN69C9ije6LtJ4BJwEckCRgLLK3lL7T97Fo+awawC1Qjh8DfAic3j3Wz/ZTts9flJSIiIiJGskEN+iRtQjWaN7dVvu0HgI2BHYDLgDMkzZB0rqQ91+GRR1Gd0gFVoPmw7af62ddJkhqSGrBsHR4dERERMXwNVtC3paRZVMdaPAxc2lcF27OA3YHzgO2AmZL2BXraaKOefp6knwNXA19sVVjSB8o3fY9I2q3F86fa7qx2tB7TV3cjIiIiRpTB2qdvZfmGrleSdgdWAU8A2F4BfBf4rqQXgDcDFwPbdqu6HbC4dn+67W9LOplqxHAi8EvgpZK2KdO6lwOXl0UhG6/f60VERESMLEO2ZYukMVSLLqbYtqSDJG1b8jYD9gMeKoHgo5LeUPK2o5rGvbtFs1OAjSS90fYzVCOMUyRtUepuDGw22O8WERERMdxs6BM5mtO+mwLPA98AvlTyxgNfLYs6NgJuBr5T8t4HXCipWfYzthd1b7wEj+cCHwduAc4C/gWYJ+kpYCVwJfCrwXi5iIiIiOFKztlUa+js7HSj0RjqbkRERET0SVJXtSahdzmRIyIiIqINJOiLiIiIaAMb+pu+EaGrC6Sh7kUMpHzFEBER7S4jfRERERFtYK2DPklnSZovaU7Z7PjVkqZLWljuZ0n6dil7tqRnJO1Qq7+i1XWL58ySdG23tCskLS55syUdXss7WtK9JX2BpL+r9WFpqTNP0lvX9p0jIiIiRrq1mt6V9FrgaOCVtp+VtD1/3PfuBNutlrwuB/4JOGMtnrMv1QbKB0v6E9tP17KbGzEfBkwF9pS0abn+c9tLJG0OjKvVmWz7/NLuXZJ2sP1Cf/sTERERMdKt7UjfWGC57WcBbC+33deed5cBx5VNlfvreKo9/G4Fju2hzAxgl3K9DVUA++vSr2dtL+xewfZ9VPsDbr8WfYmIiIgY8dY26LsV2E3SzyV9RdLra3lX1aZ3z6ulr6AK/E5Zi+ccB1wLXEMVALZyFHADgO0ngRuBhyRdI+kESWu8m6RXAy8Ay1rkTZLUkNRokR0RERExoq3V9K7tFZImAgcDhwHfknRmye5pehfgAmCWpPP7eoakTqrRxIclLQUuk7RdCewAzpP0OWBX4LW1vn1I0v7AEcBpwJHAiSX7VEl/AzwFHOcWO1Lbnko1RYzUmbWeERERMaqs9ZYttlcB04HpkuYC7+9Hnd9Iuhr4h3484nhgH0kPlvsXAe8Avlbum9/0nUw1gjix9py5wFxJ3wAW88egb7LtPgPOiIiIiNFqraZ3Je0tac9aUgfwUD+rfwn4O3oJNMuU7LuA/W2Psz2O6pu+VlO8U4CNJL1R0taSDl3HfkVERESMems70rc18GVJL6ZaEPFLYBLwbapv+laWcsttH1GvaHu5pOuBU2vJW0laUrv/GrC02+KQO4H9JI3t1p4lnQt8HHgb8HFJFwMrgaf54yhfRERERNtTi8/b2l71TV9PnyfGSJT/NY+IiNFKUpftzr7K5Ri2FiZOhEZivoiIiBhFcgxbRERERBvISF8LXV0gDXUvYn1kOjciImJ1GemLiIiIaAMJ+iIiIiLawKAGfZJ2knStpEWSuiRNk7SXJJfNlZvlpkg6sVyfLWlp7Ui3N5f0QyX9tqTdXz/dQ9KOkm6SNFvSAknTSvo4SStLnQWSLmp1PFtERETEaDdoAZAkAdcD022Ptz0R+ASwI/AEcIqkzXqoPtl2R/lNq6XfZbsDeAVwtKSDSvo5wG22D7S9H3Bmrc6iUucAYD+qPf0iIiIi2spgjnodBjxn+6Jmgu3ZwCPAMuAH9OMIt1ZsrwRmAbuUpLHAklr+nBZ1ngd+DOyxLs+MiIiIGMkGM+ibAHT1kv9F4DRJG7fI+4ikOZIuk7Rt98yStifVaR0AFwKXSrpD0lmSdm5RZyvgcGBuq85ImiSpIalRxaQRERERo8eQfd9m+wHgHuA93bK+CoynOj/3UeDfankHS5oNLAVusf1YaesWYHeqY9z2Ae6VNKbUGS9pFvAj4Gbb3+uhP1Ntd1Y7Wo9pVSQiIiJixBrMoG8+MLGPMp8DzgD+sCue7cdtr7L9AlUQ9+e18nfZPhB4OXCSpI5avSdtX237vcBM4JCStah8G/gK22ev91tFREREjECDGfTdDmwuaVIzQdIBwG7Ne9v3AwuAY2plxtbaeDswr3vDthcDX6AKGJH0hjJ9i6RtqEYKHx7Il4mIiIgYyQYt6LNtqqDtiLJly3zg88Bj3Yp+Fti1dv+vkuZKmkO1GOTUHh5xEXCIpHFUI4qNUmcGcIntmQP2MhEREREjnJzzqtbQ2dnpRqMx1N2IiIiI6JOkrmpNQu+yUXFEREREG0jQFxEREdEGNhnqDgxHXV0g9V0uBl++PoiIiBgYGemLiIiIaAODGvRJ2knStWX1bpekaZL2kmRJJ9fKTZF0Yrk+T9L95USO6yW9uKQfKum3kmaV/PNr9XeUdJOk2ZIWSJpW0sdJWlnqLJB0kaQEuhEREdF2Bi0AkiTgemC67fG2JwKfAHYEngBOkbRZi6q3ARNsHwD8vNRpust2B/AK4GhJB5X0c4DbbB9oez/gzFqdRaXOAcB+wNsG7i0jIiIiRobBHPU6DHjO9kXNBNuzgUeoDrf9AfD+7pVs32r7+XL7E1bfw69ZZiUwC9ilJI0FltTy57So8zzwY2CPdXyfiIiIiBFrMIO+CUBXL/lfBE6TtHEvZT4IrHFWrqRtgT2BO0vShcClku6QdJaknVvU2Qo4HJjb6kGSJklqSGpUMWlERETE6DFk37fZfgC4B3hPq3xJZwHPA1fVkg+WNBtYCtxi+7HS1i3A7lRn9e4D3CtpTKkzXtIs4EfAzbbXCCJLG1Ntd1abG45pVSQiIiJixBrMLVvmA3/dR5nPAd8GflhPLIs6jgYO9+pHhtxl+2hJfwb8RNJ/2p4FYPtJ4Grgakk3AYdQjTQ2v+mLiIiIaFuDOdJ3O7C5pEnNBEkHALs1723fDywAjqmVOQr4OPBW28+0atj2YuALwBmlzhvK9C2StgHGAw8P9AtFREREjFSDFvSVEbq3A0eULVvmA58HHutW9LOsvlhjCrANcFvZauUiWrsIOETSOGAi0JA0B5gBXGJ75oC9TERERMQIJ+fIgzV0dna60WgMdTciIiIi+iSpq1qT0LtsVBwRERHRBhL0RURERLSBwVy9O2J1dYE01L2IfHkQERExcDLSFxEREdEGBjXok7STpGvL6t0uSdMk7SXJkk6ulZtS9uZDUoekn5SVuw1Jf17ST5S0rKTfL+nUWv29JU0vefdJmlrSD5X021r6pwfzfSMiIiKGq0EL+iQJuB6Ybnu87YnAJ4AdgSeAUyRt1qLqvwKfKRsq/99y3/Stkn4QcJak5p5/FwCTbXf4/7N373FWlvX+/19vTySReT4fEAVPiKMzW63UwENZWzNTQ6KUbG/sV5aZkpa2I3ceEgszchvtTOvhgTI1LEvdKkmG6RoZhpOIhAfME/pLJfCEn+8f9zV6u1jDrLVmmGGt9X4+HvNoret0XxdD9Om67/v6ROwB/DjXZ3rq0wJ8VtJ+PbhMMzMzs5qwJnf6RgBvRMTb5+xFxCzgSbLktncBJ5foF8BG6fP7gX+s0iDiBeBRYJtUtA2wJFe/Sn7diPgXWYaOXatYi5mZmVlNW5NB31CyIKsz3wfOkrRuUfnXgAmSngQuJdsdfBdJOwLvAdpT0UTgbkl/lHSGpI1L9NkMOJAsPdwqJI1Nt5MLWUxqZmZmVj/67EWOiPg78DfgM0VV/x9wRkTsAJwB/DxXNzJl3XgUuCIiXk1j/QLYA/gNMJwsL2+/1OdgSTOBO4CLI6Jk0BcRkyOiJTvccIseWaOZmZnZ2mJNBn1zydKjrc6FZPlz8weknAzclD7/Btg/VzclIoYBHwQulrR1R0VE/CMiroqIY4A3yXYaIXumb9+IaM7fajYzMzNrJGsy6Lsb6CdpbEeBpGFAx8sXRMTDwDzg6Fy/fwAfTp8PBRYWDxwRBeBXwOlp3CMlrZ8+bw1sBjzVk4sxMzMzq2VrLOiLLKnvscDh6ciWucBFwDNFTS8Ats99/0/gB5Jmke0EjqW07wOfl/Q+4CPAnNTndmBcRBRfx8zMzKxhKZz2YBVSS0Chr6fR8PxX08zMrGuSWrN3ElbPadhKaG6GgmM+MzMzqyNOw2ZmZmbWALzTV0JrK0hdt7Oe51u6ZmZma4Z3+szMzMwagIM+MzMzswZQdtAnaWtJN6TjV1ol3SZpiKS9JN0taYGkhZK+LWU3RyWNkTSpaJxpklrS51MkzZbULmmOpGNS+dWSji/qN1DSCkltkuZJ+mXubL7+kq5NY82R9BdJA1LdytRnjqTfSOrfvT8yMzMzs9pTVtCXgribgWkRsUtENJPlxN0KmEqW3mw3YB+ybBlfKmPM7YFzgYNSlo0DeSeXbmcWRUQTsDfZ2X6fTuWnA89GxN4RMRT4AvBGqlsREU2p/HXgi+Ws2czMzKyelLvTNwJ4I5/GLCJmAUOA+yLijlS2HDgNOKeMMbcEXgGWpb7LImJxOZOJiJXAA8B2qWgbchk4ImJBRLxWout0YNdyrmFmZmZWT8oN+oYCrSXK9youj4hFwABJG6Wiken2apukNqDj8MBZwLPAYkm/kJRPxbZakt4DHAD8KRVdBZwtaYak70kaXKLPesDHgNmdjDlWUkFSAZ4vdypmZmZmNaE3XuSYkm6vNqVbswV4e7fuSOB44BFgoqTxXYy1SwocnwWejoj2NFYbMAiYAGwKPChpj9Rnw9SnADwB/LzUwBExOSJashOtt+jGcs3MzMzWPuWe0zeXLDgrNg84JF8gaRCwLCJeVheH3aX8vA8AD0i6E/gFMH41XRZFRJOkzYH7JH0iIqamsZYBNwE3SXoL+Dgwn/RMXxlrNDMzM6tb5e703Q30kzS2o0DSMGABcJCkw1PZhsDlwCVdDShpW0n75YqagMfLmUxELCV7bvCbaawPSdokfd4A2LPcsczMzMwaQVlBX9qROxY4PB3ZMhe4CHgGOAY4T9ICsuflHgQmdTrYO9YHLpX0cLr9OpLsLdwOP5W0JP3MKNH/FqC/pIOBXYA/S5oNzCS7lfvbctZmZmZm1ggUznu1ipaWligUCn09DTMzM7MuSWrN3klYPWfkMDMzM2sADvrMzMzMGkC5b+82lNZW6OLFY+sBfrLAzMys93inz8zMzKwBVBX0Sdpe0u8kLUxv8/5I0gaShkuKfHYNSb+XNDx93kDSZZIeTX1/l8baLJe14xlJT+W+byBpWdH1x0ialD6PL2rfJmnjNJeX0veHJV3ajT8nMzMzs5pWcdCn7MTlm4BbImIwWf7dAcAFqckS4NxOul8IvA/YLfW9JY31Yi5jx5XAxFwWj9fLmFa+fVNE/DOVT09j7gscJelDla7XzMzMrB5Us9N3KPBqRPwC3k6ndgZwCtCfLKfuS5KOyHeS1B/4PHBG6kMa47U05hoTESuANmC7NXkdMzMzs7VVNUHfXkBrviAiXibLa7trKroAOK+o367AE6ltXiGNuTob5m/fAucX1Z+Rq7+nuHPK1jEYuLezC0gaK6kgqQDPdzEdMzMzs9qyRt7ejYh7JSHpoB4a8l35cyWNAfKHEE6MiFLP7B0saRZZwHdZRDyzmjlPBiZn47f4vVIzMzOrK9Xs9M0DmvMFkjYCdgQezRUX7/YtAnaU9L6i8ZqBuVXMoxzTI2Ifsp3EL0hq6qqDmZmZWT2qJui7iyzn7UkAktYFfgBcDSzvaBQRdwCbAMPS938B1wA/TH1IY/QH7q5+CV2LiMXAxcDZa/I6ZmZmZmurioO+yJL1HgucIGkh8AjwKvCtEs0vAHbIff9mavtI6nsCcGx0PwFw/pm+NkkDS7S5EjikkzozMzOzuqbux1v1J3umr9DX06h7/qtnZmbWfZJaI6Klq3ZOw1ZCczMUHPOZmZlZHXEaNjMzM7MG4J2+ElpbQerrWdQn39I1MzPrG97pMzMzM2sADvrMzMzMGkBVQZ+kcyXNldSejkg5QNI0SQtyx6bcmNqOl7Rc0pa5/stKfc6VjZd0VonylWnsOZJulbRxKl9H0uWpfLakByXtnOoeS2Xtku6QtHU1azYzMzOrZRUHfZI+ABwF7BcRw4DDgSdT9eiIaEo/x+e6LQXO7PZsUzq2iBgKvAh8OZWPBLYFhkXE3mTnCP4z129EmmuB0ucJmpmZmdW1anb6tgGWRsRrABGxNCL+0UWfq4CRkjat4nqdmQFsl5vT0xHxVprTkoj4/0v0uRfYtQfnYGZmZlYTqgn67gB2kPSIpCskfThXd23u9u6EXPkyssDv9O5MtkNK43YYMDUV/Ro4Ol33B5L27aTrUcDsTsYcK6kgqQDP98Q0zczMzNYa1aRhWwY0A2PJoqMpksak6vzt3XFFXS8HTpb0vm7Md0NJbcAzwFbAnWlOS4DdyNK8vQXcJemwXL97Ur+NgIs6WdfkiGjJTrTeohtTNDMzM1v7VHVOX0SsBKYB0yTNBk4uo88/JV3HO8/hVWNFRDRJ6g/cnsa6PI3/GvBH4I+SngU+CdyV+o2IiKXduK6ZmZlZTavmRY7dJA3OFTUBj5fZ/YfAqXTzUOiIWA58FThT0nqS9pO0bZrfOsCwCuZkZmZmVveqeaZvAHCNpHmS2oE9gfGpLv9M3/8Vd0y7bTcD/XLF/SUtyf18PZWfly8vMdZMoB0YBWwJ3CppTip7E5hUxdrMzMzM6pLCebFW0dLSEoVCoa+nYWZmZtYlSa3ZOwmr54wcZmZmZg3AQZ+ZmZlZA+jWCxX1qrUVpL6eRf3wEwRmZmZ9zzt9ZmZmZg2gR4I+SVtLukHSIkmtkm6TNERSSPpKrt2kjoOcJZ0gaa6ktyS15NockcaYnf7z0FzdY6m8XdKfJe2Uqzs3jRMewUMAACAASURBVNee3h4+IJVPk7RA0ixJ90narSfWbGZmZlZLuh30SRLZMSzTImKXiGgmy4yxFfAccLqkDUp0nQN8iiwfbt5S4OiI2Jvs0OdfFdWPiIhhZIdDn5fm8AGyFGv7pbrDgSdzfUZHxD7ANcAEzMzMzBpMT+z0jQDeiIgrOwoiYhZZ0PU8WVaMVTJ2RMT8iFhQonxmRPwjfZ1LlnqtX3E7YAawXfq8DbA0ZeUgIpbmxsi7F9i17JWZmZmZ1YmeCPqGAq2rqf8+cJakdasY+zjgoY5grsiRwC3p8x3ADpIekXSFpA93Mt7RwOxSFZLGSipIKmSxqpmZmVn9WOMvckTE34G/AZ+ppJ+kvcgCxlOLqu6R9BTwMeD6dI1lQDMwlixim9Lx7GByraQ24EPAWZ3Mc3JEtGSHG25RyVTNzMzM1no9EfTNJQu4VudC4GygrINQJG1P9pzgSRGxqKh6BLAT0AZ8t6MwIlZGxLSI+A5wGtkuYYfREdEUEZ+MiCcxMzMzazA9EfTdDfSTNLajQNIwYIeO7xHxMDCP7PbqaknaGPgDcE5E3FeqTUS8CXwNOEnSppJ2kzQ416QJeLyaxZiZmZnVo24HfZEl7z0WODwd2TIXuAh4pqjpBcD2HV8kHStpCfAB4A+Sbk9Vp5G9bPFf6eiVNklblrju02S3d78MDACukTRPUjuwJzC+u2szMzMzqxcKp0tYhdQSUOjradQN/xUzMzNbcyS1Zu8krJ7TsJXQ3AwFx3xmZmZWR5yGzczMzKwBeKevhNZWUFnvGVs5fHvXzMys73mnz8zMzKwBOOgzMzMzawAVBX2StpZ0QzqapVXSbZKGSApJX8m1m9SREUPSf0tqT0ev3CFp26Ix/03Sm5KOz5XtmNrOT8ewDEzl0yQtkDRL0oOSmnJ9TpE0O11rjqRjUvnVkhan6z8k6QNV/DmZmZmZ1bSygz5JIsuSMS0idomIZuCbwFbAc8DpkjYo0XVCRAyLiCbg98B/5cZclyzV2h1FfX6Z+u0B7J/G7zA6IvYBrgAmpHG2B84FDoqIYcCBQHuuz7h0/XOAn5a7ZjMzM7N6UclO3wjgjYi4sqMgImYBT5Llu70LOLm4U0S8nPv6XiD/WP9XgN+SC+ok7QmsFxF3pv7LImJ5ifnMALZLn7cEXgGW5fosLtHnXrKDn83MzMwaSiVB31CgdTX13wfOSrt37yLpAklPAqNJO32StiPL5PE/Rc2HAP+UdJOkmZImlBoTOBK4JX2eBTwLLJb0C0mdpXs7GphdqkLSWEkFSYUshjUzMzOrHz32IkdE/B34G/CZEnXnRsQOwLVkadYALgPOjoi3ipqvBxwMnAX8GzAIGJOrv1bSYrLbuT9J468kCwKPBx4BJkoan+szQVIbMBb4QifznxwRLdmJ1luUu2wzMzOzmlBJ0DcXaO6izYXA2UBnp9xdCxyXPrcAN0h6jCxYu0LSJ4ElQFtE/D0i3iTbzdsvN8ZoskDwGuDHHYWReSAiLgJOzF0H0jN9EXFERMzpeqlmZmZm9aWSoO9uoJ+ksR0FkoYBO3R8j4iHgXlkt1E72gzOjXEM8HBqu3NEDIyIgcCNwJci4hbgQWBjSR3bbYemMd8WWcLgbwMHStpd0raS8oFhE/B4BWszMzMzq2tlB30p0DoWODwd2TIXuAh4pqjpBcD2ue8XpyNU2oGPAKd3cZ2VZLd275I0m2zX8Gcl2q0AfgCMA9YHLpX0cLqNO7Kr65iZmZk1EoVzZK2ipaUlCoVCX0/DzMzMrEuSWrN3ElbPGTnMzMzMGoCDPjMzM7MGsF5fT2Bt1NoK6uz9Y3sXPx1gZmZWG7zTZ2ZmZtYAugz6JK2U1Jb7GShpjKRJRe2mSWpJnx+TtHlR/RhJb6VjXjrK5kgamD4vK9F+Uvo8XtJT6fpzJH2iRPnClMVjz6I5LZA0S9KDkpoq/QMyMzMzqwfl7PStSAcbd/w81o3rLSHLpFGNiRHRBJwAXCVpnXx5RAwGpgB35874AxgdEfsAVwATqp24mZmZWS3r7du7vwf2krRbtQNExHzgTWDzEnVTgDsokQoOmAFsV+11zczMzGpZOUHfhrlbuzd383pvAZcA36p2AEkHpHGe76TJQ8DuJcqPJEvp1tm4YyUVJBU6H9rMzMysNpXz9u6KdFs1r7N3Nst5l/M64FxJO5fRNj/eGZI+C7wCjIyIUOlXbIsLr5W0ATCALD1b6QtFTAYmA0gtfifVzMzM6kq1t3dfADYpKtsUWNpVx4h4kyx92tlFVStScNbZeB3P7h0cEdNXc4l9gfm576OBQcA1wI+7mp+ZmZlZPao26HsQ+JCkrQHSW7v9gCfL7H81cDiQf+Hiz8Bn03gbAp8G7qlkUpKOI8vve32+POUN/jZwoKRSt37NzMzM6lpVQV9EPAucDtwmqQ24DBgVEW/lmrVLWpJ+fljU/3XgcmDLXPHpwKfSePcDv4mIe8uYzhkdR7aQBY2HRsQqD+VFxAqyHcZx5a/UzMzMrD4onFJhFS0tLVEoFPp6GmZmZmZdktQaES1dtXNGDjMzM7MG4KDPzMzMrAGUc2RLw2lthdKnwZifBjAzM6tN3ukzMzMzawBVBX2SVqY3ZudI+o2k/kXlcyXNknRmR45cScMlhaT/yI3TlMrOSt+vlrQ4lwHkr6l8jKTnJc2UtFDS7ZI+mOr+U9KU3JgbSVokaVAa7ylJ/VLd5pIeq/LPyszMzKxmVbvTtyIdlDwUeB34YlH5XsARwMeA7+T6zSE7f6/DKGBW0djj0hhNEfHBXPmUiNg3IgYDFwM3SdoD+F9gB0mHp3bnA1dFxN/T95XAKVWu08zMzKwu9MTt3enArsWFEfEcMBY4Te/kS3sceI+krVLZkcAfK71gRNxDljJtbDp4+YvAZemQ6MOACbnml5Gd5efnF83MzKxhdSvoS4HUx4DZperTbtu6vPsQ5huBE4APAg8BrxV1m5C7vXvtai7/ELB7uk47cDtwF/CVdPhzhyeAvwCf62ItYyUVJBVglbOdzczMzGpatbtfG6bMGZDt9P28gr6/BqaQBWzXkwV/eeMi4sYyxil+v/YnwMciYlqJthcBvwP+0NlgETGZbPcQqcXvqJqZmVldqTboWxERTV01kjSI7Jm654A9ACLiGUlvkD3zdzqrBn3l2heYn/v+VvpZRUQsTEHqp0vVm5mZmdW7Nfacm6QtgCuBSRERevfBd/8FbBkRK1XFgXiSPkz2vOCICrpdwGp2+szMzMzqWU8HfR23fdcH3gR+BfywuFFE/HU1Y0yQdF7u+/7pP0dKOgjoDywGjouI+av07kREzJX0ELBfuX3MzMzM6oXCKRZWkT3TV+jraayV/NfFzMxs7SKpNSJaumrnY0xKaG6GgmM+MzMzqyNOw2ZmZmbWALzTV0JrK1TxfklD8O1dMzOz2uSdPjMzM7MG4KDPzMzMrAFUHPRJ2l7S7yQtlLRI0o8kbSBpuKSQdHSu7e8lDU+fp0laIKld0sOSJknauKtxU91wSS+l1GzzJX2naE6XSXpK0jpF5UdKeiBdr03SFEk7VrpmMzMzs1pXUdCn7CTlm4BbImIwMAQYQHbwMcAS4NzVDDE6IoYBw8hy7v6uzHEBpqcsIC3AZyXtl/quAxwLPAl8ODfXocCPgZMjYvfU91pgYCVrNjMzM6sHle70HQq8GhG/AIiIlcAZwClkhybPAl6SdMTqBomI14FvADtK2md140rqX9T3X0ArsGsqGg7MBf4HGJVrejZwYf4A54iYGhH3VrhmMzMzs5pXadC3F1nA9baIeBl4gneCsAuA8+hCCuxmAbuXOS4AkjYDDiQL9CAL9K4Hbgb+XdL6ubk+VOa6kDRWUkFSAZ4vt5uZmZlZTejxFzk6dtJSyrSuVHIwysGSZgJ3ABentGobAB8nuy38MvA34KOrXETaLD3T94ikszqZ9+SIaMlOtN6igmmZmZmZrf0qDfrmAc35AkkbATsCj+aKu9ztk7QusDcwv8xxp0fEvhHRHBFXprKPAhsDsyU9BhzEO7d455Ly7EbEC+mZvslkzwqamZmZNZRKg767gP6SToK3A7cfAFcDyzsaRcQdwCZkL2ysIt2CvQh4MiLaVzduRCwvNUYyCviPiBgYEQOBnYEj0nOAlwDnStoj175/iTHMzMzM6l5FQV9EBNmbsidIWgg8ArwKfKtE8wuAHYrKrpXUDswB3gscU8W4AKTA7kjgD7n5/Qv4C3B0RMwGTgd+mY6KuQ/YA7iukjWbmZmZ1QOF82qtoqWlJQqFQl9Pw8zMzKxLklqzdxJWzxk5zMzMzBqAgz4zMzOzBrBeX09gbdTaCqrkMJkG4ScBzMzMapd3+szMzMwawBoN+iRtLekGSYsktUq6TdIQSSHpK7l2kySNSZ+npIOU2yQ9JqktlQ+X9FIqf1jSpbn+W0n6vaRZkuZJui2VD5S0IvWZJ+nKlKvXzMzMrKGssdu7kkSWGu2aiDgxle0DbAU8B5wu6acpD+/bImJkbowfAC/lqqdHxFGSNgRmSro5Iu4DzgfujIgfpX758wEXRUSTpPWAu4FPAjf19HrNzMzM1mZrctdrBPBGLnsGETELeJIsue1dwMmddU5B46fJ8uq+S0SsANqA7VLRNsCSXH17iT5vAn+lKJevmZmZWSNYk0HfUKB1NfXfB85K2TdKORh4NiIWFldI2gQYDNybin4C/FzSPZLOlbRtiT79gcOA2aUuJmmspIKkQhaTmpmZmdWPPnu+LSL+DvwN+EwnTUax6i7fwZJmAU8Bt0fEM2ms24FBwM+A3clu/W6R+uySngu8D/hDRPyxk/lMjoiW7HDDLUo1MTMzM6tZa/LIlrnA8V20uRC4EfhzvjA9f/cpoLmofcczfTsD90v6dUS0AUTEi2Qp1q6T9HvgELKdxkUR0dTt1ZiZmZnVsDW503c30E/S2I6C9ILF2/l4I+JhYB5wdFHfw4GHI2IJJUTEYuBi4Ow07qHp9i2S3gfsAjzRc0sxMzMzq21rLOiLLKnvscDh6ciWucBFwDNFTS8Ati8qO5ESL3AUuRI4RNJAsh3BgqR2YAbwvxHxYPdWYGZmZlY/FE6zsAqpJaDQ19NY6/ivipmZ2dpHUmv2TsLqOQ1bCc3NUHDMZ2ZmZnXE2SnMzMzMGoB3+kpobQWpr2ex9vBtXTMzs9rnnT4zMzOzBuCgz8zMzKwBlBX0Sdpa0g3p6JVWSbdJGiJpL0l3S1ogaaGkb6ecuUgaI2lS0TjTJLWkz6dImi2pXdIcScek8qslLZbUJmmWpMOK+i9I5Q9KasrVlTPeQ5I+0P0/NjMzM7Pa0mXQl4K4m4FpEbFLRDQD3wS2AqYCF0fEbsA+wAeBL5Ux5vbAucBBETEMOBBozzUZl7JofI3sPL680RGxD3AFMKHC8c4BftrV/MzMzMzqTTk7fSOANyLi7eArImYBQ4D7IuKOVLYcOI0ssOrKlsArwLLUd1nKslFsBrBdJ2Pk68od715g1zLmZ2ZmZlZXygn6hpLlsC22V3F5RCwCBkjaKBWNTLdV2yS1AR0HB84CngUWS/qFpOI0bB2OBG4po67c8Y4GZpeqkDRWUkFSAZ7vpLuZmZlZbVrTR7ZMiYjTOr5ImgYQESslHQn8G3AYMFFSc0SMT00nSLqQLD1b8TN410raABgANFUw3nlk0dwXSk00IiYDk7N5tviQEjMzM6sr5ez0zSXLbVtsXnG5pEHAsoh4uatBI/NARFxElmv3uFz1uIgYApwNXFXUdTQwCLgG+HEF4zVFxBERMaeruZmZmZnVm3KCvruBfpLGdhRIGgYsAA6SdHgq2xC4HLikqwElbStpv1xRE/B4iaaTgHUkfTRfGFnC4G8DB0ravYLxzMzMzBpSl0FfCrCOBQ5PR7bMBS4CngGOAc6TtIDsWbkHyQK1rqwPXCrp4fSs30jg9E6u/T3gGyXqVgA/AMaVO56ZmZlZo1I4x9YqWlpaolAo9PU0zMzMzLokqTUiWrpq54wcZmZmZg3AQZ+ZmZlZA1jTR7bUpNZWyJLJGYCfADAzM6t93ukzMzMzawAVBX2StpZ0Q3qLt1XSbZKGSNpL0t2SFkhaKOnbKWcvksZIej6XmeOXqfxqSU9J6pe+by7psfR5oKRVztNLfRancWZJOixXd5Skmal8nqRTU/n4dJ02SXMkfaLqPy0zMzOzGlV20JeCuJuBaRGxS0Q0A98EtgKmAhdHxG7APsAHgS/luk9JhyM3RcRJufKVwCkVznlcRDQBXwOuTHNbnyybxtERsQ+wLzAt12di6nMCcJUk73CamZlZQ6kk+BkBvBERV3YURMQsYAhwX0TckcqWA6cB55Qx5mXAGZKqebZwBrBd+vw+sucTX0hzeC0iFhR3iIj5wJvA5lVcz8zMzKxmVRL0DQVaS5TvVVweEYuAAZI2SkUjc7d3P59r+gTwF+BzFcyjw5HALel6L5LtNj4u6XpJo0vt5kk6AHiLLAdvcd1YSQVJhRLVZmZmZjWtt97enRIRp3VSdxHwO+APZY41QdKFwPbABzoKI+I/JO0NHA6cBRwBjEnVZ0j6LPAKMDJKnEgdEZPJbhEjtfh9VTMzM6srlez0zQWaS5TPKy6XNAhYFhEvdzVoRCwE2oBPlzmPcRExBDgbuKporNkRMZEs4DsuVzUxPU94cERML/M6ZmZmZnWjkqDvbqCfpLEdBZKGAQuAgyQdnso2BC4HLqlg7AvIducqMQlYR9JHJQ2QNDxX1wQ8XuF4ZmZmZnWr7KAv3RI9Fjg8Hdkyl+zW7DPAMcB5khYAs4EHyYKycseeCzxUVLybpCW5nxNKzOd7wDcAAd9IR8a0Ad/lnVu7ZmZmZg1PJR5va3jZM32Fvp7GWsN/RczMzNZeklojoqWrdk7DVkJzMxQc85mZmVkd8SHFZmZmZg3AO30ltLZClkTOfGvXzMysPninz8zMzKwBOOgzMzMzawBlB32SzpU0V1J7Sqd2gKRpHcekpJ8bU9vxkpZL2jLXf1nu88rUfo6kWyVtXHStr0l6VdL7c2XDJb2U+j0s6dJc3VaSfi9plqR5km5L5QMlrUh95km6slR6NjMzM7N6V1YAJOkDwFHAfhExjCzV2ZOpenTKdtEUEcfnui0FzuxkyBWp/VDgReDLRfWjyM76+1RR+fSIaAL2BY6S9KFUfj5wZ0TsExF7Aufk+ixKfYYBewKfLGfNZmZmZvWk3F2vbYClEfEaQEQsjYh/dNHnKmCkpE27aDcD2K7ji6RdgAHAeWTB3yoiYgVZ6raOftsAS3L17SX6vAn8Fdi1i/mYmZmZ1Z1yg747gB0kPSLpCkkfztVdm7u9OyFXvows8Du9s0ElrQscBkzNFZ8I3ABMJ8vKsVWJfpsAg4F7U9FPgJ9Luifdht62RJ/+6VqzO5nLWEkFSQV4vrMpm5mZmdWksoK+iFgGNANjySKiKZLGpOr87d1xRV0vB06W9L6i8g1TurRngK2AO3N1o4AbIuIt4LdAPv3awZJmAU8Bt0fEM2l+twODgJ8BuwMzJW2R+uySrnUf8IeI+GMna5wcES3ZidZblGpiZmZmVrPKPqcvIlYC04BpkmYDJ5fR55+SrmPVZ/ZWRERT2n27PdVfLmlvsh28O5UdlLcBsJh38vhOj4ijJO0M3C/p1xHRlq71InAdcJ2k3wOHAK2880yfmZmZWcMq90WO3SQNzhU1AY+XeY0fAqdSIsCMiOXAV4EzJa1Htss3PiIGpp9tgW0l7VTUbzFwMXB2mt+hKYAk7SruAjxR5vzMzMzM6l65z/QNAK5Jx560k70FOz7V5Z/p+7/ijhGxFLgZ6Fdq4IiYCbSTBXwnprZ5N6fyYlcCh0gaSHbruZDmNgP434h4sMy1mZmZmdU9hfNsraKlpSUKhUJfT8PMzMysS5Jas3cSVs8HFZuZmZk1AAd9ZmZmZg2g7Ld3G0lrK2QvD5vv/puZmdUH7/SZmZmZNYCKg76U8WKupPb0xu4BkqZJWpB7i/fG1Ha8pOWStsz1X5b7vDK1nyPpVkkbp/KBkuaUuPbVkhanPrMkHZarO0rSzFQ+T9KpuTk8lbvOJypds5mZmVmtq+j2rqQPAEcB+0XEa5I2JztAGbLMHKVeeV0KnEk6U6/Iio6DkyVdQ3ZI8wVdTGNcRNwoaQQwGRgsaf30ef+IWCKpHzAw12diRFwqaQ9guqQtU8YPMzMzs4ZQ6U7fNsDSiHgNsjP4IuIfXfS5ChgpadMu2s0AtqtgLvn27yMLYF9I83otIhYUd4iI+cCbwOYVXMfMzMys5lUa9N0B7CDpEUlXSPpwri5/SPOEXPkyssDv9M4GlbQucBgwtYK5HAncAm+nYJsKPC7pekmjJa2yNkkHAG+R5Q8urhsrqSCpUKLazMzMrKZVdHs3IpZJagYOBkYAUySdk6o7u70LcDnQJunSovINJbWR7djNB+4sYxoTJF0IbA98IDe3/0i5ew8HzgKOAMak6jMkfRZ4BRgZJU6kjojJZLeIkVr8zqqZmZnVlYpf5IiIlRExLSK+A5wGHFdGn38C15E9s5fX8UzfToBK1JcyLiKGkD0jeFXRdWZHxESygC8/r4kR0RQRB0fE9DKuYWZmZlZXKgr6JO0maXCuqAl4vMzuPwROpcTuYkQsB74KnCmp3N3HScA6kj4qaYCk4VXOy8zMzKzuVbrTNwC4Jh2J0g7sCYxPdfln+v6vuGNELAVuBvqVGjgiZgLtwKhUtJukJbmfE4raB/A94Btku4Tf6Dg2Bvgu79zaNTMzM2t4KvF4W8NraWmJQqGzxxPNzMzM1h6SWiOipat2zshhZmZm1gAc9JmZmZk1gIqObGkUra0g9fUs1g6++29mZlYfvNNnZmZm1gAqDvokrUxv6M6RdKukjVP5QEkrcm/wtknaQNIYSZNKjPOYpNmS2iX9WdJORfWflBSSds+V5a8xT9IvU95dJPWXdG0ac46kv0gaUGLOv5HUv9J1m5mZmdWyanb6VqSDjocCL/LuA5UXpbqOn9e7GGtERAwDpgHnFdWNAv7CO0e4vOsawN5kWTk+ncpPB56NiL3T3L4AvFFizq8DXyx7tWZmZmZ1oLu3d2eQpVDrrneNk3boDiIL3E4s1SEiVgIP5PptAzyVq18QEa+V6Dod2LUH5mxmZmZWM6oO+iStCxwGTM0V75K7tfuTCoY7Ergl9/0Y4E8R8QjwQsr3W3z99wAHAH9KRVcBZ0uaIel7RZlDOvqsB3wMmF2ibqykgqQCPF/B1M3MzMzWftUEfRumrBfPAFsBd+bq8rd3y8mje4+kp8gCsetz5aOAG9LnG3j3Ld5d0vWfBZ6OiHaAiGgDBgETgE2BByXtUTTnAvAE8PPiiUTE5IhoyQ433KKMqZuZmZnVjmqObFkREU3pZYjbyZ7pu7zK648A/glcS5Y67euSNgUOBfaWFMC6QEgal/osStffHLhP0iciYipARCwDbgJukvQW8HFgfsecq5yjmZmZWc2r+vZuRCwHvgqcmW6bVjvOm8DXgJNSwHc88KuI2CkiBkbEDsBi4OCifkuBc4BvAkj6kKRN0ucNyPICP17tvMzMzMzqSbde5IiImUA7q75hW2yMpCW5n+2Lxnma7Pbul9NYNxf1/20n17gF6C/pYGAX4M+SZgMzyW7l/rbSNZmZmZnVI4VTLqxCaoksZjT/9TAzM1u7SWrN3klYPadhK6G5GQqO+czMzKyOOA2bmZmZWQPwTl8Jra0g9fUs+p5v7ZqZmdUP7/SZmZmZNQAHfWZmZmYNoDtp2LaX9DtJCyUtkvQjSRtIGi4pJB2da/t7ScPT52mSWorGGi7pJUkzJS2QdK+ko4rajJX0cPp5QNJBubppqd8sSfdJ2i1Xt7mkNyR9sdq1mpmZmdW6qoI+SSLLfHFLRAwGhgADgAtSkyXAuRUOOz0i9o2I3cgOfZ4k6bB0vaOAU4GDImJ34IvAdZK2zvUfHRH7ANeQpWLrcAJwP12fJWhmZmZWt6rd6TsUeDUifgEQESuBM4BTgP7ALOAlSUdUM3jKo3s+cFoqOhsYl7JwEBEPkQV3pfL73gvsmvs+CjgT2K74UGgzMzOzRlFt0LcX0JoviIiXgSd4J+C6ADiv+qnxELB7Z9cjOz15rxL9jgZmA0jaAdgmIh4Afg2M7Oxi6fZxQVIBnu/GtM3MzMzWPmvsRY6IuBcg/+xdhSo9NOVaSW3Ah4CzUtlIsmAP4AZWc4s3IiZHREt2ovUWFU/WzMzMbG1W7Tl984Dj8wWSNgJ2BB4FPpKKO3b73qziGvsC83PXawbuztU3A3Nz30dHRHEejVHA1pJGp+/bShocEQurmI+ZmZlZzap2p+8uoL+kkwAkrQv8ALgaWN7RKCLuADYBhlUyuKRhwLeBn6SiS4DvS9os1TcBY4ArVjPGEGBARGwXEQMjYiBwEX6hw8zMzBpQVUFfRARwLHCCpIXAI8CrwLdKNL8A2KGo7A+SlqSf36SygzuObCEL9r4aEXel600FrgL+Kulh4GfAZyPi6dVMcxRwc1HZb3HQZ2ZmZg1I4Vxbq2hpaYlCofhOsZmZmdnaR1Jr9k7C6jkjh5mZmVkDcNBnZmZm1gCqfXu3rrW2gio9MKbO+K6/mZlZffFOn5mZmVkDqDb37kpJbZLmSLpV0sapfKCkFamu42cDSWMkTSoxzmOSZktql/RnSTvl6paVaD9e0lNp3HmSRuXqDpT0t1Q3X9L4VD5G0vO5Pv9ZzZrNzMzMalm1O30rIqIpIoYCL/LuHLiLUl3Hz+tdjDUiIoYB0ygvbdvEiGgCjgF+Kmn9VH4NMDbVDeWdTBwAU1L5cOBCSVuVcR0zMzOzutETt3dnANv19jgpq8ZyssOfAbYEnk51KyNiXok+zwGLgJ2K68zMzMzqWbeCvpSJ4zBgaq54l9yt3Z900rWUI4FbKrj2fsDC9KyPVQAADdBJREFUFMgBTAQWSLpZ0qmS3lOizyBgEFmquOK6sZIKkgrwfAXTNjMzM1v7Vfv27oaS2sh25uYDd+bqFqVbqeW6R9KmwDKy1GtdOUPS54EhwNEdhRFxvqRryfL+foYs88bwVD1S0kHAa8CpEfFi8aARMRmYDCC1+N1VMzMzqyvdeqaP7DapePczfZUakcZpA75bRvuJEbEXcBzw8/yOXkQsioj/Idt93KcjVy/pmb6IOCAiilOzmZmZmdW9bt3ejYjlwFeBMyVVfeZfRLwJfA04Ke36ldNnKlAATgaQ9O/S26frDQZWAv+sdk5mZmZm9aTbL3JExEygnex26uqMkbQk97N90ThPA9fzzq5h/6L2Xy8x5vnA1yWtA3yO7Jm+NuBXwOiIWNmdtZmZmZnVC4VTL6wie6av0NfT6FP+a2FmZlYbJLVGREtX7ZyGrYTmZig0dsxnZmZmdcZp2MzMzMwagHf6SmhthbdfCWlAvrVrZmZWf7zTZ2ZmZtYAHPSZmZmZNYCqgj5JK1OatTmSbpW0cSofKGlFLg1bm6QNJI2RNKnEOI9J2ryTa9wi6f6isvGSnkrjzpM0Kld3oKS/pbr5ksan8jGSns/1+c9q1mxmZmZWy7qVkSMihgIv8u6MHItSXcfP65UOnoLIZuD9KV9u3sSUDeQY4KeS1k/l1wBjU91Q4Ne5PlNS+XDgQklbVTonMzMzs1rWE7d3Z5Dl4O1JnwJuBW4ATizVICIWAsuBTVLRlsDTqW5lRMwr0ec5YBFZ2jczMzOzhtGtoE/SumR5bqfminfJ3dr9SZVDjyLLznE9nWT6kLQfsDAFcgATyTJy3Czp1HxO3lyfQcAg4NESdWMlFSQV4Pkqp21mZma2dqr2yJYNU7qz7YD5wJ25ukXpVmpV0q3XwcBfIiIkvSFpaETMSU3OkPR5YAhwdEe/iDhf0rXAR4DPkAWLw1P1SEkHAa8Bp0bEi8XXjYjJwORsDi0+tMTMzMzqSree6SO7TSre/Uxfd32a7JbtYkmPAQN5927fxIjYCzgO+Hl+Ry8iFkXE/5DtPu4jabNUNSU9X3hARNzcg3M1MzMzqwndur0bEcuBrwJnSuqpg55HAUdGxMCIGEj2Qscqz/VFxFSyBLknA0j6d+ntI5UHAyuBf/bQnMzMzMxqWrdf5IiImUA7nTx7lzNG0pLcz/apvD1XdhPZ7uHbR7VExGLgJUkHlBjzfODrktYBPkf2TF8b8CtgdESs7ObyzMzMzOqCwjm3VtHS0hKFQqGvp2FmZmbWJUmtEdHSVTtn5DAzMzNrAA76zMzMzBqAgz4zMzOzBuCgz8zMzKwBOOgzMzMzawAO+szMzMwagIM+MzMzswbgoM/MzMysATjoMzMzM2sADvrMzMzMGoCDPjMzM7MG4KDPzMzMrAE46DMzMzNrAA76zMzMzBqAgz4zMzOzBuCgz8zMzKwBOOgzMzMzawAO+szMzMwagIM+MzMzswbgoM/MzMysATjoMzMzM2sADvrMzMzMGoCDPjMzM7MG4KDPzMzMrAEoIvp6DmsdSa8AC/p6Hn1kc2BpX0+ijzTy2qGx1++1N65GXr/XXj92iogtumq0Xm/MpAYtiIiWvp5EX5BU8NobUyOv32tvzLVDY6/fa2+8tfv2rpmZmVkDcNBnZmZm1gAc9JU2ua8n0Ie89sbVyOv32htXI6/fa28wfpHDzMzMrAF4p8/MzMysATjoMzMzM2sADRX0STpS0gJJj0o6p0R9P0lTUv3fJA3M1X0zlS+Q9NHenHdPqHbtkjaTdI+kZZIm9fa8e0o31n+EpFZJs9N/Htrbc++ubqx9f0lt6WeWpGN7e+49oTv/vU/1O6a//2f11px7Sjd+9wMlrcj9/q/s7bl3Vzf/vR8maYakuem/++/pzbn3hG787kfnfu9tkt6S1NTb8++Obqx9fUnXpN/5fEnf7O25r3ER0RA/wLrAImAQsAEwC9izqM2XgCvT5xOBKenznql9P2DnNM66fb2mXlr7e4GDgC8Ck/p6LX2w/n2BbdPnocBTfb2eXlx7f2C99Hkb4LmO77Xy05315+pvBH4DnNXX6+nF3/1AYE5fr6GP1r4e0A7sk75vVkv/3nd3/UVt9gYW9fV6evF3/xnghvS5P/AYMLCv19STP42007c/8GhE/D0iXgduAI4panMMcE36fCNwmCSl8hsi4rWIWAw8msarFVWvPSL+FRF/AV7tven2uO6sf2ZE/COVzwU2lNSvV2bdM7qz9uUR8WYqfw9Qi299dee/90j6JLCY7Hdfa7q19hrXnbV/BGiPiFkAEfFCRKzspXn3lJ763Y9KfWtJd9YewHslrQdsCLwOvNw70+4djRT0bQc8mfu+JJWVbJP+x+4lsv+XV07ftVl31l4Pemr9xwEPRcRra2iea0K31i7pAElzgdnAF3NBYK2oev2SBgBnA9/thXmuCd39e7+zpJmS/izp4DU92R7WnbUPAULS7ZIekvSNXphvT+upf/NGAtevoTmuKd1Z+43Av4CngSeASyPixTU94d7kNGxmZZC0F/B9sl2AhhERfwP2krQHcI2kP0ZELe/6VmI8MDEiltXH5ldFngZ2jIgXJDUDt0jaKyLqatejE+uRPdLyb8By4C5JrRFxV99Oq3dJOgBYHhFz+nouvWh/YCWwLbAJMF3S/0XE3/t2Wj2nkXb6ngJ2yH3fPpWVbJO2d98PvFBm37VZd9ZeD7q1fknbAzcDJ0XEojU+257VI7/7iJgPLCN7rrGWdGf9BwCXSHoM+BrwLUmnrekJ96Cq154eZXkBICJayZ6RGrLGZ9xzuvN7XwLcGxFLI2I5cBuw3xqfcc/qif/en0jt7fJB99b+GeBPEfFGRDwH3AfUVX7eRgr6HgQGS9pZ0gZkf6GnFrWZCpycPh8P3B3ZE51TgRPTGz87A4OBB3pp3j2hO2uvB1WvX9LGwB+AcyLivl6bcc/pztp3Tv8gImknYHeyB5trSdXrj4iDI2JgRAwELgMujIhaeoO9O7/7LSStCyBpENm/ebW029Gdf/NuB/aW1D/9/f8wMK+X5t1TuvVvvqR1gE9Te8/zQffW/gRwKICk9wIHAg/3yqx7S1+/SdKbP8DHgUfI/l/ruansfOAT6fN7yN7Se5QsqBuU63tu6rcA+Fhfr6WX1/4Y8CLZTs8Sit6EqoWfatcPnEf2jEdb7mfLvl5PL639c2QvMLQBDwGf7Ou19Ob6i8YYT429vdvN3/1xRb/7o/t6Lb35ewc+m9Y/B7ikr9fSB+sfDtzf12vo7bUDA1L5XLJAf1xfr6Wnf5yGzczMzKwBNNLtXTMzM7OG5aDPzMzMrAE46DMzMzNrAA76zMzMzBqAgz4zMzOzBuCgz8zWepJWSmqTNEfSren8xK76LOuifmNJX8p931bSjT0w14GSejWLgaQmSR/vzWuaWe1x0GdmtWBFRDRFxFCyMyO/3ANjbgy8HfRFxD8i4vgeGLdXpQOEm8jOJjMz65SDPjOrNTPIJVCXNE7Sg5LaJX23uLGkAZLukvSQpNmSjklVFwO7pB3ECfkdOkn3p3zLHWNMk9Qi6b2SrpL0gKSZubFKkjRG0i2S7pT0mKTTJH099b1f0qa58X+U283cP5Vvmvq3p/bDUvl4Sb+SdB/wK7KDZ0em/iMl7S9pRrrOXyXtlpvPTZL+JGmhpEtycz0y/RnNknRXKqtovWa2dluvrydgZlaulBrsMODn6ftHyFKE7Q8ImCrpkIi4N9ftVeDYiHhZ0ubA/ZKmAucAQyOiKY01MNdnClkaqu9I2gbYJiIKki4kS9l0SrrF/ICyhOz/Ws20hwL7kmUBeBQ4OyL2lTQROIksxRtA/4hoknQIcFXq911gZkR8UtKhwC/JdvUA9gQOiogVksYALRFxWlrLRsDBEfGmpMOBC8mybJD67wu8BiyQ9OP0Z/Qz4JCIWNwRjJJlIqp0vWa2lnLQZ2a1YENJbWQ7fPOBO1P5R9LPzPR9AFkQmA/6BFyYgqm30hhbdXG9XwN3AN8hC/46nvX7CPAJSWel7+8Bdkxz6sw9EfEK8Iqkl4BbU/lsYFiu3fUAEXGvpI1SkHUQKViLiLslbZYCOoCpEbGik2u+H7hG0mAggPVzdXdFxEsAkuYBOwGbAPdGxOJ0rRe7sV4zW0s56DOzWrAi7YL1B24ne6bvcrKA7qKI+Olq+o4GtgCaI+INSY+RBS+dioinJL2QbqeOBL6YqgQcFxELKpj7a7nPb+W+v8W7/w0uzonZVY7M1e22/TdZsHls2sGc1sl8VrL6/x2oZr1mtpbyM31mVjMiYjnwVeDM9ALD7cApkgYASNpO0pZF3d4PPJcCvhFkO1sArwDvW83lpgDfAN4fEe2p7HbgK5KUrrdvT6wrGZnGPAh4Ke3GTScLWpE0HFgaES+X6Fu8lvcDT6XPY8q49v3AIZJ2TtfquL27JtdrZr3MQZ+Z1ZSImAm0A6Mi4g7gOmCGpNlkt2GLA7lrgZZUfxLwcBrnBeC+9OLEhBKXuhE4kexWb4f/JrtV2i5pbvreU16VNBO4EvhCKhsPNEtqJ3vx5ORO+t4D7NnxIgdwCXBRGq/LOzoR8TwwFrhJ0iyygBfW7HrNrJcpoqs7CGZmtiZJmgacFRGFvp6LmdUv7/SZmZmZNQDv9JmZmf2/duxABgAAAECYv3Ug/RQtGHD6AAAGRB8AwIDoAwAYEH0AAAOiDwBgIL00mq5+hceUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_importantFeatures(clf,X_train,threshold=0.01,figsize=(10,10),color='b'):\n",
    "    importances=clf.feature_importances_\n",
    "    importances=importances[importances>=threshold]\n",
    "    features = X_train.columns\n",
    "    indices = np.argsort(importances)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color=color, align='center')\n",
    "    plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()\n",
    "\n",
    "plot_importantFeatures(rfc_up,X_train_up) #to correct - not consistent with table above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using only the Relevant Features from the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PDDXDT_diff_days</th>\n",
       "      <th>BIRTHDT</th>\n",
       "      <th>lastDate_diff_days</th>\n",
       "      <th>PRIMDIAG</th>\n",
       "      <th>SYSSTND</th>\n",
       "      <th>DOMSIDE</th>\n",
       "      <th>DIASTND</th>\n",
       "      <th>HRSTND</th>\n",
       "      <th>visitsdiff_days</th>\n",
       "      <th>DIASUP</th>\n",
       "      <th>...</th>\n",
       "      <th>MHROW_7</th>\n",
       "      <th>PDMEDT_diff_days</th>\n",
       "      <th>DFAGESX</th>\n",
       "      <th>PESEQ_11</th>\n",
       "      <th>MHROW_9</th>\n",
       "      <th>MHROW_11</th>\n",
       "      <th>MHROW_8</th>\n",
       "      <th>MHROW_10</th>\n",
       "      <th>PESEQ_13</th>\n",
       "      <th>MHROW_13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATNO</th>\n",
       "      <th>INFODT_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3001</th>\n",
       "      <th>2011-02-01</th>\n",
       "      <td>306</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>2707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-01</th>\n",
       "      <td>700</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>2313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2</td>\n",
       "      <td>79.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>394</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>1126</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2</td>\n",
       "      <td>85.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>426</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-04-01</th>\n",
       "      <td>1461</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1552</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>335</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01</th>\n",
       "      <td>1826</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>1187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2</td>\n",
       "      <td>78.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>365</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   PDDXDT_diff_days  BIRTHDT  lastDate_diff_days  PRIMDIAG  \\\n",
       "PATNO INFODT_date                                                            \n",
       "3001  2011-02-01                306   1946.0                2707       1.0   \n",
       "      2012-03-01                700   1946.0                2313       1.0   \n",
       "      2013-05-01               1126   1946.0                1887       1.0   \n",
       "      2014-04-01               1461   1946.0                1552       1.0   \n",
       "      2015-04-01               1826   1946.0                1187       1.0   \n",
       "\n",
       "                   SYSSTND  DOMSIDE  DIASTND  HRSTND  visitsdiff_days  DIASUP  \\\n",
       "PATNO INFODT_date                                                               \n",
       "3001  2011-02-01     136.0        2     90.0    72.0                0    90.0   \n",
       "      2012-03-01     124.0        2     79.0    76.0              394    83.0   \n",
       "      2013-05-01     104.0        2     85.0    88.0              426    72.0   \n",
       "      2014-04-01     107.0        2     76.0    82.0              335    68.0   \n",
       "      2015-04-01     114.0        2     78.0    84.0              365    81.0   \n",
       "\n",
       "                     ...     MHROW_7  PDMEDT_diff_days  DFAGESX  PESEQ_11  \\\n",
       "PATNO INFODT_date    ...                                                    \n",
       "3001  2011-02-01     ...           0                 0      0.0         1   \n",
       "      2012-03-01     ...           0                 0      0.0         1   \n",
       "      2013-05-01     ...           0                 0      0.0         1   \n",
       "      2014-04-01     ...           0                 0      0.0         1   \n",
       "      2015-04-01     ...           0                 0      0.0         1   \n",
       "\n",
       "                   MHROW_9  MHROW_11  MHROW_8  MHROW_10  PESEQ_13  MHROW_13  \n",
       "PATNO INFODT_date                                                            \n",
       "3001  2011-02-01         0         0        0         0         0         0  \n",
       "      2012-03-01         0         0        0         0         0         0  \n",
       "      2013-05-01         0         0        0         0         0         0  \n",
       "      2014-04-01         0         0        0         0         0         0  \n",
       "      2015-04-01         0         0        0         0         0         0  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_GS=data[RelevantFeaturesList]\n",
    "data_GS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.16"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([estimator.tree_.max_depth for estimator in rfc_up.estimators_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(param_grid, estimator, data, target, cv=3,njobs=-1):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    est = estimator\n",
    "    grid_search=GridSearchCV(est, param_grid,cv=cv)\n",
    "    grid_search.fit(data,target)\n",
    "    print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))\n",
    "    print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "    print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=40, max_features=12, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "Best parameters: {'max_features': 12, 'n_estimators': 250, 'max_depth': 40}\n",
      "Best cross-validation score: 0.90\n"
     ]
    }
   ],
   "source": [
    "param_grid_rfc={'n_estimators':[250,500],\n",
    "               'max_features':[7,10,12],\n",
    "               'max_depth':[20,30,40]}\n",
    "grid_search2_up=grid_search(param_grid_rfc, estimator=RandomForestClassifier(random_state=0), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.49065042, 4.99722465, 2.77177731, 5.67424003, 3.06176368,\n",
       "        6.09358637, 2.49837724, 4.94226011, 2.97134797, 5.81968506,\n",
       "        3.20316331, 6.37664056, 2.50313266, 4.96431065, 2.85334833,\n",
       "        5.6972692 , 3.15652164, 6.95034933]),\n",
       " 'mean_score_time': array([0.2523969 , 0.52203838, 0.22943068, 0.47631931, 0.24607929,\n",
       "        0.44986169, 0.25657368, 0.50934164, 0.24877501, 0.45821627,\n",
       "        0.22974515, 0.45491767, 0.251326  , 0.55193337, 0.23697035,\n",
       "        0.46155477, 0.23287074, 0.46993701]),\n",
       " 'mean_test_score': array([0.89843532, 0.89892428, 0.8997625 , 0.89997206, 0.89969265,\n",
       "        0.8994831 , 0.9031154 , 0.90262643, 0.90262643, 0.90353451,\n",
       "        0.90318525, 0.90367421, 0.90276614, 0.90297569, 0.90255658,\n",
       "        0.90283599, 0.90409332, 0.90304554]),\n",
       " 'mean_train_score': array([0.99647245, 0.99654226, 0.99713608, 0.9972409 , 0.99790444,\n",
       "        0.99793938, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'param_max_depth': masked_array(data=[20, 20, 20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 40, 40,\n",
       "                    40, 40, 40, 40],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[7, 7, 10, 10, 12, 12, 7, 7, 10, 10, 12, 12, 7, 7, 10,\n",
       "                    10, 12, 12],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[250, 500, 250, 500, 250, 500, 250, 500, 250, 500, 250,\n",
       "                    500, 250, 500, 250, 500, 250, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 20, 'max_features': 7, 'n_estimators': 250},\n",
       "  {'max_depth': 20, 'max_features': 7, 'n_estimators': 500},\n",
       "  {'max_depth': 20, 'max_features': 10, 'n_estimators': 250},\n",
       "  {'max_depth': 20, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 20, 'max_features': 12, 'n_estimators': 250},\n",
       "  {'max_depth': 20, 'max_features': 12, 'n_estimators': 500},\n",
       "  {'max_depth': 30, 'max_features': 7, 'n_estimators': 250},\n",
       "  {'max_depth': 30, 'max_features': 7, 'n_estimators': 500},\n",
       "  {'max_depth': 30, 'max_features': 10, 'n_estimators': 250},\n",
       "  {'max_depth': 30, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 30, 'max_features': 12, 'n_estimators': 250},\n",
       "  {'max_depth': 30, 'max_features': 12, 'n_estimators': 500},\n",
       "  {'max_depth': 40, 'max_features': 7, 'n_estimators': 250},\n",
       "  {'max_depth': 40, 'max_features': 7, 'n_estimators': 500},\n",
       "  {'max_depth': 40, 'max_features': 10, 'n_estimators': 250},\n",
       "  {'max_depth': 40, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 40, 'max_features': 12, 'n_estimators': 250},\n",
       "  {'max_depth': 40, 'max_features': 12, 'n_estimators': 500}],\n",
       " 'rank_test_score': array([18, 17, 14, 13, 15, 16,  5, 10, 10,  3,  4,  2,  9,  7, 12,  8,  1,\n",
       "         6], dtype=int32),\n",
       " 'split0_test_score': array([0.93027638, 0.93299832, 0.93488275, 0.93530151, 0.93467337,\n",
       "        0.93404523, 0.94053601, 0.93907035, 0.93907035, 0.94011725,\n",
       "        0.93760469, 0.93865159, 0.93781407, 0.93844221, 0.93948911,\n",
       "        0.93907035, 0.94011725, 0.93844221]),\n",
       " 'split0_train_score': array([0.99633124, 0.99622642, 0.99716981, 0.99748428, 0.99790356,\n",
       "        0.99800839, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split1_test_score': array([0.91404612, 0.91425577, 0.91530398, 0.9148847 , 0.91572327,\n",
       "        0.91551363, 0.91802935, 0.91802935, 0.91802935, 0.9197065 ,\n",
       "        0.92033543, 0.921174  , 0.91928721, 0.91886792, 0.91761006,\n",
       "        0.91865828, 0.92033543, 0.91949686]),\n",
       " 'split1_train_score': array([0.99664781, 0.99696208, 0.9973811 , 0.99727635, 0.99748586,\n",
       "        0.99759061, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'split2_test_score': array([0.8509434 , 0.84947589, 0.8490566 , 0.84968553, 0.84863732,\n",
       "        0.84884696, 0.85073375, 0.85073375, 0.85073375, 0.85073375,\n",
       "        0.85157233, 0.85115304, 0.85115304, 0.85157233, 0.85052411,\n",
       "        0.85073375, 0.85178197, 0.85115304]),\n",
       " 'split2_train_score': array([0.9964383 , 0.9964383 , 0.99685732, 0.99696208, 0.99832391,\n",
       "        0.99821915, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        ]),\n",
       " 'std_fit_time': array([0.24990411, 0.24839638, 0.02655481, 0.23506951, 0.02229803,\n",
       "        0.15268066, 0.07125943, 0.10448104, 0.03538835, 0.16884914,\n",
       "        0.05652233, 0.12310262, 0.05824618, 0.1176768 , 0.0359764 ,\n",
       "        0.02960423, 0.04501922, 0.41345247]),\n",
       " 'std_score_time': array([0.01684933, 0.02155943, 0.00447243, 0.03548389, 0.02051729,\n",
       "        0.01258883, 0.00847986, 0.00988408, 0.00314316, 0.01247508,\n",
       "        0.01030506, 0.00928957, 0.00817173, 0.09369359, 0.00583029,\n",
       "        0.0091981 , 0.00255543, 0.02024572]),\n",
       " 'std_test_score': array([0.03421908, 0.03578216, 0.0367238 , 0.03651111, 0.03691027,\n",
       "        0.03658486, 0.038151  , 0.03767468, 0.03767468, 0.03824306,\n",
       "        0.03715945, 0.03780597, 0.03726041, 0.03720477, 0.03785019,\n",
       "        0.03776142, 0.03784987, 0.03748871]),\n",
       " 'std_train_score': array([0.00013148, 0.0003092 , 0.00021516, 0.00021465, 0.00034213,\n",
       "        0.0002612 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2_up.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=30, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "Best parameters: {'max_features': 10, 'n_estimators': 500, 'max_depth': 30}\n",
      "Best cross-validation score: 0.90\n"
     ]
    }
   ],
   "source": [
    "param_grid_rfc2={'n_estimators':[500],\n",
    "               'max_features':[5,10,15],\n",
    "               'max_depth':[10,20,30]}\n",
    "grid_search3_up=grid_search(param_grid_rfc2, estimator=RandomForestClassifier(random_state=0), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.05891601, 4.10385291, 5.24767256, 4.02202797, 5.41419172,\n",
       "        6.847814  , 4.55425906, 5.84806434, 7.0884889 ]),\n",
       " 'mean_score_time': array([0.38116399, 0.3411657 , 0.32909719, 0.50070707, 0.45651031,\n",
       "        0.43583139, 0.53690672, 0.47267429, 0.44018245]),\n",
       " 'mean_test_score': array([0.8357083 , 0.83619726, 0.837734  , 0.89794635, 0.89997206,\n",
       "        0.89983236, 0.90332495, 0.90353451, 0.90199776]),\n",
       " 'mean_train_score': array([0.91052057, 0.91680742, 0.92037011, 0.9942722 , 0.9972409 ,\n",
       "        0.99839337, 1.        , 1.        , 1.        ]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 20, 20, 20, 30, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[5, 10, 15, 5, 10, 15, 5, 10, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'max_features': 5, 'n_estimators': 500},\n",
       "  {'max_depth': 10, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 10, 'max_features': 15, 'n_estimators': 500},\n",
       "  {'max_depth': 20, 'max_features': 5, 'n_estimators': 500},\n",
       "  {'max_depth': 20, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 20, 'max_features': 15, 'n_estimators': 500},\n",
       "  {'max_depth': 30, 'max_features': 5, 'n_estimators': 500},\n",
       "  {'max_depth': 30, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 30, 'max_features': 15, 'n_estimators': 500}],\n",
       " 'rank_test_score': array([9, 8, 7, 6, 4, 5, 2, 1, 3], dtype=int32),\n",
       " 'split0_test_score': array([0.87206868, 0.87479062, 0.87667504, 0.93048576, 0.93530151,\n",
       "        0.93362647, 0.93907035, 0.94011725, 0.93676717]),\n",
       " 'split0_train_score': array([0.91467505, 0.92180294, 0.92651992, 0.99454927, 0.99748428,\n",
       "        0.99821803, 1.        , 1.        , 1.        ]),\n",
       " 'split1_test_score': array([0.8572327 , 0.85932914, 0.860587  , 0.91467505, 0.9148847 ,\n",
       "        0.91509434, 0.92096436, 0.9197065 , 0.91802935]),\n",
       " 'split1_train_score': array([0.91745234, 0.92447098, 0.92604232, 0.99444794, 0.99727635,\n",
       "        0.99800964, 1.        , 1.        , 1.        ]),\n",
       " 'split2_test_score': array([0.77777778, 0.77442348, 0.77589099, 0.84863732, 0.84968553,\n",
       "        0.85073375, 0.84989518, 0.85073375, 0.85115304]),\n",
       " 'split2_train_score': array([0.89943432, 0.90414833, 0.90854808, 0.9938194 , 0.99696208,\n",
       "        0.99895244, 1.        , 1.        , 1.        ]),\n",
       " 'std_fit_time': array([0.08137359, 0.02410484, 0.01589963, 0.13170131, 0.12335289,\n",
       "        0.16029233, 0.07355541, 0.24020704, 0.2352853 ]),\n",
       " 'std_score_time': array([0.02494286, 0.00876259, 0.00168776, 0.0165341 , 0.0211217 ,\n",
       "        0.00759379, 0.016823  , 0.01638193, 0.00917416]),\n",
       " 'std_test_score': array([0.04139577, 0.04412088, 0.04420661, 0.03544853, 0.03651111,\n",
       "        0.03552226, 0.03848535, 0.03824306, 0.03674657]),\n",
       " 'std_train_score': array([0.00792073, 0.00901735, 0.00836171, 0.00032284, 0.00021465,\n",
       "        0.00040437, 0.        , 0.        , 0.        ])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search3_up.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=18, max_features=10, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
      "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
      "Best parameters: {'max_features': 10, 'n_estimators': 500, 'max_depth': 18}\n",
      "Best cross-validation score: 0.90\n"
     ]
    }
   ],
   "source": [
    "param_grid_rfc3={'n_estimators':[500],\n",
    "               'max_features':[5,10,15],\n",
    "               'max_depth':[10,15,18]}\n",
    "grid_search4_up=grid_search(param_grid_rfc3, estimator=RandomForestClassifier(random_state=0), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.98845363, 3.98993262, 5.08366474, 3.49005826, 4.91866835,\n",
       "        6.54688859, 3.9353617 , 5.55442166, 6.64459729]),\n",
       " 'mean_score_time': array([0.34641504, 0.32942128, 0.33834863, 0.43737308, 0.41767033,\n",
       "        0.40905269, 0.52869169, 0.4665091 , 0.42439095]),\n",
       " 'mean_test_score': array([0.8357083 , 0.83619726, 0.837734  , 0.88313775, 0.88572227,\n",
       "        0.88593182, 0.89571109, 0.89745739, 0.89745739]),\n",
       " 'mean_train_score': array([0.91052057, 0.91680742, 0.92037011, 0.97331652, 0.98033679,\n",
       "        0.98424814, 0.98948714, 0.99441188, 0.99601844]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 15, 15, 15, 18, 18, 18],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[5, 10, 15, 5, 10, 15, 5, 10, 15],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'max_features': 5, 'n_estimators': 500},\n",
       "  {'max_depth': 10, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 10, 'max_features': 15, 'n_estimators': 500},\n",
       "  {'max_depth': 15, 'max_features': 5, 'n_estimators': 500},\n",
       "  {'max_depth': 15, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 15, 'max_features': 15, 'n_estimators': 500},\n",
       "  {'max_depth': 18, 'max_features': 5, 'n_estimators': 500},\n",
       "  {'max_depth': 18, 'max_features': 10, 'n_estimators': 500},\n",
       "  {'max_depth': 18, 'max_features': 15, 'n_estimators': 500}],\n",
       " 'rank_test_score': array([9, 8, 7, 6, 5, 4, 3, 1, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.87206868, 0.87479062, 0.87667504, 0.91834171, 0.91813233,\n",
       "        0.91876047, 0.92881072, 0.93069514, 0.92881072]),\n",
       " 'split0_train_score': array([0.91467505, 0.92180294, 0.92651992, 0.9730608 , 0.98081761,\n",
       "        0.98301887, 0.98878407, 0.99454927, 0.99601677]),\n",
       " 'split1_test_score': array([0.8572327 , 0.85932914, 0.860587  , 0.89769392, 0.90125786,\n",
       "        0.90209644, 0.91174004, 0.91404612, 0.91404612]),\n",
       " 'split1_train_score': array([0.91745234, 0.92447098, 0.92604232, 0.97747748, 0.98240101,\n",
       "        0.98816258, 0.99036246, 0.9947622 , 0.99622879]),\n",
       " 'split2_test_score': array([0.77777778, 0.77442348, 0.77589099, 0.83333333, 0.83773585,\n",
       "        0.83689727, 0.84654088, 0.8475891 , 0.84947589]),\n",
       " 'split2_train_score': array([0.89943432, 0.90414833, 0.90854808, 0.96941127, 0.97779175,\n",
       "        0.98156296, 0.9893149 , 0.99392416, 0.99580976]),\n",
       " 'std_fit_time': array([0.12609294, 0.05041953, 0.05559646, 0.04442795, 0.07212255,\n",
       "        0.34278028, 0.03390027, 0.16122812, 0.15932595]),\n",
       " 'std_score_time': array([0.00870238, 0.00242758, 0.00952529, 0.00165261, 0.01035017,\n",
       "        0.0107608 , 0.04689023, 0.02622188, 0.01040851]),\n",
       " 'std_test_score': array([0.04139577, 0.04412088, 0.04420661, 0.03620125, 0.03461347,\n",
       "        0.03532321, 0.03544959, 0.03590055, 0.03444893]),\n",
       " 'std_train_score': array([0.00792073, 0.00901735, 0.00836171, 0.00329798, 0.00191219,\n",
       "        0.00283103, 0.00065578, 0.00035566, 0.00017107])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search4_up.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV on xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
      "       max_depth=10, min_child_weight=1, missing=None, n_estimators=250,\n",
      "       n_jobs=1, njobs=-1, nthread=None, objective='multi:softprob',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=0, silent=True, subsample=1)\n",
      "Best parameters: {'learning_rate': 0.005, 'max_depth': 10, 'n_estimators': 250}\n",
      "Best cross-validation score: 0.85\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb1={'n_estimators':[100,250],\n",
    "               'learning_rate':[0.005],\n",
    "               'max_depth':[5,7,10]}\n",
    "grid_search_xgb1=grid_search(param_grid_xgb1, estimator=XGBClassifier(seed=0,njobs=-1), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 43.48839569, 111.46507557,  60.09012826, 143.52294731,\n",
       "         80.93842705, 184.0702726 ]),\n",
       " 'mean_score_time': array([0.17739042, 0.51545008, 0.23133508, 0.68863535, 0.30539266,\n",
       "        1.15255372]),\n",
       " 'mean_test_score': array([0.73379436, 0.75677564, 0.79316848, 0.80776753, 0.84164571,\n",
       "        0.85128528]),\n",
       " 'mean_train_score': array([0.80329434, 0.83727894, 0.88250789, 0.90695601, 0.94991455,\n",
       "        0.96531718]),\n",
       " 'param_learning_rate': masked_array(data=[0.005, 0.005, 0.005, 0.005, 0.005, 0.005],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[5, 5, 7, 7, 10, 10],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 250, 100, 250, 100, 250],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.005, 'max_depth': 5, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.005, 'max_depth': 5, 'n_estimators': 250},\n",
       "  {'learning_rate': 0.005, 'max_depth': 7, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.005, 'max_depth': 7, 'n_estimators': 250},\n",
       "  {'learning_rate': 0.005, 'max_depth': 10, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.005, 'max_depth': 10, 'n_estimators': 250}],\n",
       " 'rank_test_score': array([6, 5, 4, 3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.74727806, 0.77198492, 0.81469849, 0.83123953, 0.86034338,\n",
       "        0.86976549]),\n",
       " 'split0_train_score': array([0.79056604, 0.83238994, 0.87683438, 0.90104822, 0.94213836,\n",
       "        0.95890985]),\n",
       " 'split1_test_score': array([0.75597484, 0.7672956 , 0.80230608, 0.80880503, 0.85534591,\n",
       "        0.86477987]),\n",
       " 'split1_train_score': array([0.80274461, 0.82537188, 0.88162581, 0.90383407, 0.95265032,\n",
       "        0.96689713]),\n",
       " 'split2_test_score': array([0.69811321, 0.73102725, 0.76247379, 0.78322851, 0.80922432,\n",
       "        0.81928721]),\n",
       " 'split2_train_score': array([0.81657239, 0.85407501, 0.88906348, 0.91598575, 0.95495495,\n",
       "        0.97014456]),\n",
       " 'std_fit_time': array([2.66929006, 2.32332564, 1.34538795, 5.88957607, 5.2750238 ,\n",
       "        2.00005366]),\n",
       " 'std_score_time': array([0.00532102, 0.07955257, 0.02153138, 0.02531468, 0.01580152,\n",
       "        0.17665597]),\n",
       " 'std_test_score': array([0.02547117, 0.01830156, 0.02227973, 0.01961618, 0.02300883,\n",
       "        0.02271035]),\n",
       " 'std_train_score': array([0.01062416, 0.01221731, 0.00503132, 0.00648549, 0.00557851,\n",
       "        0.00472065])}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
      "       max_depth=15, min_child_weight=1, missing=None, n_estimators=250,\n",
      "       n_jobs=1, njobs=-1, nthread=None, objective='multi:softprob',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=0, silent=True, subsample=1)\n",
      "Best parameters: {'learning_rate': 0.005, 'max_depth': 15, 'n_estimators': 250}\n",
      "Best cross-validation score: 0.87\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb2={'n_estimators':[250],\n",
    "               'learning_rate':[0.005],\n",
    "               'max_depth':[10,12,15]}\n",
    "grid_search_xgb2=grid_search(param_grid_xgb2, estimator=XGBClassifier(seed=0,njobs=-1), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([258.14451869, 258.1622204 , 237.14172467]),\n",
       " 'mean_score_time': array([3.30912296, 1.519147  , 1.51991264]),\n",
       " 'mean_test_score': array([0.85128528, 0.86511595, 0.87272981]),\n",
       " 'mean_train_score': array([0.96531718, 0.98306024, 0.99238578]),\n",
       " 'param_learning_rate': masked_array(data=[0.005, 0.005, 0.005],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 12, 15],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[250, 250, 250],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.005, 'max_depth': 10, 'n_estimators': 250},\n",
       "  {'learning_rate': 0.005, 'max_depth': 12, 'n_estimators': 250},\n",
       "  {'learning_rate': 0.005, 'max_depth': 15, 'n_estimators': 250}],\n",
       " 'rank_test_score': array([3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.86976549, 0.88588777, 0.89468174]),\n",
       " 'split0_train_score': array([0.95890985, 0.97987421, 0.99067086]),\n",
       " 'split1_test_score': array([0.86477987, 0.87631027, 0.8836478 ]),\n",
       " 'split1_train_score': array([0.96689713, 0.98428661, 0.9938194 ]),\n",
       " 'split2_test_score': array([0.81928721, 0.83312369, 0.83983229]),\n",
       " 'split2_train_score': array([0.97014456, 0.9850199 , 0.99266709]),\n",
       " 'std_fit_time': array([24.11320715, 40.11332784, 13.64326338]),\n",
       " 'std_score_time': array([2.91832279, 0.32960562, 0.14931018]),\n",
       " 'std_test_score': array([0.02271035, 0.02295043, 0.02368711]),\n",
       " 'std_train_score': array([0.00472065, 0.00227267, 0.00130069])}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
      "       max_depth=15, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, njobs=-1, nthread=None, objective='multi:softprob',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=0, silent=True, subsample=1)\n",
      "Best parameters: {'learning_rate': 0.005, 'max_depth': 15, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.86\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb3={'n_estimators':[100],\n",
    "               'learning_rate':[0.005],\n",
    "               'max_depth':[10,12,15]}\n",
    "grid_search_xgb3=grid_search(param_grid_xgb3, estimator=XGBClassifier(seed=0,njobs=-1), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([72.82414699, 79.65618896, 90.97650798]),\n",
       " 'mean_score_time': array([0.27262036, 0.28293467, 0.33811474]),\n",
       " 'mean_test_score': array([0.84164571, 0.85554624, 0.8632998 ]),\n",
       " 'mean_train_score': array([0.94991455, 0.9699627 , 0.98295551]),\n",
       " 'param_learning_rate': masked_array(data=[0.005, 0.005, 0.005],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[10, 12, 15],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 100, 100],\n",
       "              mask=[False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.005, 'max_depth': 10, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.005, 'max_depth': 12, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.005, 'max_depth': 15, 'n_estimators': 100}],\n",
       " 'rank_test_score': array([3, 2, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.86034338, 0.8739531 , 0.88316583]),\n",
       " 'split0_train_score': array([0.94213836, 0.96530398, 0.97997904]),\n",
       " 'split1_test_score': array([0.85534591, 0.87127883, 0.87651992]),\n",
       " 'split1_train_score': array([0.95265032, 0.97150639, 0.98418186]),\n",
       " 'split2_test_score': array([0.80922432, 0.82138365, 0.83018868]),\n",
       " 'split2_train_score': array([0.95495495, 0.97307773, 0.98470564]),\n",
       " 'std_fit_time': array([2.16847915, 1.1059112 , 1.11477894]),\n",
       " 'std_score_time': array([0.03959265, 0.01161233, 0.02553952]),\n",
       " 'std_test_score': array([0.02300883, 0.02417368, 0.02356251]),\n",
       " 'std_train_score': array([0.00557851, 0.00335609, 0.00211552])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb3.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
      "       max_depth=20, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, njobs=-1, nthread=None, objective='multi:softprob',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=0, silent=True, subsample=1)\n",
      "Best parameters: {'learning_rate': 0.005, 'max_depth': 20, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.87\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb4={'n_estimators':[50,100],\n",
    "               'learning_rate':[0.005],\n",
    "               'max_depth':[15,20]}\n",
    "grid_search_xgb4=grid_search(param_grid_xgb4, estimator=XGBClassifier(seed=0,njobs=-1), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 45.66247765,  94.31431262,  61.57371394, 115.90997561]),\n",
       " 'mean_score_time': array([0.15694364, 0.33077065, 0.28004734, 0.63530501]),\n",
       " 'mean_test_score': array([0.85582565, 0.8632998 , 0.8614138 , 0.86735122]),\n",
       " 'mean_train_score': array([0.97565613, 0.98295551, 0.98285117, 0.98906805]),\n",
       " 'param_learning_rate': masked_array(data=[0.005, 0.005, 0.005, 0.005],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[15, 15, 20, 20],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[50, 100, 50, 100],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.005, 'max_depth': 15, 'n_estimators': 50},\n",
       "  {'learning_rate': 0.005, 'max_depth': 15, 'n_estimators': 100},\n",
       "  {'learning_rate': 0.005, 'max_depth': 20, 'n_estimators': 50},\n",
       "  {'learning_rate': 0.005, 'max_depth': 20, 'n_estimators': 100}],\n",
       " 'rank_test_score': array([4, 2, 3, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.87835008, 0.88316583, 0.88295645, 0.88860972]),\n",
       " 'split0_train_score': array([0.97337526, 0.97997904, 0.98197065, 0.9884696 ]),\n",
       " 'split1_test_score': array([0.86771488, 0.87651992, 0.87085954, 0.87945493]),\n",
       " 'split1_train_score': array([0.97852504, 0.98418186, 0.98449612, 0.9893149 ]),\n",
       " 'split2_test_score': array([0.82138365, 0.83018868, 0.83039832, 0.83396226]),\n",
       " 'split2_train_score': array([0.97506809, 0.98470564, 0.98208674, 0.98941965]),\n",
       " 'std_fit_time': array([1.10563222, 3.430081  , 3.01822699, 1.80787814]),\n",
       " 'std_score_time': array([0.01077643, 0.00513663, 0.11228583, 0.23077331]),\n",
       " 'std_test_score': array([0.02473071, 0.02356251, 0.02247381, 0.02389628]),\n",
       " 'std_train_score': array([0.00214311, 0.00211552, 0.00116412, 0.00042532])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb4.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
      "       max_depth=25, min_child_weight=1, missing=None, n_estimators=50,\n",
      "       n_jobs=1, njobs=-1, nthread=None, objective='multi:softprob',\n",
      "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "       seed=0, silent=True, subsample=1)\n",
      "Best parameters: {'learning_rate': 0.005, 'max_depth': 25, 'n_estimators': 50}\n",
      "Best cross-validation score: 0.86\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb5={'n_estimators':[25,50],\n",
    "               'learning_rate':[0.005],\n",
    "               'max_depth':[20,25]}\n",
    "grid_search_xgb5=grid_search(param_grid_xgb5, estimator=XGBClassifier(seed=0,njobs=-1), \n",
    "                        data=data_up, \n",
    "                         target=target_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([24.89038332, 50.14715338, 34.49055799, 60.62206968]),\n",
       " 'mean_score_time': array([0.09376605, 0.17527374, 0.12596273, 0.1679186 ]),\n",
       " 'mean_test_score': array([0.85491757, 0.8614138 , 0.85736239, 0.86281084]),\n",
       " 'mean_train_score': array([0.97635452, 0.98285117, 0.97792661, 0.98368931]),\n",
       " 'param_learning_rate': masked_array(data=[0.005, 0.005, 0.005, 0.005],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[20, 20, 25, 25],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[25, 50, 25, 50],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.005, 'max_depth': 20, 'n_estimators': 25},\n",
       "  {'learning_rate': 0.005, 'max_depth': 20, 'n_estimators': 50},\n",
       "  {'learning_rate': 0.005, 'max_depth': 25, 'n_estimators': 25},\n",
       "  {'learning_rate': 0.005, 'max_depth': 25, 'n_estimators': 50}],\n",
       " 'rank_test_score': array([4, 2, 3, 1], dtype=int32),\n",
       " 'split0_test_score': array([0.87458124, 0.88295645, 0.88023451, 0.88505025]),\n",
       " 'split0_train_score': array([0.97348008, 0.98197065, 0.97704403, 0.98238994]),\n",
       " 'split1_test_score': array([0.86289308, 0.87085954, 0.86436059, 0.87274633]),\n",
       " 'split1_train_score': array([0.9769537 , 0.98449612, 0.9778965 , 0.98596271]),\n",
       " 'split2_test_score': array([0.82725367, 0.83039832, 0.82746331, 0.83060797]),\n",
       " 'split2_train_score': array([0.97862979, 0.98208674, 0.9788393 , 0.98271527]),\n",
       " 'std_fit_time': array([0.3447146 , 0.70313226, 8.50624239, 4.02120275]),\n",
       " 'std_score_time': array([0.01201347, 0.01853241, 0.03205222, 0.00315578]),\n",
       " 'std_test_score': array([0.02012906, 0.02247381, 0.02210661, 0.02331144]),\n",
       " 'std_train_score': array([0.00214463, 0.00116412, 0.00073323, 0.00161301])}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb5.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final temptative to reduce overfitting: ensembling models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.005, max_delta_step=0,\n",
       "       max_depth=15, min_child_weight=1, missing=None, n_estimators=250,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc=RandomForestClassifier(max_depth=40, max_features=12, n_estimators=250)\n",
    "rfc_tradeOff=RandomForestClassifier(max_depth=15, max_features=5, n_estimators=500)\n",
    "xgb_tradeOff=XGBClassifier(learning_rate=0.005, max_depth=12, n_estimators=100)\n",
    "best_xgb=XGBClassifier(learning_rate=0.005, max_depth=15, n_estimators=250)\n",
    "\n",
    "best_rfc.fit(X_train_up,y_train_up)\n",
    "rfc_tradeOff.fit(X_train_up,y_train_up)\n",
    "xgb_tradeOff.fit(X_train_up, y_train_up)\n",
    "best_xgb.fit(X_train_up,y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Score-best_rfc: 1.0000, Test-Accuracy-best_rfc: 0.7674\n",
      "Train-Score-rfc-TradeOff: 0.9776, Test-Accuracy-rfc_TradeOff: 0.7549\n",
      "Train-Score-best_xgb: 0.9915, Test-Accuracy-best_xgb: 0.7263\n",
      "Train-Score-xgb_tradeOff: 0.9742, Test-Accuracy-xgb_tradeOff: 0.7110\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-Score-best_rfc: %.4f, Test-Accuracy-best_rfc: %.4f\" % (best_rfc.score(X_train_up, y_train_up), \n",
    "                                                             best_rfc.score(X_test, y_test)))\n",
    "print(\"Train-Score-rfc-TradeOff: %.4f, Test-Accuracy-rfc_TradeOff: %.4f\" % (rfc_tradeOff.score(X_train_up, y_train_up), \n",
    "                                                             rfc_tradeOff.score(X_test, y_test)))\n",
    "\n",
    "print(\"Train-Score-best_xgb: %.4f, Test-Accuracy-best_xgb: %.4f\" % (best_xgb.score(X_train_up, y_train_up), \n",
    "                                                         best_xgb.score(X_test, y_test)))\n",
    "print(\"Train-Score-xgb_tradeOff: %.4f, Test-Accuracy-xgb_tradeOff: %.4f\" % (xgb_tradeOff.score(X_train_up, y_train_up), \n",
    "                                                         xgb_tradeOff.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf1=VotingClassifier([('LogisticRegression', logreg_up), ('best_rfc',best_rfc)],voting='hard')\n",
    "eclf2=VotingClassifier([('LogisticRegression', logreg_up), ('best_rfc',best_rfc)],voting='soft',weights=[1,2])\n",
    "\n",
    "eclf3=VotingClassifier([('LogisticRegression', logreg_up), \n",
    "                        ('best_rfc',best_rfc), ('best_xgb', best_xgb)],voting='hard')\n",
    "eclf4=VotingClassifier([('LogisticRegression', logreg_up), \n",
    "                        ('best_rfc',best_rfc), ('best_xgb', best_xgb)],voting='soft',weights=[1,2,2])\n",
    "\n",
    "eclf5=VotingClassifier([('LogisticRegression', logreg_up), \n",
    "                        ('rfc_tradeoff',rfc_tradeOff), ('xgb_tradeOff', xgb_tradeOff)],voting='hard')\n",
    "eclf6=VotingClassifier([('LogisticRegression', logreg_up), \n",
    "                        ('rfc_tradeoff',rfc_tradeOff), ('best_xgb', xgb_tradeOff)],voting='soft',weights=[1,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=Fa...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf1.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=Fa...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft', weights=[1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf2.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=Fa...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft',\n",
       "         weights=[1, 2, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf3.fit(X_train_up, y_train_up)\n",
    "eclf4.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('LogisticRegression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=Fa...\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1))],\n",
       "         flatten_transform=None, n_jobs=1, voting='soft',\n",
       "         weights=[1, 2, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf5.fit(X_train_up, y_train_up)\n",
    "eclf6.fit(X_train_up, y_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression(0.8230600438858967, 0.637883008356546)\n",
      "Random Forest(1.0, 0.7743732590529248)\n",
      "XGBoost(0.8863953720327149, 0.6657381615598886)\n",
      "Ensemble LogReg + RF - Hard Voting(0.9085378017155396, 0.7207520891364902)\n",
      "Ensemble LogReg + RF - Soft Voting(0.9994015559545183, 0.7569637883008357)\n",
      "Ensemble LogReg + best RF + best XGB - Hard Voting(0.993018152802713, 0.75)\n",
      "Ensemble LogReg+ Best RF+Best XGB - Soft Voting(0.9980051865150609, 0.7618384401114207)\n",
      "Ensemble LogReg+ TradeOff RF+TradeOff XGB - Hard VotingEnsemble LogReg+ TradeOff RF+TradeOff XGB - Soft Voting(0.9687811689607022, 0.7374651810584958)\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([logreg_up, rfc_up, xgb_up, eclf1, eclf2, eclf3, eclf4, eclf5, eclf6], ['Logistic Regression', 'Random Forest', \n",
    "                                                                         'XGBoost', \n",
    "                                                                         'Ensemble LogReg + RF - Hard Voting',\n",
    "                                                                         'Ensemble LogReg + RF - Soft Voting',\n",
    "                                                                         'Ensemble LogReg + best RF + best XGB - Hard Voting',\n",
    "                                                                         'Ensemble LogReg+ Best RF+Best XGB - Soft Voting',\n",
    "                                                                         'Ensemble LogReg+ TradeOff RF+TradeOff XGB - Hard Voting'\n",
    "                                                                         'Ensemble LogReg+ TradeOff RF+TradeOff XGB - Soft Voting']):\n",
    "    score= (clf.score(X_train_up, y_train_up),clf.score(X_test, y_test))\n",
    "    print(label+'{}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_validation on ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cross_validate_ecfl1=cross_validate(eclf1,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_ecfl2=cross_validate(eclf2,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cross_validate_ecfl3=cross_validate(eclf3,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_ecfl4=cross_validate(eclf4,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/Users/alicemartin/miniconda3/envs/project/lib/python3.5/site-packages/sklearn/utils/optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cross_validate_ecfl5=cross_validate(eclf5,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)\n",
    "cross_validate_ecfl6=cross_validate(eclf6,data_up,target_up,cv=3,n_jobs=-1,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Ensemble LR+RF-Hard Voting: 0.90 (+/- 0.02)\n",
      "Training Accuracy Ensemble LR+RF-Soft Voting: 1.00 (+/- 0.00)\n",
      "Training Accuracy Ensemble LR+Rf+XGB (best)- Hard Voting: 0.99 (+/- 0.00)\n",
      "Training Accuracy Ensemble LR+Rf+XGB (best)- Soft Voting: 1.00 (+/- 0.00)\n",
      "Training Accuracy Ensemble LR+Rf+XGB (Trade-off)- Hard Voting: 0.97 (+/- 0.00)\n",
      "Training Accuracy Ensemble LR+Rf+XGB (Trade-off)- Soft Voting: 0.96 (+/- 0.01)\n",
      "Test Accuracy Ensemble LR+RF-Hard Voting: 0.82 (+/- 0.05)\n",
      "Test Accuracy Ensemble LR+RF-Soft Voting: 0.89 (+/- 0.06)\n",
      "Test Accuracy Ensemble LR+Rf+XGB (best)- Hard Voting: 0.88 (+/- 0.06)\n",
      "Test Accuracy Ensemble LR+Rf+XGB (best)- Soft Voting: 0.89 (+/- 0.06)\n",
      "Test Accuracy Ensemble LR+Rf+XGB (Trade-off)- Hard Voting: 0.87 (+/- 0.06)\n",
      "Test Accuracy Ensemble LR+Rf+XGB (Trade-off)- Soft Voting: 0.86 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "#print(cross_validate_lr)\n",
    "print(\"Training Accuracy Ensemble LR+RF-Hard Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl1['train_score'].mean(), cross_validate_ecfl1['train_score'].std() * 2))\n",
    "print(\"Training Accuracy Ensemble LR+RF-Soft Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl2['train_score'].mean(), cross_validate_ecfl2['train_score'].std() * 2))\n",
    "print(\"Training Accuracy Ensemble LR+Rf+XGB (best)- Hard Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl3['train_score'].mean(), cross_validate_ecfl3['train_score'].std() * 2))\n",
    "print(\"Training Accuracy Ensemble LR+Rf+XGB (best)- Soft Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl4['train_score'].mean(), cross_validate_ecfl4['train_score'].std() * 2))\n",
    "print(\"Training Accuracy Ensemble LR+Rf+XGB (Trade-off)- Hard Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl5['train_score'].mean(), cross_validate_ecfl5['train_score'].std() * 2))\n",
    "print(\"Training Accuracy Ensemble LR+Rf+XGB (Trade-off)- Soft Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl6['train_score'].mean(), cross_validate_ecfl6['train_score'].std() * 2))\n",
    "\n",
    "print(\"Test Accuracy Ensemble LR+RF-Hard Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl1['test_score'].mean(), cross_validate_ecfl1['test_score'].std() * 2))\n",
    "print(\"Test Accuracy Ensemble LR+RF-Soft Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl2['test_score'].mean(), cross_validate_ecfl2['test_score'].std() * 2))\n",
    "print(\"Test Accuracy Ensemble LR+Rf+XGB (best)- Hard Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl3['test_score'].mean(), cross_validate_ecfl3['test_score'].std() * 2))\n",
    "print(\"Test Accuracy Ensemble LR+Rf+XGB (best)- Soft Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl4['test_score'].mean(), cross_validate_ecfl4['test_score'].std() * 2))\n",
    "print(\"Test Accuracy Ensemble LR+Rf+XGB (Trade-off)- Hard Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl5['test_score'].mean(), cross_validate_ecfl5['test_score'].std() * 2))\n",
    "print(\"Test Accuracy Ensemble LR+Rf+XGB (Trade-off)- Soft Voting: %0.2f (+/- %0.2f)\" % (cross_validate_ecfl6['test_score'].mean(), cross_validate_ecfl6['test_score'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

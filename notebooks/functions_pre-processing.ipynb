{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib.parse\n",
    "from glob import glob\n",
    "import os\n",
    "import ntpath \n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_csv_files(folder_path):\n",
    "    '''PRE-PROCESSING: reading the csv file on a particular folder'''\n",
    "    \n",
    "    # saving all the csv files in a dataframe\n",
    "    import os\n",
    "    import glob\n",
    "    # glob.glob('*.csv') #find all the csv files in a pathname. \n",
    "    os.chdir(folder_path)\n",
    "    csv_files = [i for i in glob.glob('*.csv')]\n",
    "\n",
    "    # Reading each csv file and storing them in a dictionnary containing the file name and the dataframe\n",
    "    dict_files={}\n",
    "    files_names=[]\n",
    "    for files in csv_files:\n",
    "        df=pd.read_csv(files,engine='python')\n",
    "        basepath, filename=ntpath.split(files)\n",
    "        files_names.append(filename)\n",
    "        dict_files[filename]=df\n",
    "\n",
    "    # Calculating the # of rows and features for each dataframe and storing them in a list of tuples\n",
    "    shape_df=[]\n",
    "    for i in range(0,len(dict_files.keys())):\n",
    "        nrows, ncols=(len(dict_files[files_names[i]]),len(dict_files[files_names[i]].columns))\n",
    "        shape_df.append((nrows,ncols))\n",
    "\n",
    "    return (shape_df,files_names,dict_files)\n",
    "\n",
    "def number_of_patients(df):\n",
    "    '''PRE_PROCESSING: return the number of patients in each csv files'''\n",
    "    if 'PATNO' in df.columns:\n",
    "        patients=len(list(set(df['PATNO'])))\n",
    "    else: \n",
    "        patients=0\n",
    "    return patients\n",
    "\n",
    "# to change by adding the max sequence length. \n",
    "def number_of_events(df): \n",
    "    '''PRE_PROCESSING: return the number of events covered by each csv file'''\n",
    "    if 'EVENT_ID' in df.columns:\n",
    "        events=len(list(set(df['EVENT_ID'])))\n",
    "    else: \n",
    "        events=0\n",
    "    return events\n",
    "\n",
    "def features_selection(list_df_sel):\n",
    "    '''PRE PROCESSING: do features selection for each df,sel in list_df_sel'''\n",
    "    return df_sel\n",
    "\n",
    "def patients_selection(df, threshold=6):\n",
    "    '''PRE-PROCESSING: return a dataframe containing only the patients with number of visits > threshold'''\n",
    "    if 'PATNO' in df.columns: \n",
    "        visits_number_by_pat=df.groupby('PATNO').size().sort_values(ascending=False)\n",
    "        mask_sel=visits_number_by_pat>=threshold\n",
    "        patients_sel=list(mask_sel[mask_sel.values==True].index)\n",
    "        df=df.loc[df['PATNO'].isin(patients_sel),:]\n",
    "        df=df.sort_values('PATNO')\n",
    "        return (patients_sel, df)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def padding_cropping_analysis(df,input_timesteps=4,th_drop=2):\n",
    "    \n",
    "    '''Return the number of crops, pads, drops to do in function of the length of the input \n",
    "    sequence and the threshold of pads allowed'''\n",
    "    \n",
    "    ## Write some assert statement for this function\n",
    "    visits_number=df.groupby('PATNO').size().sort_values(ascending=False)\n",
    "\n",
    "    patients_cropping=visits_number[visits_number>input_timesteps].to_frame().rename(columns=dict(zip([0],['visits_num'])))\n",
    "    patients_nothing=visits_number[visits_number==input_timesteps].to_frame().rename(columns=dict(zip([0],['visits_num'])))\n",
    "    patients_dropping=visits_number[visits_number<input_timesteps-th_drop].to_frame().rename(columns=dict(zip([0],['visits_num'])))\n",
    "    pad_mask=((visits_number>=(input_timesteps-2)) & (visits_number<input_timesteps))\n",
    "    patients_padding=visits_number[pad_mask].to_frame().rename(columns=dict(zip([0],['visits_num'])))\n",
    "\n",
    "    patients_cropping['processing_op']='cropping'\n",
    "    patients_cropping['op_num']=patients_cropping['visits_num']-(input_timesteps)\n",
    "    num_crops=patients_cropping['op_num'].sum()\n",
    "    \n",
    "    patients_nothing['processing_op']='nothing'\n",
    "    patients_nothing['op_num']=patients_nothing['visits_num']-(input_timesteps)\n",
    "    \n",
    "    assert patients_nothing['op_num'].sum()==0\n",
    "    \n",
    "    patients_dropping['processing_op']='dropping'\n",
    "    patients_dropping['op_num']=(input_timesteps-2)-patients_dropping['visits_num']\n",
    "    num_drops=patients_dropping['op_num'].sum()\n",
    "    \n",
    "    patients_padding['processing_op']='padding'\n",
    "    patients_padding['op_num']=(input_timesteps)-patients_padding['visits_num']\n",
    "    num_pads=patients_padding['op_num'].sum()\n",
    "\n",
    "    df_visits=pd.concat([patients_dropping,patients_padding,patients_nothing,patients_cropping],axis=0)\n",
    "  \n",
    "    #operations_num=df_visits.groupby('processing_op').size()\n",
    "    #index=list(operations_num.index)\n",
    "    #index_values=[operations_num[i] for i in index]\n",
    "    #num_pat=dict(zip(index,index_values))\n",
    "    \n",
    "    return (df_visits, dict(zip(['drops','pads','crops'],[num_drops,num_pads,num_crops])))\n",
    "\n",
    "def table_analysis(list_df,df_names,threshold=6,input_timesteps=4,th_drop=2): \n",
    "    '''PRE-PROCESSING: return a dataframe with: \n",
    "    -as rows: list of df\n",
    "    -as columns: \n",
    "        - total number of observations=rows\n",
    "        - total number of features=columns after features_selection - features_selection function \n",
    "        - number of events\n",
    "        - number of PD patients by using PRODROMA info - number_of_patients function\n",
    "        - number of patients with # of visits > threshold - number_of_patients function\n",
    "        - shape of final df after selections of rows and columns\n",
    "        -number of NaN values in the final df\n",
    "        NB: takes as input the df with features selection. \n",
    "    '''   \n",
    "    # initialisation df\n",
    "    col=['observations_tot','features','events_num','patients_num',\n",
    "         'patients_sel','len_df_sel','drops','pads','crops','new_len','NaN_values']\n",
    "    df_df=pd.DataFrame(columns=col,index=df_names)\n",
    "\n",
    "    # remplissage of dataframe for each row\n",
    "    for i,df in enumerate(list_df):\n",
    "        \n",
    "        df_df.iloc[i,:]['observations_tot']=len(df)\n",
    "        df_df.iloc[i,:]['features']=len(df.columns)\n",
    "        df_df.iloc[i,:]['events_num']=number_of_events(df)\n",
    "        df_df.iloc[i,:]['patients_num']=number_of_patients(df)\n",
    "        \n",
    "        if not patients_selection(df)==0:\n",
    "            df=patients_selection(df,threshold=threshold)[1]          \n",
    "            df_df.iloc[i,:]['patients_sel']=len(set(df['PATNO']))\n",
    "        else: \n",
    "            if 'PATNO' in df.columns:\n",
    "                df_df.iloc[i,:]['patients_sel']=len(set(df['PATNO']))\n",
    "            else:\n",
    "                df_df.iloc[i,:]['patients_sel']=0            \n",
    "        df_df.iloc[i,:]['len_df_sel']=len(df)\n",
    "        df_df.iloc[i,:]['NaN_values']=(df.isnull().sum().sum())/(df_df.iloc[i,:]['len_df_sel']*df_df.iloc[i,:]['features'])\n",
    "        \n",
    "        \n",
    "        if 'drops' in list(padding_cropping_analysis(df)[1].keys()):\n",
    "            df_df.iloc[i,:]['drops']=padding_cropping_analysis(df,input_timesteps=input_timesteps,th_drop=th_drop)[1]['drops']\n",
    "        else:\n",
    "            df_df.iloc[i,:]['drops']=0\n",
    "            \n",
    "        if 'pads' in list(padding_cropping_analysis(df)[1].keys()):\n",
    "            df_df.iloc[i,:]['pads']=padding_cropping_analysis(df,input_timesteps=input_timesteps,th_drop=th_drop)[1]['pads']\n",
    "        else:\n",
    "            df_df.iloc[i,:]['pads']=0\n",
    "            \n",
    "        if 'crops' in list(padding_cropping_analysis(df)[1].keys()):\n",
    "            df_df.iloc[i,:]['crops']=padding_cropping_analysis(df,input_timesteps=input_timesteps,th_drop=th_drop)[1]['crops']\n",
    "        else:\n",
    "            df_df.iloc[i,:]['crops']=0\n",
    "            \n",
    "        df_df.iloc[i,:]['new_len']=input_timesteps*df_df.iloc[i,:]['patients_num']-df_df.iloc[i,:]['drops']\n",
    "\n",
    "    return df_df\n",
    "\n",
    "def INFODT_date(df):\n",
    "    '''PRE_PROCESSING: add a datetime for the timeseries'''\n",
    "    if 'INFODT' in df.columns: \n",
    "        df['INFODT_date']=df['INFODT'].apply(lambda x: datetime.strptime(x,'%m/%Y'))\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
